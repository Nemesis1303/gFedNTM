{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2ad70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile as zp\n",
    "from pathlib import Path\n",
    "from gensim.utils import check_output\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.special import softmax\n",
    "import shutil\n",
    "from subprocess import check_output\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import colored\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "plt.rcParams.update({'font.size': 16})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762233a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printgr(text):\n",
    "    print(colored.stylize(text, colored.fg('green')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410f9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60659944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 274,
       "width": 385
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx([0,1,2], [0,1,2], label = \"ESTO\", marker=\"X\")\n",
    "plt.semilogx([10,20,30], [5,6,2], label = \"ESTO\", marker=\"X\")\n",
    "plt.xlabel('Number of frozen topics', fontsize=16)\n",
    "plt.ylabel('Similarity', fontsize=16)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271d636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd /export/usuarios_ml4ds/lbartolome/topicmodeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851156b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.topicmodeling.neural_models.pytorchavitm.datasets.bow_dataset import BOWDataset\n",
    "#from src.topicmodeling.neural_models.pytorchavitm.avitm_network.avitm import AVITM\n",
    "#from src.topicmodeling.neural_models.pytorchavitm.utils.data_preparation import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2ae92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsdir = Path(\"/export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24f946f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'OCTIS' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MIND-Lab/OCTIS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8de452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/usuarios_ml4ds/lbartolome/topicmodeler/aux/federated/OCTIS\n"
     ]
    }
   ],
   "source": [
    "cd OCTIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83cfccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octis.models.pytorchavitm.avitm import avitm_model as AVITM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beaf0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from octis.models.pytorchavitm.datasets.bow import BOWDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class BOWDataset(Dataset):\n",
    "    \n",
    "    \"\"\"Class to load BOW dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, idx2token):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes BOWDataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape=(n_samples, n_features)\n",
    "            Document-term matrix\n",
    "        idx2token : list\n",
    "            A list of feature names\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.idx2token = idx2token\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns length of dataset.\"\"\"\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Returns sample from dataset at index i.\"\"\"\n",
    "        X = torch.FloatTensor(self.X[i])\n",
    "\n",
    "        return {'X': X}\n",
    "\n",
    "def prepare_dataset(corpus, val_size=0.25):\n",
    "    \"\"\"It prepares the training data in the format that is asked as input in AVITM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus: List[str]\n",
    "        List of documents to be used for training of the model\n",
    "    val_size: float (default=0.25)\n",
    "        Percentage of the documents to be used for validation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_data: BOWDataset\n",
    "        Training dataset in the required format for AVITM\n",
    "    val_data: BOWDataset\n",
    "        Validation dataset in the required format for AVITM\n",
    "    input_size: int\n",
    "        Size of the input dimensions of the AVITM model to be trained\n",
    "    id2token: tuple\n",
    "        Mappings with the content of each training dataset's document-term matrix.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Divide data into training and validation\n",
    "    docs_train, docs_val = train_test_split(corpus, test_size=val_size, random_state=42)\n",
    "\n",
    "    # Create a CountVectorizer object to convert a collection of text documents into a matrix of token counts\n",
    "    # Max and min_df not considered since cleaning is being previously performed\n",
    "    cv = CountVectorizer(input='content', lowercase=True, stop_words='english', binary=False)\n",
    "\n",
    "    #########################################\n",
    "    # Prepare train dataset in AVITM format #\n",
    "    #########################################\n",
    "    docs_train_conv = [\" \".join(docs_train[i]) for i in np.arange(len(docs_train))]\n",
    "\n",
    "    # Learn the vocabulary dictionary, train_bow = document-term matrix.\n",
    "    train_bow = cv.fit_transform(docs_train_conv).toarray()\n",
    "\n",
    "    # Array mapping from feature integer indices to feature name.\n",
    "    idx2token = cv.get_feature_names_out()\n",
    "    input_size = len(idx2token)\n",
    "    id2token = {k: v for k, v in zip(range(0, len(idx2token)), idx2token)}\n",
    "\n",
    "    # The train dataset is an object from the class BOWDataset\n",
    "    train_data = BOWDataset(train_bow, idx2token)\n",
    "\n",
    "    ##############################################\n",
    "    # Prepare validation dataset in AVITM format #\n",
    "    ##############################################\n",
    "    docs_val_conv = [\" \".join(docs_val[i]) for i in np.arange(len(docs_val))]\n",
    "    val_bow = cv.transform(docs_val_conv)\n",
    "    val_bow = val_bow.toarray()\n",
    "    val_data = BOWDataset(val_bow, idx2token)\n",
    "\n",
    "    return train_data, val_data, input_size, id2token, docs_train, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e831b1d",
   "metadata": {},
   "source": [
    "## **1. Creation of synthetic corpus functions**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41fcef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateArray(arr, n, d):\n",
    "    temp = []\n",
    "    i = 0\n",
    "    while (i < d):\n",
    "        temp.append(arr[i])\n",
    "        i = i + 1\n",
    "    i = 0\n",
    "    while (d < n):\n",
    "        arr[i] = arr[d]\n",
    "        i = i + 1\n",
    "        d = d + 1\n",
    "    arr[:] = arr[: i] + temp\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65ccd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSynthetic(just_inf, gen_docs, vocab_size, n_topics, beta, alpha, n_docs,\n",
    "                      n_docs_inf, n_docs_global_inf, nwords, alg, n_nodes,\n",
    "                      frozen_topics, prior_frozen, own_topics, prior_nofrozen):\n",
    "    \n",
    "    if just_inf:\n",
    "        n_total_docs = n_docs_global_inf\n",
    "    else:\n",
    "        n_total_docs = n_docs + n_docs_inf\n",
    "\n",
    "    # Step 1 - generation of topics\n",
    "    topic_vectors = np.random.dirichlet(vocab_size*[beta], n_topics)\n",
    "    \n",
    "    # Step 2 - generation of document topic proportions\n",
    "    doc_topics_all = []\n",
    "    for i in np.arange(n_nodes):\n",
    "        doc_topics = np.random.dirichlet(prior_frozen + prior_nofrozen, n_total_docs)\n",
    "        prior_nofrozen = rotateArray(prior_nofrozen, len(prior_nofrozen), own_topics)\n",
    "        doc_topics_all.append(doc_topics)\n",
    "        \n",
    "    # Step 3 - Document generation\n",
    "    documents_all = []\n",
    "    # z_all = []\n",
    "    \n",
    "    if gen_docs:\n",
    "        for i in np.arange(n_nodes):\n",
    "            print(\"Generating document words for node \", str(i))\n",
    "            documents = [] # Document words\n",
    "            #z = [] # Assignments\n",
    "            for docid in tqdm(np.arange(n_total_docs)):\n",
    "                doc_len = np.random.randint(low=nwords[0], high=nwords[1])\n",
    "                this_doc_words = []\n",
    "                #this_doc_assigns = []\n",
    "                for wd_idx in np.arange(doc_len):\n",
    "\n",
    "                    tpc = np.nonzero(np.random.multinomial(1, doc_topics_all[i][docid]))[0][0]\n",
    "                    #this_doc_assigns.append(tpc)\n",
    "                    if alg == \"lda\":\n",
    "                        word = np.nonzero(np.random.multinomial(1, topic_vectors[tpc]))[0][0]\n",
    "                    else: #prodlda\n",
    "                        pval = np.power(topic_vectors[tpc], doc_topics_all[i][docid][tpc])\n",
    "                        weights = torch.tensor(pval, dtype=torch.float) # create a tensor of weights\n",
    "                        word = torch.multinomial(weights, 1).numpy()[0]\n",
    "                        #pval = normalize(pval[:,np.newaxis], norm='l1', axis=0).ravel()\n",
    "                        #word = np.nonzero(np.random.multinomial(1, b))[0][0]\n",
    "                    this_doc_words.append('wd'+str(word))\n",
    "                #z.append(this_doc_assigns)\n",
    "                documents.append(this_doc_words)\n",
    "            documents_all.append(documents)\n",
    "            #z_all.append(z)\n",
    "    \n",
    "    return topic_vectors, doc_topics_all, documents_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c080d43",
   "metadata": {},
   "source": [
    "## **2. Training and evaluation functions**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e8a4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_folder(modelname, modelsdir):\n",
    "    \n",
    "    # Create model folder and save model training configuration\n",
    "    modeldir = modelsdir.joinpath(modelname)\n",
    "    \n",
    "    if modeldir.exists():\n",
    "\n",
    "        # Remove current backup folder, if it exists\n",
    "        old_model_dir = Path(str(modeldir) + '_old/')\n",
    "        if old_model_dir.exists():\n",
    "            shutil.rmtree(old_model_dir)\n",
    "\n",
    "        # Copy current model folder to the backup folder.\n",
    "        shutil.move(modeldir, old_model_dir)\n",
    "        print(f'-- -- Creating backup of existing model in {old_model_dir}')\n",
    "\n",
    "    modeldir.mkdir()\n",
    "    configFile = modeldir.joinpath('trainconfig.json')\n",
    "    \n",
    "    return modeldir, configFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da7da7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_topic_word_to_init_size(vocab_size, model, model_type,\n",
    "                                    ntopics, id2token, all_words):\n",
    "    \"\"\"It converts the topic-word distribution matrix obtained from the training of a model into a matrix with the dimensions of the original topic-word distribution, assigning zeros to those words that are not present in the corpus. \n",
    "    It is only of use in case we are training a model over a synthetic dataset, so as to later compare the performance of the attained model in what regards to the similarity between the original and the trained model.\n",
    "\n",
    "    Args:\n",
    "        * vocab_size (int):       Size of the synethic'data vocabulary.\n",
    "        * model (AVITM/CTM):      Model whose topic-word matrix is being transformed.\n",
    "        * model_type (str):       Type of the trained model (e.g. AVITM)\n",
    "        * ntopics (int):          Number of topics of the trained model.\n",
    "        * id2token (List[tuple]): Mappings with the content of the document-term matrix.\n",
    "        * all_words (List[str]):  List of all the words of the vocabulary of size vocab_size.\n",
    "\n",
    "    Returns:\n",
    "        * ndarray: Normalized transormed topic-word distribution.\n",
    "    \"\"\"\n",
    "    if model_type == \"avitm\":\n",
    "        w_t_distrib = np.zeros((ntopics, vocab_size), dtype=np.float64)\n",
    "        wd = model.get_topic_word_mat()#get_topic_word_distribution()\n",
    "        wd = softmax(betas, axis=1)\n",
    "        for i in np.arange(ntopics):\n",
    "            for idx, word in id2token.items():\n",
    "                for j in np.arange(len(all_words)):\n",
    "                    if all_words[j] == word:\n",
    "                        w_t_distrib[i, j] = wd[i][idx]\n",
    "                        break\n",
    "        normalized_array = normalize(w_t_distrib,axis=1,norm='l1')\n",
    "        return normalized_array\n",
    "    else:\n",
    "        print(\"Method not impleemnted for the selected model type\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86e07eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_avitm(modelname, modelsdir, corpus):\n",
    "    \n",
    "    # Create model folder\n",
    "    modeldir, configFile = create_model_folder(modelname, modelsdir)\n",
    "    \n",
    "    # Create corpus in ProdLDA format (BoWDataset)\n",
    "    train_data, val_data, input_size, id2token, docs_train, cv = prepare_dataset(corpus)\n",
    "    idx2token = train_data.idx2token\n",
    "    \n",
    "    #cv = CountVectorizer(input='content', lowercase=True, stop_words='english', binary=False)\n",
    "    #docs = [\" \".join(corpus[i]) for i in np.arange(len(corpus))]\n",
    "    #train_bow = cv.fit_transform(docs).toarray()\n",
    "    #idx2token = cv.get_feature_names_out()\n",
    "    #train_dataset = BOWDataset(train_bow, idx2token)\n",
    "    #input_size = len(idx2token)\n",
    "    #id2token = {k: v for k, v in zip(range(0, len(idx2token)), idx2token)}\n",
    "    \n",
    "    #avitm = AVITM(logger=None,\n",
    "    #          input_size=input_size,\n",
    "    #          n_components=n_topics,\n",
    "    #          model_type=\"prodLDA\",\n",
    "    #          hidden_sizes=(100, 100),\n",
    "    #          activation='softplus',\n",
    "    #          dropout=0.2,\n",
    "    #          learn_priors=True,\n",
    "    #          batch_size=64,\n",
    "    #          lr=2e-3,\n",
    "    #          momentum=0.99,\n",
    "    #          solver='adam',\n",
    "    #          num_epochs=100,\n",
    "    #          reduce_on_plateau=False,\n",
    "    #          topic_prior_mean=0.0,\n",
    "    #          topic_prior_variance=None,\n",
    "    #          num_samples=20,\n",
    "    #          num_data_loader_workers=0,\n",
    "    #          verbose=True)\n",
    "    \n",
    "    avitm = AVITM.AVITM_model(input_size=input_size,\n",
    "                  num_topics=n_topics,\n",
    "                  model_type='prodLDA',\n",
    "                  hidden_sizes=(100, 100),\n",
    "                  activation='softplus',\n",
    "                  dropout=0.2,\n",
    "                  learn_priors=True,\n",
    "                  batch_size=64,\n",
    "                  lr=2e-3,\n",
    "                  momentum=0.99,\n",
    "                  solver='adam',\n",
    "                  num_epochs=100,\n",
    "                  reduce_on_plateau=False,\n",
    "                  topic_prior_mean=0.0,\n",
    "                  topic_prior_variance=None,\n",
    "                  num_samples=10,\n",
    "                  num_data_loader_workers=0,\n",
    "                  verbose=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    avitm.fit(train_data,val_data)\n",
    "    \n",
    "    return modeldir, avitm, cv, id2token, idx2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d1fe824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_betas(beta, topic_vectors):\n",
    "    print('Tópicos (equivalentes) evaluados correctamente:')\n",
    "    score = np.sum(np.max(np.sqrt(beta).dot(np.sqrt(topic_vectors.T)), axis=0))\n",
    "    printgr(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d40df29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_thetas(thetas_theoretical, thetas_actual, n_docs):\n",
    "    sim_mat_theoretical = np.sqrt(thetas_theoretical).dot(np.sqrt(thetas_theoretical.T))\n",
    "    sim_mat_actual = np.sqrt(thetas_actual).dot(np.sqrt(thetas_actual.T))\n",
    "    print('Difference in evaluation of doc similarity:')\n",
    "    score = np.sum(np.abs(sim_mat_theoretical - sim_mat_actual))/n_docs\n",
    "    printgr(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b3a2e6",
   "metadata": {},
   "source": [
    "## **3. Actual training and evaluation**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c0cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4bcdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling settings\n",
    "vocab_size = 5000\n",
    "n_topics = 50\n",
    "beta = 1e-2\n",
    "alpha = 5/n_topics\n",
    "n_docs = 10000\n",
    "n_docs_inf = 1000\n",
    "n_docs_global_inf = 1000#int(n_docs / n_nodes)\n",
    "nwords = (150, 250) #Min and max lengths of the documents\n",
    "alg = \"lda\" #\"prod\"\n",
    "\n",
    "tm_settings = {\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"n_topics\": n_topics,\n",
    "    \"beta\": beta,\n",
    "    \"alpha\": alpha,\n",
    "    \"n_docs\": n_docs,\n",
    "    \"n_docs_inf\": n_docs_inf,\n",
    "    \"n_docs_global_inf\": n_docs_global_inf,\n",
    "    \"nwords\": nwords,\n",
    "    \"alg\": alg\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "533d815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralized settings\n",
    "\n",
    "frozen_topics = 5\n",
    "prior_frozen = frozen_topics * [alpha]\n",
    "own_topics = int((n_topics-frozen_topics)/n_nodes)\n",
    "prior_nofrozen = own_topics * [alpha] + (n_topics-frozen_topics-own_topics) * [alpha/10000]\n",
    "\n",
    "centralized_settings = {\n",
    "    \"n_nodes\": n_nodes,\n",
    "    \"frozen_topics\": frozen_topics,\n",
    "    \"prior_frozen\": prior_frozen,\n",
    "    \"own_topics\": own_topics,\n",
    "    \"prior_nofrozen\": prior_nofrozen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6055a65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing for frozen topics  5\n",
      "Shape of thetas_bas (5000, 50)\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:50<00:00, 39.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 41.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 50)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1738.9884822916667\tTime: 0:00:00.575423\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1683.856940625\tTime: 0:00:00.060773\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1629.78651875\tTime: 0:00:00.653099\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1567.04604375\tTime: 0:00:00.059367\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1584.2735604166667\tTime: 0:00:00.543466\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1535.681875\tTime: 0:00:00.059066\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1556.8311541666667\tTime: 0:00:00.535887\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1517.0091625\tTime: 0:00:00.059630\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1538.2299104166666\tTime: 0:00:00.542031\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1502.314334375\tTime: 0:00:00.061011\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1525.4389708333333\tTime: 0:00:00.560590\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1487.220190625\tTime: 0:00:00.075819\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1514.8703458333334\tTime: 0:00:00.586123\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1481.832484375\tTime: 0:00:00.059765\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1505.92475625\tTime: 0:00:00.527359\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1472.204296875\tTime: 0:00:00.059593\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1496.947465625\tTime: 0:00:00.562357\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1464.873371875\tTime: 0:00:00.074084\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1489.6634135416666\tTime: 0:00:00.532069\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1453.48324375\tTime: 0:00:00.059707\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1486.333196875\tTime: 0:00:00.534888\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1449.9186125\tTime: 0:00:00.059851\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1481.574640625\tTime: 0:00:00.536679\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1444.40745625\tTime: 0:00:00.059956\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1473.302440625\tTime: 0:00:00.534010\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1436.44409375\tTime: 0:00:00.059894\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1471.8334645833334\tTime: 0:00:00.533596\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1437.232521875\tTime: 0:00:00.060204\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1467.3705041666667\tTime: 0:00:00.526154\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1435.998259375\tTime: 0:00:00.061547\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1460.3984447916666\tTime: 0:00:00.525082\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1426.676371875\tTime: 0:00:00.060776\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1463.59429375\tTime: 0:00:00.525677\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1423.48866875\tTime: 0:00:00.060771\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1458.6012864583333\tTime: 0:00:00.527160\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1423.57998125\tTime: 0:00:00.060245\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1456.8553229166666\tTime: 0:00:00.523069\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1416.7221\tTime: 0:00:00.060616\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1453.7569260416667\tTime: 0:00:00.526211\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1415.908375\tTime: 0:00:00.061078\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1449.6567114583333\tTime: 0:00:00.527262\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1413.694678125\tTime: 0:00:00.062097\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1450.3633822916668\tTime: 0:00:00.526643\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1420.44810625\tTime: 0:00:00.060994\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1446.450859375\tTime: 0:00:00.530301\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1412.95928125\tTime: 0:00:00.060919\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1450.1098791666666\tTime: 0:00:00.527782\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1409.595275\tTime: 0:00:00.060959\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1446.8491020833333\tTime: 0:00:00.531553\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1406.585371875\tTime: 0:00:00.060355\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1446.0249427083334\tTime: 0:00:00.530231\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1406.86796875\tTime: 0:00:00.061234\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1445.4720458333334\tTime: 0:00:00.527290\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1404.346596875\tTime: 0:00:00.061018\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1442.324325\tTime: 0:00:00.624840\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1405.998259375\tTime: 0:00:00.060851\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1442.2704604166668\tTime: 0:00:00.528015\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1401.71685625\tTime: 0:00:00.076727\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1441.090846875\tTime: 0:00:00.570888\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1407.168059375\tTime: 0:00:00.061491\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1438.1934197916667\tTime: 0:00:00.525735\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1401.91390625\tTime: 0:00:00.060426\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1438.3337770833334\tTime: 0:00:00.528603\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1398.922034375\tTime: 0:00:00.060900\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1437.6334270833333\tTime: 0:00:00.528239\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1402.3129625\tTime: 0:00:00.061254\n",
      "Epoch: [34/100]\tSamples: [127500/375000]\tTrain Loss: 1436.5332791666667\tTime: 0:00:00.527069\n",
      "Epoch: [34/100]\tSamples: [1250/125000]\tValidation Loss: 1398.5663875\tTime: 0:00:00.062419\n",
      "Epoch: [35/100]\tSamples: [131250/375000]\tTrain Loss: 1437.537546875\tTime: 0:00:00.537144\n",
      "Epoch: [35/100]\tSamples: [1250/125000]\tValidation Loss: 1401.28761875\tTime: 0:00:00.061930\n",
      "Epoch: [36/100]\tSamples: [135000/375000]\tTrain Loss: 1436.2937229166666\tTime: 0:00:00.539618\n",
      "Epoch: [36/100]\tSamples: [1250/125000]\tValidation Loss: 1400.12574375\tTime: 0:00:00.061073\n",
      "Epoch: [37/100]\tSamples: [138750/375000]\tTrain Loss: 1434.3709572916666\tTime: 0:00:00.531775\n",
      "Epoch: [37/100]\tSamples: [1250/125000]\tValidation Loss: 1398.871103125\tTime: 0:00:00.061091\n",
      "Epoch: [38/100]\tSamples: [142500/375000]\tTrain Loss: 1435.1893552083334\tTime: 0:00:00.541589\n",
      "Epoch: [38/100]\tSamples: [1250/125000]\tValidation Loss: 1398.617175\tTime: 0:00:00.061388\n",
      "Epoch: [39/100]\tSamples: [146250/375000]\tTrain Loss: 1436.509521875\tTime: 0:00:00.533292\n",
      "Epoch: [39/100]\tSamples: [1250/125000]\tValidation Loss: 1397.562571875\tTime: 0:00:00.060766\n",
      "Epoch: [40/100]\tSamples: [150000/375000]\tTrain Loss: 1433.6265520833333\tTime: 0:00:00.583883\n",
      "Epoch: [40/100]\tSamples: [1250/125000]\tValidation Loss: 1397.635296875\tTime: 0:00:00.076208\n",
      "Epoch: [41/100]\tSamples: [153750/375000]\tTrain Loss: 1434.0692677083334\tTime: 0:00:00.603100\n",
      "Epoch: [41/100]\tSamples: [1250/125000]\tValidation Loss: 1396.37763125\tTime: 0:00:00.076922\n",
      "Epoch: [42/100]\tSamples: [157500/375000]\tTrain Loss: 1434.56330625\tTime: 0:00:00.601208\n",
      "Epoch: [42/100]\tSamples: [1250/125000]\tValidation Loss: 1393.44503125\tTime: 0:00:00.076678\n",
      "Epoch: [43/100]\tSamples: [161250/375000]\tTrain Loss: 1432.374946875\tTime: 0:00:00.604095\n",
      "Epoch: [43/100]\tSamples: [1250/125000]\tValidation Loss: 1394.8498\tTime: 0:00:00.076685\n",
      "Epoch: [44/100]\tSamples: [165000/375000]\tTrain Loss: 1432.732678125\tTime: 0:00:00.600623\n",
      "Epoch: [44/100]\tSamples: [1250/125000]\tValidation Loss: 1390.43075\tTime: 0:00:00.078086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45/100]\tSamples: [168750/375000]\tTrain Loss: 1430.807059375\tTime: 0:00:00.608613\n",
      "Epoch: [45/100]\tSamples: [1250/125000]\tValidation Loss: 1395.420109375\tTime: 0:00:00.077064\n",
      "Epoch: [46/100]\tSamples: [172500/375000]\tTrain Loss: 1431.9349208333333\tTime: 0:00:00.602373\n",
      "Epoch: [46/100]\tSamples: [1250/125000]\tValidation Loss: 1392.513653125\tTime: 0:00:00.076890\n",
      "Epoch: [47/100]\tSamples: [176250/375000]\tTrain Loss: 1429.9526802083333\tTime: 0:00:00.601534\n",
      "Epoch: [47/100]\tSamples: [1250/125000]\tValidation Loss: 1389.821221875\tTime: 0:00:00.076276\n",
      "Epoch: [48/100]\tSamples: [180000/375000]\tTrain Loss: 1431.1783895833332\tTime: 0:00:00.604031\n",
      "Epoch: [48/100]\tSamples: [1250/125000]\tValidation Loss: 1391.692403125\tTime: 0:00:00.076999\n",
      "Epoch: [49/100]\tSamples: [183750/375000]\tTrain Loss: 1434.2245697916667\tTime: 0:00:00.607802\n",
      "Epoch: [49/100]\tSamples: [1250/125000]\tValidation Loss: 1390.340275\tTime: 0:00:00.076526\n",
      "Epoch: [50/100]\tSamples: [187500/375000]\tTrain Loss: 1429.267053125\tTime: 0:00:00.606210\n",
      "Epoch: [50/100]\tSamples: [1250/125000]\tValidation Loss: 1388.6588375\tTime: 0:00:00.076659\n",
      "Epoch: [51/100]\tSamples: [191250/375000]\tTrain Loss: 1428.6378989583334\tTime: 0:00:00.656870\n",
      "Epoch: [51/100]\tSamples: [1250/125000]\tValidation Loss: 1389.948665625\tTime: 0:00:00.061003\n",
      "Epoch: [52/100]\tSamples: [195000/375000]\tTrain Loss: 1426.39903125\tTime: 0:00:00.528494\n",
      "Epoch: [52/100]\tSamples: [1250/125000]\tValidation Loss: 1388.529965625\tTime: 0:00:00.061232\n",
      "Epoch: [53/100]\tSamples: [198750/375000]\tTrain Loss: 1426.132471875\tTime: 0:00:00.527438\n",
      "Epoch: [53/100]\tSamples: [1250/125000]\tValidation Loss: 1392.00870625\tTime: 0:00:00.061370\n",
      "Epoch: [54/100]\tSamples: [202500/375000]\tTrain Loss: 1426.2242229166666\tTime: 0:00:00.537197\n",
      "Epoch: [54/100]\tSamples: [1250/125000]\tValidation Loss: 1385.96658125\tTime: 0:00:00.061203\n",
      "Epoch: [55/100]\tSamples: [206250/375000]\tTrain Loss: 1426.349053125\tTime: 0:00:00.700708\n",
      "Epoch: [55/100]\tSamples: [1250/125000]\tValidation Loss: 1387.93893125\tTime: 0:00:00.073349\n",
      "Epoch: [56/100]\tSamples: [210000/375000]\tTrain Loss: 1428.7922052083334\tTime: 0:00:00.529369\n",
      "Epoch: [56/100]\tSamples: [1250/125000]\tValidation Loss: 1386.08954375\tTime: 0:00:00.061590\n",
      "Epoch: [57/100]\tSamples: [213750/375000]\tTrain Loss: 1426.9276041666667\tTime: 0:00:00.529892\n",
      "Epoch: [57/100]\tSamples: [1250/125000]\tValidation Loss: 1389.60560625\tTime: 0:00:00.061771\n",
      "Epoch: [58/100]\tSamples: [217500/375000]\tTrain Loss: 1424.5519854166666\tTime: 0:00:00.530024\n",
      "Epoch: [58/100]\tSamples: [1250/125000]\tValidation Loss: 1391.47675625\tTime: 0:00:00.061531\n",
      "Epoch: [59/100]\tSamples: [221250/375000]\tTrain Loss: 1426.8689260416666\tTime: 0:00:00.525452\n",
      "Epoch: [59/100]\tSamples: [1250/125000]\tValidation Loss: 1386.19548125\tTime: 0:00:00.061751\n",
      "Early stopping\n",
      "MAX BETAS:  0.0004734374\n",
      "MIN BETAS:  0.00014095912\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m8.569492878037615\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2545.9730582615643\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1689.7844791666666\tTime: 0:00:00.088667\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1580.307375\tTime: 0:00:00.011812\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1652.8730729166666\tTime: 0:00:00.080588\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1591.743875\tTime: 0:00:00.011680\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1614.65365625\tTime: 0:00:00.082725\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1597.48090625\tTime: 0:00:00.011904\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1581.71728125\tTime: 0:00:00.083296\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1582.7079375\tTime: 0:00:00.011484\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1548.6375\tTime: 0:00:00.082364\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1553.846125\tTime: 0:00:00.011897\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1531.3631458333334\tTime: 0:00:00.083361\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1511.45740625\tTime: 0:00:00.014338\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1519.6772083333333\tTime: 0:00:00.085809\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1479.60278125\tTime: 0:00:00.014182\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1501.0983958333334\tTime: 0:00:00.080691\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1456.99040625\tTime: 0:00:00.011549\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1487.2898958333333\tTime: 0:00:00.081230\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1449.96553125\tTime: 0:00:00.011551\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1480.6174895833333\tTime: 0:00:00.084205\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1444.91846875\tTime: 0:00:00.011390\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1473.44565625\tTime: 0:00:00.085279\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1430.2505625\tTime: 0:00:00.011797\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1467.4554375\tTime: 0:00:00.080331\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1425.1443125\tTime: 0:00:00.011571\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1457.9851666666666\tTime: 0:00:00.081478\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1421.4143125\tTime: 0:00:00.012124\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1450.9949479166667\tTime: 0:00:00.083050\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1416.57578125\tTime: 0:00:00.011688\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1456.0903541666667\tTime: 0:00:00.083248\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1412.106\tTime: 0:00:00.011608\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1444.8212708333333\tTime: 0:00:00.083921\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1405.99928125\tTime: 0:00:00.011569\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1438.67621875\tTime: 0:00:00.084338\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1400.5541875\tTime: 0:00:00.011841\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1435.35875\tTime: 0:00:00.083084\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1394.833125\tTime: 0:00:00.011554\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1436.0211875\tTime: 0:00:00.081104\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1393.19771875\tTime: 0:00:00.011865\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1436.233328125\tTime: 0:00:00.080877\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1393.9181875\tTime: 0:00:00.014406\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1428.45390625\tTime: 0:00:00.082220\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1383.36165625\tTime: 0:00:00.011889\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1424.28465625\tTime: 0:00:00.082279\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1386.89284375\tTime: 0:00:00.011598\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1421.5708541666668\tTime: 0:00:00.085116\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1382.49140625\tTime: 0:00:00.012638\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1422.2361979166667\tTime: 0:00:00.081910\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1381.21028125\tTime: 0:00:00.012007\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1415.0324895833332\tTime: 0:00:00.085422\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1380.3014375\tTime: 0:00:00.011808\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1411.7295208333333\tTime: 0:00:00.082715\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1375.072\tTime: 0:00:00.014131\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1413.0342083333333\tTime: 0:00:00.081940\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1379.902375\tTime: 0:00:00.011581\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1410.2010677083333\tTime: 0:00:00.080449\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1375.47890625\tTime: 0:00:00.014135\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1410.1596041666667\tTime: 0:00:00.082702\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1375.64059375\tTime: 0:00:00.011972\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1409.2881041666667\tTime: 0:00:00.080981\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1374.08828125\tTime: 0:00:00.011414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1406.5251458333332\tTime: 0:00:00.081565\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1378.6864375\tTime: 0:00:00.011808\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1408.90521875\tTime: 0:00:00.080888\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1378.88071875\tTime: 0:00:00.011668\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1403.1239322916667\tTime: 0:00:00.079909\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1371.095625\tTime: 0:00:00.011422\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1405.604875\tTime: 0:00:00.082348\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1370.9491875\tTime: 0:00:00.011688\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1398.5839375\tTime: 0:00:00.085921\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1370.760875\tTime: 0:00:00.011411\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1400.352046875\tTime: 0:00:00.081303\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1373.98565625\tTime: 0:00:00.011668\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1398.9188802083333\tTime: 0:00:00.081427\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1376.17603125\tTime: 0:00:00.011598\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1397.77090625\tTime: 0:00:00.080632\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1368.7233125\tTime: 0:00:00.011372\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1387.9603802083334\tTime: 0:00:00.080815\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1376.4820625\tTime: 0:00:00.011814\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1396.73634375\tTime: 0:00:00.081070\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1371.38921875\tTime: 0:00:00.011450\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1398.1618020833334\tTime: 0:00:00.080391\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1368.56815625\tTime: 0:00:00.012164\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1396.4675\tTime: 0:00:00.083087\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1369.7318125\tTime: 0:00:00.011605\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1390.3501145833334\tTime: 0:00:00.081467\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1374.00109375\tTime: 0:00:00.011290\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1397.181515625\tTime: 0:00:00.080327\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1368.64553125\tTime: 0:00:00.011523\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1391.858375\tTime: 0:00:00.081021\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1365.51009375\tTime: 0:00:00.011633\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1389.8368333333333\tTime: 0:00:00.081322\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1366.3258125\tTime: 0:00:00.013112\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1390.975703125\tTime: 0:00:00.082261\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1369.98209375\tTime: 0:00:00.011960\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1393.1474791666667\tTime: 0:00:00.081306\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1368.6889375\tTime: 0:00:00.014478\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1386.4479895833333\tTime: 0:00:00.085048\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1364.24709375\tTime: 0:00:00.012113\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1390.9701302083333\tTime: 0:00:00.080870\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1368.8293125\tTime: 0:00:00.011497\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1389.0269427083333\tTime: 0:00:00.082098\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1364.143\tTime: 0:00:00.011896\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1386.8152447916666\tTime: 0:00:00.081953\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1366.97128125\tTime: 0:00:00.011438\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1384.5959166666667\tTime: 0:00:00.084250\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1367.82\tTime: 0:00:00.014337\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1386.6898541666667\tTime: 0:00:00.083147\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1362.39865625\tTime: 0:00:00.011391\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1382.663359375\tTime: 0:00:00.081418\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1363.46946875\tTime: 0:00:00.011838\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1385.035375\tTime: 0:00:00.082851\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1364.98328125\tTime: 0:00:00.011470\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1385.5393125\tTime: 0:00:00.082609\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1367.94340625\tTime: 0:00:00.011862\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1387.2898385416668\tTime: 0:00:00.080921\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1364.31378125\tTime: 0:00:00.011332\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1385.42778125\tTime: 0:00:00.082989\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1365.97284375\tTime: 0:00:00.011645\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.492365281696458\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3326.8610323266475\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1677.3265520833334\tTime: 0:00:00.083955\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1554.86671875\tTime: 0:00:00.011799\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1639.24478125\tTime: 0:00:00.083881\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1567.05528125\tTime: 0:00:00.014243\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1594.1062291666667\tTime: 0:00:00.085948\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1574.36859375\tTime: 0:00:00.012014\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1556.2233645833333\tTime: 0:00:00.082132\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1556.60196875\tTime: 0:00:00.012472\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1529.1171041666666\tTime: 0:00:00.083921\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1521.16228125\tTime: 0:00:00.012885\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1514.7795625\tTime: 0:00:00.093127\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1473.115\tTime: 0:00:00.014372\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1490.9213177083334\tTime: 0:00:00.086809\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1450.250875\tTime: 0:00:00.012129\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1478.1132291666668\tTime: 0:00:00.083005\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1429.35559375\tTime: 0:00:00.011731\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1466.5867760416666\tTime: 0:00:00.083680\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1419.52840625\tTime: 0:00:00.014634\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1451.6917395833334\tTime: 0:00:00.083206\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1406.26678125\tTime: 0:00:00.011847\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1449.44275\tTime: 0:00:00.086514\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1402.0375\tTime: 0:00:00.011882\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1439.03025\tTime: 0:00:00.081873\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1395.1103125\tTime: 0:00:00.011861\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1439.3031458333332\tTime: 0:00:00.101306\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1390.29828125\tTime: 0:00:00.014540\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1437.6369479166667\tTime: 0:00:00.099446\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1388.50703125\tTime: 0:00:00.011605\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1425.6718385416666\tTime: 0:00:00.084227\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1395.9748125\tTime: 0:00:00.014416\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1422.6546041666666\tTime: 0:00:00.083853\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1380.53153125\tTime: 0:00:00.011590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1416.24853125\tTime: 0:00:00.084797\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1381.57715625\tTime: 0:00:00.014781\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1415.8906145833334\tTime: 0:00:00.088925\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1382.5619375\tTime: 0:00:00.011729\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1408.4620833333333\tTime: 0:00:00.085344\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1374.6295625\tTime: 0:00:00.012329\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1410.8592395833334\tTime: 0:00:00.083293\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1377.469\tTime: 0:00:00.014302\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1407.830140625\tTime: 0:00:00.084662\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1375.21234375\tTime: 0:00:00.011922\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1408.47390625\tTime: 0:00:00.084163\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1370.1489375\tTime: 0:00:00.011957\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1410.4020520833333\tTime: 0:00:00.084075\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1370.4070625\tTime: 0:00:00.011766\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1400.9193020833334\tTime: 0:00:00.084981\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1372.55646875\tTime: 0:00:00.011699\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1403.6174114583334\tTime: 0:00:00.081945\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1366.21446875\tTime: 0:00:00.013202\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1400.5140677083334\tTime: 0:00:00.085819\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1365.575625\tTime: 0:00:00.014065\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1402.96196875\tTime: 0:00:00.086662\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1365.3303125\tTime: 0:00:00.014488\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1393.7575260416668\tTime: 0:00:00.083878\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1364.90803125\tTime: 0:00:00.011864\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1398.3216145833333\tTime: 0:00:00.084283\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1364.07834375\tTime: 0:00:00.011808\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1394.54771875\tTime: 0:00:00.091874\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1362.92471875\tTime: 0:00:00.014710\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1391.6761145833334\tTime: 0:00:00.087786\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1365.2030625\tTime: 0:00:00.011904\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1389.5514739583334\tTime: 0:00:00.085277\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1367.0091875\tTime: 0:00:00.014488\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1391.5353854166667\tTime: 0:00:00.085312\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1364.457\tTime: 0:00:00.012978\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1391.46028125\tTime: 0:00:00.084846\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1358.16403125\tTime: 0:00:00.011784\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1388.6401458333332\tTime: 0:00:00.087507\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1360.4826875\tTime: 0:00:00.012020\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1388.4649375\tTime: 0:00:00.084841\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1362.14796875\tTime: 0:00:00.011873\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1385.6023958333333\tTime: 0:00:00.097758\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1360.27015625\tTime: 0:00:00.015140\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1388.1578645833333\tTime: 0:00:00.101109\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1359.30503125\tTime: 0:00:00.014498\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1385.4437239583333\tTime: 0:00:00.087455\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1365.19646875\tTime: 0:00:00.012710\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.559379361680816\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3207.6395653382447\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1704.62775\tTime: 0:00:00.082601\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1585.622\tTime: 0:00:00.014702\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1671.0710208333333\tTime: 0:00:00.082269\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1596.460625\tTime: 0:00:00.011684\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1628.0136770833333\tTime: 0:00:00.081995\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1604.2808125\tTime: 0:00:00.014374\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1590.4448541666666\tTime: 0:00:00.083871\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1591.0740625\tTime: 0:00:00.014360\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1563.0371666666667\tTime: 0:00:00.083342\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1557.66478125\tTime: 0:00:00.012240\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1544.1263020833333\tTime: 0:00:00.082455\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1521.50646875\tTime: 0:00:00.014069\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1523.2178958333334\tTime: 0:00:00.100324\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1480.9625625\tTime: 0:00:00.014643\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1511.1331458333334\tTime: 0:00:00.083735\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1460.2905\tTime: 0:00:00.011608\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1497.5716145833333\tTime: 0:00:00.083309\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1445.05165625\tTime: 0:00:00.014466\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1486.1628125\tTime: 0:00:00.082398\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1428.08165625\tTime: 0:00:00.014276\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1480.4611875\tTime: 0:00:00.100550\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1426.993625\tTime: 0:00:00.014659\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1473.893921875\tTime: 0:00:00.099153\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1415.42675\tTime: 0:00:00.014155\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1469.7339375\tTime: 0:00:00.100320\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1414.90196875\tTime: 0:00:00.014243\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1463.61640625\tTime: 0:00:00.084350\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1409.083\tTime: 0:00:00.014539\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1461.95128125\tTime: 0:00:00.082540\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1400.86590625\tTime: 0:00:00.011784\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1454.9188020833333\tTime: 0:00:00.083393\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1402.44203125\tTime: 0:00:00.011552\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1443.7841354166667\tTime: 0:00:00.085476\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1393.25303125\tTime: 0:00:00.014406\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1451.5048645833333\tTime: 0:00:00.086829\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1396.852125\tTime: 0:00:00.011603\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1447.9166458333334\tTime: 0:00:00.083765\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1392.303375\tTime: 0:00:00.012031\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1441.5093645833333\tTime: 0:00:00.083882\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1390.33478125\tTime: 0:00:00.011421\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1435.9469791666668\tTime: 0:00:00.084421\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1383.8933125\tTime: 0:00:00.011789\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1433.0583802083333\tTime: 0:00:00.083056\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1382.31578125\tTime: 0:00:00.011815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1439.59253125\tTime: 0:00:00.082119\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1381.74328125\tTime: 0:00:00.011817\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1438.0468020833334\tTime: 0:00:00.082176\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1386.61190625\tTime: 0:00:00.011872\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1433.1065729166667\tTime: 0:00:00.084860\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1382.91\tTime: 0:00:00.014565\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1427.1225833333333\tTime: 0:00:00.086626\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1376.31371875\tTime: 0:00:00.011575\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1424.1964479166666\tTime: 0:00:00.082519\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1380.69353125\tTime: 0:00:00.011819\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1427.2997291666666\tTime: 0:00:00.083069\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1372.852625\tTime: 0:00:00.011659\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1423.19175\tTime: 0:00:00.082284\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1374.0340625\tTime: 0:00:00.014516\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1425.96196875\tTime: 0:00:00.082881\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1374.711125\tTime: 0:00:00.011414\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1419.4253333333334\tTime: 0:00:00.084085\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1382.62515625\tTime: 0:00:00.014982\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1420.4078125\tTime: 0:00:00.085640\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1371.9524375\tTime: 0:00:00.014407\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1420.130375\tTime: 0:00:00.086865\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1374.4098125\tTime: 0:00:00.012101\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1417.187265625\tTime: 0:00:00.083802\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1369.1301875\tTime: 0:00:00.011759\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1417.7965677083334\tTime: 0:00:00.081741\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1372.32628125\tTime: 0:00:00.011946\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1417.6317708333333\tTime: 0:00:00.082849\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1367.4210625\tTime: 0:00:00.011721\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1415.4100416666668\tTime: 0:00:00.083567\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1371.2733125\tTime: 0:00:00.011897\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1415.335703125\tTime: 0:00:00.081952\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1369.3625625\tTime: 0:00:00.012033\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1414.855453125\tTime: 0:00:00.083710\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1359.48878125\tTime: 0:00:00.012498\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1409.1224427083334\tTime: 0:00:00.085073\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1364.1610625\tTime: 0:00:00.011462\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1408.1696979166666\tTime: 0:00:00.083668\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1364.54846875\tTime: 0:00:00.012073\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1405.9029010416666\tTime: 0:00:00.082003\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1366.52446875\tTime: 0:00:00.014422\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1409.03646875\tTime: 0:00:00.086062\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1369.69259375\tTime: 0:00:00.012479\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1404.9273333333333\tTime: 0:00:00.082046\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1370.472375\tTime: 0:00:00.011644\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.583395669038123\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3293.189371726224\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1678.2546666666667\tTime: 0:00:00.092243\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1575.2605\tTime: 0:00:00.014936\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1641.349875\tTime: 0:00:00.099550\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1588.16040625\tTime: 0:00:00.014217\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1598.98478125\tTime: 0:00:00.091625\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1593.55365625\tTime: 0:00:00.012154\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1560.9733125\tTime: 0:00:00.081495\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1578.45759375\tTime: 0:00:00.011635\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1528.28884375\tTime: 0:00:00.097347\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1542.06178125\tTime: 0:00:00.014496\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1512.6503229166667\tTime: 0:00:00.099366\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1510.497375\tTime: 0:00:00.014389\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1491.2011770833333\tTime: 0:00:00.091575\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1480.77346875\tTime: 0:00:00.014445\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1483.4808854166668\tTime: 0:00:00.082814\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1465.87078125\tTime: 0:00:00.014187\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1468.9457708333334\tTime: 0:00:00.083103\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1453.05059375\tTime: 0:00:00.014410\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1461.4594479166667\tTime: 0:00:00.084448\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1440.70046875\tTime: 0:00:00.011614\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1453.6483333333333\tTime: 0:00:00.082658\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1436.301875\tTime: 0:00:00.014883\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1446.2043854166666\tTime: 0:00:00.083102\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1430.52340625\tTime: 0:00:00.012106\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1443.2005\tTime: 0:00:00.084173\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1421.73090625\tTime: 0:00:00.011975\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1435.0035677083333\tTime: 0:00:00.083614\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1422.56825\tTime: 0:00:00.014445\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1428.69075\tTime: 0:00:00.084246\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1412.88915625\tTime: 0:00:00.014530\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1426.2526875\tTime: 0:00:00.084050\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1417.57034375\tTime: 0:00:00.014042\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1419.3301041666666\tTime: 0:00:00.083942\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1404.56175\tTime: 0:00:00.013495\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1419.3787552083334\tTime: 0:00:00.084313\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1403.87825\tTime: 0:00:00.011743\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1417.7824010416666\tTime: 0:00:00.084585\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1405.57753125\tTime: 0:00:00.012056\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1412.9843541666667\tTime: 0:00:00.081753\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1395.2948125\tTime: 0:00:00.011807\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1414.3265833333332\tTime: 0:00:00.085469\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1400.1059375\tTime: 0:00:00.012057\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1405.89984375\tTime: 0:00:00.082322\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1396.93346875\tTime: 0:00:00.011731\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1407.017203125\tTime: 0:00:00.088672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1394.8554375\tTime: 0:00:00.015115\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1400.0753645833333\tTime: 0:00:00.084696\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1392.3121875\tTime: 0:00:00.011746\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1397.91115625\tTime: 0:00:00.083360\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1395.53421875\tTime: 0:00:00.011981\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1397.0093229166666\tTime: 0:00:00.082564\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1388.88928125\tTime: 0:00:00.014426\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1395.5405104166666\tTime: 0:00:00.084182\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1390.52465625\tTime: 0:00:00.014857\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1394.61509375\tTime: 0:00:00.086094\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1386.9914375\tTime: 0:00:00.011821\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1389.54071875\tTime: 0:00:00.085920\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1387.69896875\tTime: 0:00:00.011984\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1392.6270833333333\tTime: 0:00:00.083376\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1384.3938125\tTime: 0:00:00.014484\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1387.7878333333333\tTime: 0:00:00.083494\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1386.7739375\tTime: 0:00:00.011951\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1389.21490625\tTime: 0:00:00.081739\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1385.39484375\tTime: 0:00:00.011699\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1387.8391666666666\tTime: 0:00:00.081655\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1384.39425\tTime: 0:00:00.011628\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1384.21696875\tTime: 0:00:00.086087\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1384.4980625\tTime: 0:00:00.012064\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1382.1864895833332\tTime: 0:00:00.082175\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1382.1035\tTime: 0:00:00.011695\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1384.513359375\tTime: 0:00:00.082305\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1383.11771875\tTime: 0:00:00.011968\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1383.0148177083333\tTime: 0:00:00.084414\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1377.25653125\tTime: 0:00:00.011676\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1386.7844895833334\tTime: 0:00:00.082898\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1383.0995625\tTime: 0:00:00.011827\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1379.12303125\tTime: 0:00:00.082538\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1380.962875\tTime: 0:00:00.011483\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1381.0561770833333\tTime: 0:00:00.082408\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1381.49034375\tTime: 0:00:00.012384\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1377.7615520833333\tTime: 0:00:00.084445\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1381.0898125\tTime: 0:00:00.011620\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1377.90259375\tTime: 0:00:00.083277\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1372.89459375\tTime: 0:00:00.011654\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1375.8803958333333\tTime: 0:00:00.083900\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1378.21765625\tTime: 0:00:00.011842\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1373.9688385416666\tTime: 0:00:00.083460\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1371.75503125\tTime: 0:00:00.011700\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1373.781421875\tTime: 0:00:00.082432\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1380.2984375\tTime: 0:00:00.011894\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1377.610875\tTime: 0:00:00.084463\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1371.76665625\tTime: 0:00:00.011883\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1371.4603489583333\tTime: 0:00:00.081980\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1376.4978125\tTime: 0:00:00.015594\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1373.2005364583333\tTime: 0:00:00.119708\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1376.32928125\tTime: 0:00:00.017743\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1370.4782395833333\tTime: 0:00:00.118685\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1372.38465625\tTime: 0:00:00.017933\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.49743865447138\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3300.5151429568423\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1674.4364166666667\tTime: 0:00:00.099916\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1571.807375\tTime: 0:00:00.014543\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1633.4898125\tTime: 0:00:00.100865\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1583.36440625\tTime: 0:00:00.014202\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1593.4915520833333\tTime: 0:00:00.103022\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1590.56015625\tTime: 0:00:00.018067\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1560.6122395833333\tTime: 0:00:00.105847\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1575.05946875\tTime: 0:00:00.013992\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1534.2028541666666\tTime: 0:00:00.101051\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1541.22440625\tTime: 0:00:00.014264\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1514.2992604166666\tTime: 0:00:00.099100\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1504.96628125\tTime: 0:00:00.014306\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1497.9235416666668\tTime: 0:00:00.100474\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1472.838375\tTime: 0:00:00.018027\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1482.454375\tTime: 0:00:00.102998\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1460.2120625\tTime: 0:00:00.017688\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1471.4583645833334\tTime: 0:00:00.101811\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1446.04246875\tTime: 0:00:00.014133\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1462.7973854166667\tTime: 0:00:00.098984\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1434.135125\tTime: 0:00:00.014094\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1452.6583229166667\tTime: 0:00:00.099856\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1433.24109375\tTime: 0:00:00.014210\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1453.0717291666667\tTime: 0:00:00.100709\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1423.6838125\tTime: 0:00:00.017876\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1442.09096875\tTime: 0:00:00.101401\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1417.543625\tTime: 0:00:00.014192\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1436.5064791666666\tTime: 0:00:00.100897\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1415.78665625\tTime: 0:00:00.014295\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1429.94171875\tTime: 0:00:00.100439\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1411.19359375\tTime: 0:00:00.014495\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1426.0029375\tTime: 0:00:00.098271\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1405.5125\tTime: 0:00:00.014563\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1421.7104375\tTime: 0:00:00.099606\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1403.29228125\tTime: 0:00:00.014685\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1420.5104739583333\tTime: 0:00:00.195519\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1403.28490625\tTime: 0:00:00.014407\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1413.64596875\tTime: 0:00:00.098363\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1400.8463125\tTime: 0:00:00.014228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1415.715890625\tTime: 0:00:00.103988\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1399.09784375\tTime: 0:00:00.014465\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1414.7850625\tTime: 0:00:00.099622\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1389.23190625\tTime: 0:00:00.014240\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1408.1757239583333\tTime: 0:00:00.101239\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1393.050125\tTime: 0:00:00.017987\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1406.1896614583334\tTime: 0:00:00.100190\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1383.79059375\tTime: 0:00:00.017466\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1399.7618645833334\tTime: 0:00:00.100875\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1389.79184375\tTime: 0:00:00.014594\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1399.8281041666667\tTime: 0:00:00.101317\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1386.02640625\tTime: 0:00:00.014129\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1394.7383125\tTime: 0:00:00.099695\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1383.76784375\tTime: 0:00:00.014274\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1392.379046875\tTime: 0:00:00.104064\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1379.88853125\tTime: 0:00:00.014072\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1394.416078125\tTime: 0:00:00.100995\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1379.30146875\tTime: 0:00:00.014404\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1393.9434479166666\tTime: 0:00:00.099344\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1388.23984375\tTime: 0:00:00.014280\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1393.3762604166666\tTime: 0:00:00.099234\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1384.80909375\tTime: 0:00:00.014406\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1388.0030729166667\tTime: 0:00:00.098851\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1381.3528125\tTime: 0:00:00.014291\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1386.0982916666667\tTime: 0:00:00.099395\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1377.40709375\tTime: 0:00:00.014399\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1389.0475260416667\tTime: 0:00:00.100321\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1376.95171875\tTime: 0:00:00.014145\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1385.8329427083333\tTime: 0:00:00.100733\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1375.46215625\tTime: 0:00:00.014616\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1386.843375\tTime: 0:00:00.103023\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1374.13103125\tTime: 0:00:00.015304\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1385.14009375\tTime: 0:00:00.099608\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1377.02621875\tTime: 0:00:00.014771\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1389.0407395833333\tTime: 0:00:00.099400\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1378.43675\tTime: 0:00:00.014067\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1388.1616145833334\tTime: 0:00:00.104142\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1372.41728125\tTime: 0:00:00.014291\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1380.6533802083334\tTime: 0:00:00.101510\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1373.2079375\tTime: 0:00:00.014483\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1382.2109166666667\tTime: 0:00:00.101145\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1372.23996875\tTime: 0:00:00.014734\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1380.1436979166667\tTime: 0:00:00.100422\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1374.88859375\tTime: 0:00:00.014366\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1380.037390625\tTime: 0:00:00.100550\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1372.14303125\tTime: 0:00:00.014453\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1375.2876875\tTime: 0:00:00.098406\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1375.02946875\tTime: 0:00:00.014205\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1378.63578125\tTime: 0:00:00.100112\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1374.1739375\tTime: 0:00:00.014561\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1373.8244166666666\tTime: 0:00:00.100805\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1375.031625\tTime: 0:00:00.014268\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1375.9156875\tTime: 0:00:00.100706\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1372.47540625\tTime: 0:00:00.014482\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1379.353203125\tTime: 0:00:00.098691\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1365.42296875\tTime: 0:00:00.011658\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1370.1801979166667\tTime: 0:00:00.085301\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1364.8915625\tTime: 0:00:00.014753\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1370.7340833333333\tTime: 0:00:00.083948\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1367.23028125\tTime: 0:00:00.014425\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1372.201\tTime: 0:00:00.084370\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1362.1525\tTime: 0:00:00.011890\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1375.1473541666667\tTime: 0:00:00.085800\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1366.9835625\tTime: 0:00:00.011736\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1368.5306354166667\tTime: 0:00:00.083709\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1369.18115625\tTime: 0:00:00.014630\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1374.118359375\tTime: 0:00:00.086873\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1362.8843125\tTime: 0:00:00.012578\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1370.8283020833333\tTime: 0:00:00.083497\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1364.653\tTime: 0:00:00.014920\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1372.26375\tTime: 0:00:00.085617\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1365.73390625\tTime: 0:00:00.011526\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.584986315630622\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3341.52895175097\u001b[0m\n",
      "Nodes averages betas and thetas inf:  6.54351305650348 3293.9468128197855\n",
      "BASELINE\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m770.0356102367481\u001b[0m\n",
      "Executing for frozen topics  10\n",
      "Shape of thetas_bas (5000, 50)\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 40.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 41.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 41.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 50)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1748.6543666666666\tTime: 0:00:00.439073\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1680.92076875\tTime: 0:00:00.059543\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1653.6874416666667\tTime: 0:00:00.434084\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1592.034165625\tTime: 0:00:00.059809\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1606.9286083333334\tTime: 0:00:00.431764\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1553.367121875\tTime: 0:00:00.058752\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1578.8554885416668\tTime: 0:00:00.432732\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1531.46578125\tTime: 0:00:00.061151\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1556.9756135416667\tTime: 0:00:00.445177\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1515.210765625\tTime: 0:00:00.059755\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1544.9083541666666\tTime: 0:00:00.513099\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1504.930684375\tTime: 0:00:00.077090\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1534.1995083333334\tTime: 0:00:00.514956\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1497.2317375\tTime: 0:00:00.076007\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1526.3510125\tTime: 0:00:00.501502\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1492.182653125\tTime: 0:00:00.076187\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1518.5873625\tTime: 0:00:00.515708\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1486.59314375\tTime: 0:00:00.075433\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1514.3006041666667\tTime: 0:00:00.478547\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1483.2817375\tTime: 0:00:00.061042\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1510.13330625\tTime: 0:00:00.440637\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1480.209875\tTime: 0:00:00.060360\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1507.5335364583334\tTime: 0:00:00.537715\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1474.08226875\tTime: 0:00:00.061514\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1500.3917375\tTime: 0:00:00.436278\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1469.46678125\tTime: 0:00:00.060525\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1497.4927322916667\tTime: 0:00:00.431215\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1466.30244375\tTime: 0:00:00.061427\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1495.8950739583333\tTime: 0:00:00.424301\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1462.630590625\tTime: 0:00:00.060488\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1494.6101333333334\tTime: 0:00:00.426258\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1459.116171875\tTime: 0:00:00.063981\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1488.8826833333333\tTime: 0:00:00.437900\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1457.50539375\tTime: 0:00:00.060557\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1487.2686635416667\tTime: 0:00:00.431396\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1452.017871875\tTime: 0:00:00.061240\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1486.229696875\tTime: 0:00:00.430982\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1453.424775\tTime: 0:00:00.061516\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1486.4337739583334\tTime: 0:00:00.426388\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1452.4695\tTime: 0:00:00.061925\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1482.3223822916666\tTime: 0:00:00.429904\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1452.3446\tTime: 0:00:00.060236\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1481.8589166666666\tTime: 0:00:00.429115\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1450.044225\tTime: 0:00:00.062286\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1483.009184375\tTime: 0:00:00.428807\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1447.61698125\tTime: 0:00:00.061403\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1479.6665395833334\tTime: 0:00:00.427539\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1449.79348125\tTime: 0:00:00.061719\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1478.1041979166666\tTime: 0:00:00.430444\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1446.05169375\tTime: 0:00:00.061547\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1479.3313729166666\tTime: 0:00:00.431376\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1445.28105625\tTime: 0:00:00.062032\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1476.1454739583332\tTime: 0:00:00.431597\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1444.299725\tTime: 0:00:00.061746\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1477.6920947916667\tTime: 0:00:00.428539\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1439.4752625\tTime: 0:00:00.062082\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1474.02779375\tTime: 0:00:00.429422\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1441.61904375\tTime: 0:00:00.061198\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1477.5006645833334\tTime: 0:00:00.437376\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1442.135484375\tTime: 0:00:00.061732\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1478.311684375\tTime: 0:00:00.433679\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1439.693525\tTime: 0:00:00.076089\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1475.2189104166666\tTime: 0:00:00.426228\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1439.727840625\tTime: 0:00:00.061534\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1472.5301666666667\tTime: 0:00:00.429511\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1440.23061875\tTime: 0:00:00.061051\n",
      "Early stopping\n",
      "MAX BETAS:  0.00039320334\n",
      "MIN BETAS:  0.000149142\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m8.499583087413269\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2491.5819564115645\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1702.8725208333333\tTime: 0:00:00.085497\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1600.059875\tTime: 0:00:00.012432\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1678.2916770833333\tTime: 0:00:00.082665\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1607.456125\tTime: 0:00:00.011875\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1644.2917604166666\tTime: 0:00:00.085681\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1620.32375\tTime: 0:00:00.012206\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1615.62071875\tTime: 0:00:00.085224\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1616.67465625\tTime: 0:00:00.012035\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1589.7499270833334\tTime: 0:00:00.082612\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1591.709125\tTime: 0:00:00.012737\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1570.1434375\tTime: 0:00:00.082625\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1560.7728125\tTime: 0:00:00.011991\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1554.2474895833334\tTime: 0:00:00.082642\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1533.3943125\tTime: 0:00:00.012015\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1544.8905833333333\tTime: 0:00:00.082815\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1523.98475\tTime: 0:00:00.011890\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1532.26778125\tTime: 0:00:00.083517\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1511.736875\tTime: 0:00:00.012026\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1524.98628125\tTime: 0:00:00.083979\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1504.0156875\tTime: 0:00:00.011850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1514.8390729166667\tTime: 0:00:00.083294\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1494.41596875\tTime: 0:00:00.012039\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1509.36465625\tTime: 0:00:00.082349\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1489.1935\tTime: 0:00:00.011970\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1504.5618229166666\tTime: 0:00:00.084143\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1475.1125625\tTime: 0:00:00.011936\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1495.9048333333333\tTime: 0:00:00.084775\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1481.95325\tTime: 0:00:00.011812\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1493.5535625\tTime: 0:00:00.083866\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1468.9575625\tTime: 0:00:00.011994\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1481.77853125\tTime: 0:00:00.082742\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1471.1155\tTime: 0:00:00.011954\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1482.12103125\tTime: 0:00:00.085450\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1468.1131875\tTime: 0:00:00.012082\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1478.2964583333332\tTime: 0:00:00.082980\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1463.51553125\tTime: 0:00:00.011981\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1477.2480208333334\tTime: 0:00:00.083493\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1464.229875\tTime: 0:00:00.012014\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1464.7337083333334\tTime: 0:00:00.082987\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1456.42984375\tTime: 0:00:00.011885\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1462.9596354166667\tTime: 0:00:00.084536\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1462.131\tTime: 0:00:00.011913\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1464.25103125\tTime: 0:00:00.082810\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1457.35325\tTime: 0:00:00.011794\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1460.3169791666667\tTime: 0:00:00.082583\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1448.60315625\tTime: 0:00:00.012815\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1456.26121875\tTime: 0:00:00.082973\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1444.7014375\tTime: 0:00:00.011665\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1456.387875\tTime: 0:00:00.084918\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1449.305875\tTime: 0:00:00.014582\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1449.8491458333333\tTime: 0:00:00.084103\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1444.5829375\tTime: 0:00:00.011923\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1448.8856354166667\tTime: 0:00:00.083079\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1440.82453125\tTime: 0:00:00.011874\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1452.20990625\tTime: 0:00:00.084333\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1442.2980625\tTime: 0:00:00.011998\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1451.1062395833333\tTime: 0:00:00.085777\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1437.50003125\tTime: 0:00:00.012006\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1440.4193125\tTime: 0:00:00.082359\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1435.235625\tTime: 0:00:00.011782\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1438.7469166666667\tTime: 0:00:00.084205\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1438.56459375\tTime: 0:00:00.012638\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1441.6587395833333\tTime: 0:00:00.086441\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1437.57946875\tTime: 0:00:00.011845\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1435.4990260416666\tTime: 0:00:00.083065\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1438.5995\tTime: 0:00:00.012181\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1440.55315625\tTime: 0:00:00.084638\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1436.935875\tTime: 0:00:00.011923\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1438.8891875\tTime: 0:00:00.083625\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1430.4718125\tTime: 0:00:00.011836\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1429.9706145833334\tTime: 0:00:00.082990\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1434.3844375\tTime: 0:00:00.012329\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1433.6007916666667\tTime: 0:00:00.082461\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1432.43265625\tTime: 0:00:00.011761\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1423.9410416666667\tTime: 0:00:00.083919\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1433.0568125\tTime: 0:00:00.015305\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1431.4960104166666\tTime: 0:00:00.085871\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1429.962875\tTime: 0:00:00.011815\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1428.14190625\tTime: 0:00:00.083411\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1427.25165625\tTime: 0:00:00.012201\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1431.8154583333333\tTime: 0:00:00.083740\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1431.02678125\tTime: 0:00:00.011732\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1428.4081822916667\tTime: 0:00:00.086122\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1423.96196875\tTime: 0:00:00.012094\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1422.3290729166667\tTime: 0:00:00.083367\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1426.46275\tTime: 0:00:00.014711\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1425.39865625\tTime: 0:00:00.086571\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1423.4268125\tTime: 0:00:00.014708\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1426.258\tTime: 0:00:00.088423\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1426.05028125\tTime: 0:00:00.012127\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1428.02121875\tTime: 0:00:00.085735\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1426.12271875\tTime: 0:00:00.012115\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1420.4112708333334\tTime: 0:00:00.082436\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1422.87290625\tTime: 0:00:00.012046\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1426.5114166666667\tTime: 0:00:00.083541\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1425.1554375\tTime: 0:00:00.012227\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1420.5462395833333\tTime: 0:00:00.084355\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1422.59265625\tTime: 0:00:00.012480\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1420.1090572916667\tTime: 0:00:00.085023\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1423.4561875\tTime: 0:00:00.012309\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1419.4650104166667\tTime: 0:00:00.084977\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1423.87334375\tTime: 0:00:00.011883\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1414.0988333333332\tTime: 0:00:00.084223\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1420.27328125\tTime: 0:00:00.012467\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1421.8784375\tTime: 0:00:00.082972\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1419.75075\tTime: 0:00:00.011855\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1412.8227604166666\tTime: 0:00:00.085350\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1421.23178125\tTime: 0:00:00.014824\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1417.2262916666666\tTime: 0:00:00.083785\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1422.4774375\tTime: 0:00:00.011732\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1415.825578125\tTime: 0:00:00.082294\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1420.53025\tTime: 0:00:00.012835\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1416.839421875\tTime: 0:00:00.083132\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1418.1499375\tTime: 0:00:00.011811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1410.5707760416667\tTime: 0:00:00.083840\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1421.67459375\tTime: 0:00:00.012120\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1413.58021875\tTime: 0:00:00.085080\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1422.536\tTime: 0:00:00.011825\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1414.2512916666667\tTime: 0:00:00.085942\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1419.51953125\tTime: 0:00:00.013508\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1412.1225520833334\tTime: 0:00:00.082785\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1418.7099375\tTime: 0:00:00.011814\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1411.8068541666667\tTime: 0:00:00.082581\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1416.0589375\tTime: 0:00:00.012022\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1414.3453125\tTime: 0:00:00.084779\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1418.50903125\tTime: 0:00:00.012233\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1414.0964947916666\tTime: 0:00:00.082700\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1421.063\tTime: 0:00:00.011954\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1411.7616145833333\tTime: 0:00:00.081965\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1417.96659375\tTime: 0:00:00.012524\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1409.31771875\tTime: 0:00:00.083063\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1421.0429375\tTime: 0:00:00.011826\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1409.8112395833334\tTime: 0:00:00.083647\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1421.77828125\tTime: 0:00:00.011814\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.877296099459672\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2908.698761952916\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1697.9986354166667\tTime: 0:00:00.087237\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1577.71290625\tTime: 0:00:00.015007\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1669.94903125\tTime: 0:00:00.084117\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1585.62809375\tTime: 0:00:00.011779\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1634.7019166666666\tTime: 0:00:00.087874\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1593.2976875\tTime: 0:00:00.011860\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1603.07046875\tTime: 0:00:00.086813\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1583.42621875\tTime: 0:00:00.014397\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1575.8273541666667\tTime: 0:00:00.085311\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1560.3641875\tTime: 0:00:00.015082\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1559.9965208333333\tTime: 0:00:00.087202\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1528.2846875\tTime: 0:00:00.011789\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1540.5808958333334\tTime: 0:00:00.086970\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1508.12525\tTime: 0:00:00.012084\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1529.6507604166666\tTime: 0:00:00.088280\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1492.8704375\tTime: 0:00:00.012028\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1523.12809375\tTime: 0:00:00.088340\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1482.10009375\tTime: 0:00:00.011754\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1506.3260833333334\tTime: 0:00:00.084828\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1474.9304375\tTime: 0:00:00.011635\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1505.8242395833333\tTime: 0:00:00.087307\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1467.64065625\tTime: 0:00:00.011855\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1499.4806458333333\tTime: 0:00:00.084330\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1458.3074375\tTime: 0:00:00.011812\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1489.138875\tTime: 0:00:00.088404\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1455.52571875\tTime: 0:00:00.011880\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1487.2860729166666\tTime: 0:00:00.087607\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1453.55946875\tTime: 0:00:00.011711\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1482.06234375\tTime: 0:00:00.085978\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1447.21990625\tTime: 0:00:00.012107\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1478.5153541666666\tTime: 0:00:00.086255\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1443.00909375\tTime: 0:00:00.014460\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1468.68921875\tTime: 0:00:00.084565\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1437.97390625\tTime: 0:00:00.012147\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1469.1879791666668\tTime: 0:00:00.085085\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1435.56090625\tTime: 0:00:00.012074\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1463.20965625\tTime: 0:00:00.089802\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1432.766125\tTime: 0:00:00.012109\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1456.1495208333333\tTime: 0:00:00.085465\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1427.4070625\tTime: 0:00:00.011560\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1456.3532916666666\tTime: 0:00:00.087725\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1426.41525\tTime: 0:00:00.011860\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1455.4940052083334\tTime: 0:00:00.085113\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1428.3201875\tTime: 0:00:00.014442\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1451.3570104166668\tTime: 0:00:00.086888\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1422.69790625\tTime: 0:00:00.011960\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1448.5663229166666\tTime: 0:00:00.085230\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1420.24790625\tTime: 0:00:00.014558\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1443.7667708333333\tTime: 0:00:00.085571\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1420.95715625\tTime: 0:00:00.014733\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1442.9417708333333\tTime: 0:00:00.087696\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1419.9708125\tTime: 0:00:00.014284\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1445.0082708333334\tTime: 0:00:00.086507\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1418.98009375\tTime: 0:00:00.014547\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1439.8812291666666\tTime: 0:00:00.086594\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1415.39446875\tTime: 0:00:00.011895\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1440.82796875\tTime: 0:00:00.087512\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1416.39165625\tTime: 0:00:00.011992\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1432.6189114583333\tTime: 0:00:00.084787\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1413.96903125\tTime: 0:00:00.014360\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1436.5844791666666\tTime: 0:00:00.087412\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1415.79209375\tTime: 0:00:00.011948\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1434.9521666666667\tTime: 0:00:00.084962\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1411.5294375\tTime: 0:00:00.014544\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1433.6290989583333\tTime: 0:00:00.088539\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1411.93696875\tTime: 0:00:00.011944\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1434.8115208333334\tTime: 0:00:00.086926\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1405.98684375\tTime: 0:00:00.011719\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1426.6618854166666\tTime: 0:00:00.085117\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1404.3243125\tTime: 0:00:00.014602\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1427.5085\tTime: 0:00:00.087229\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1406.3028125\tTime: 0:00:00.014496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1423.6229270833333\tTime: 0:00:00.089454\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1408.0301875\tTime: 0:00:00.012125\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1422.8048854166666\tTime: 0:00:00.085088\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1404.12859375\tTime: 0:00:00.014630\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1425.1451354166666\tTime: 0:00:00.086835\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1405.84328125\tTime: 0:00:00.014697\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1421.5610416666666\tTime: 0:00:00.084917\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1402.170375\tTime: 0:00:00.014418\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1426.46684375\tTime: 0:00:00.100010\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1404.76459375\tTime: 0:00:00.014425\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1419.406609375\tTime: 0:00:00.099998\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1402.717375\tTime: 0:00:00.014268\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1418.8786145833333\tTime: 0:00:00.100895\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1404.16321875\tTime: 0:00:00.014658\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1419.171984375\tTime: 0:00:00.092005\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1398.16278125\tTime: 0:00:00.011783\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1414.9418541666666\tTime: 0:00:00.088647\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1395.37940625\tTime: 0:00:00.011961\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1416.0070677083334\tTime: 0:00:00.087693\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1395.04378125\tTime: 0:00:00.014404\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1414.9310520833333\tTime: 0:00:00.089753\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1395.9355\tTime: 0:00:00.012005\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1410.5153385416668\tTime: 0:00:00.084727\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1397.496875\tTime: 0:00:00.011785\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1411.9131770833333\tTime: 0:00:00.087203\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1397.3845\tTime: 0:00:00.012705\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1413.5521770833334\tTime: 0:00:00.086504\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1392.6191875\tTime: 0:00:00.011648\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1415.2831875\tTime: 0:00:00.086859\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1394.86625\tTime: 0:00:00.012133\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1419.3049791666667\tTime: 0:00:00.086055\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1390.9075625\tTime: 0:00:00.011777\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1413.1194322916667\tTime: 0:00:00.083755\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1396.02540625\tTime: 0:00:00.011981\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1411.0178958333333\tTime: 0:00:00.087368\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1394.642125\tTime: 0:00:00.011717\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1409.2116041666666\tTime: 0:00:00.088148\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1392.27771875\tTime: 0:00:00.014884\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1407.71396875\tTime: 0:00:00.084723\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1391.45409375\tTime: 0:00:00.011733\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1411.769203125\tTime: 0:00:00.084173\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1390.1358125\tTime: 0:00:00.011761\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1403.25184375\tTime: 0:00:00.085155\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1392.71490625\tTime: 0:00:00.014567\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1407.4525729166667\tTime: 0:00:00.088120\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1393.15478125\tTime: 0:00:00.011633\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1407.341703125\tTime: 0:00:00.086246\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1393.40903125\tTime: 0:00:00.014695\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1405.8666510416667\tTime: 0:00:00.087940\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1388.1915625\tTime: 0:00:00.014350\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1407.5931666666668\tTime: 0:00:00.090617\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1388.017\tTime: 0:00:00.012198\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1401.64340625\tTime: 0:00:00.086026\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1387.7006875\tTime: 0:00:00.011556\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1406.1779322916666\tTime: 0:00:00.087030\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1390.8319375\tTime: 0:00:00.012154\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1405.6088854166667\tTime: 0:00:00.084139\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1390.3835\tTime: 0:00:00.011817\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1401.915765625\tTime: 0:00:00.085468\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1391.993125\tTime: 0:00:00.015188\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1403.2269375\tTime: 0:00:00.088127\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1391.73871875\tTime: 0:00:00.011845\n",
      "Epoch: [68/100]\tSamples: [51000/75000]\tTrain Loss: 1405.7858229166666\tTime: 0:00:00.087259\n",
      "Epoch: [68/100]\tSamples: [250/25000]\tValidation Loss: 1391.99140625\tTime: 0:00:00.015364\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.8538593242844215\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2974.0148869436794\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1728.7710520833334\tTime: 0:00:00.088918\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1614.30115625\tTime: 0:00:00.011724\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1697.7227604166667\tTime: 0:00:00.082897\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1622.40734375\tTime: 0:00:00.011496\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1661.8268645833334\tTime: 0:00:00.084121\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1629.227875\tTime: 0:00:00.011715\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1630.4752395833334\tTime: 0:00:00.086727\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1619.65709375\tTime: 0:00:00.014250\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1606.4407604166668\tTime: 0:00:00.180927\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1597.62690625\tTime: 0:00:00.011709\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1584.7798645833334\tTime: 0:00:00.083439\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1564.1685\tTime: 0:00:00.014024\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1570.524125\tTime: 0:00:00.084798\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1535.24625\tTime: 0:00:00.012428\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1556.0393229166666\tTime: 0:00:00.083225\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1519.33728125\tTime: 0:00:00.014275\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1544.63403125\tTime: 0:00:00.086083\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1513.0661875\tTime: 0:00:00.014156\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1538.7006145833334\tTime: 0:00:00.084182\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1503.58490625\tTime: 0:00:00.011637\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1527.5863229166666\tTime: 0:00:00.086440\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1496.869\tTime: 0:00:00.011874\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1523.1078645833334\tTime: 0:00:00.085261\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1489.191875\tTime: 0:00:00.014054\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1514.6376875\tTime: 0:00:00.084860\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1485.61240625\tTime: 0:00:00.014211\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1508.6937604166667\tTime: 0:00:00.085865\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1476.77196875\tTime: 0:00:00.014236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1503.3014791666667\tTime: 0:00:00.090689\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1471.81209375\tTime: 0:00:00.014198\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1499.8265520833334\tTime: 0:00:00.085258\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1460.88978125\tTime: 0:00:00.011574\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1496.4411041666667\tTime: 0:00:00.084808\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1463.16403125\tTime: 0:00:00.014208\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1492.5384895833333\tTime: 0:00:00.087580\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1461.22753125\tTime: 0:00:00.011783\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1488.1806979166668\tTime: 0:00:00.082579\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1460.6484375\tTime: 0:00:00.012157\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1480.8386979166667\tTime: 0:00:00.087032\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1454.0371875\tTime: 0:00:00.011414\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1474.6318541666667\tTime: 0:00:00.086034\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1452.9115\tTime: 0:00:00.011748\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1479.7704270833333\tTime: 0:00:00.085410\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1444.59409375\tTime: 0:00:00.014008\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1475.2105729166667\tTime: 0:00:00.086658\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1445.83846875\tTime: 0:00:00.011693\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1472.9129166666667\tTime: 0:00:00.084426\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1440.73740625\tTime: 0:00:00.014273\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1472.7006875\tTime: 0:00:00.085399\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1440.80421875\tTime: 0:00:00.011940\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1470.4135625\tTime: 0:00:00.085774\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1439.4059375\tTime: 0:00:00.011574\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1461.7345729166666\tTime: 0:00:00.085706\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1439.53890625\tTime: 0:00:00.014424\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1464.8139895833333\tTime: 0:00:00.084510\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1428.29596875\tTime: 0:00:00.011603\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1461.7654375\tTime: 0:00:00.084026\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1440.455875\tTime: 0:00:00.011737\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1458.4758854166666\tTime: 0:00:00.099414\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1434.68884375\tTime: 0:00:00.013936\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1458.8656458333332\tTime: 0:00:00.097765\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1438.005625\tTime: 0:00:00.014546\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1454.1197291666667\tTime: 0:00:00.089823\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1431.7271875\tTime: 0:00:00.011379\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1453.5610104166667\tTime: 0:00:00.085125\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1430.380375\tTime: 0:00:00.011761\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.954150939319833\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2828.405525948359\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1700.2036770833333\tTime: 0:00:00.085586\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1577.4941875\tTime: 0:00:00.014756\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1672.1621875\tTime: 0:00:00.083793\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1585.51025\tTime: 0:00:00.011722\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1639.0181354166666\tTime: 0:00:00.086318\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1592.29890625\tTime: 0:00:00.012091\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1612.14690625\tTime: 0:00:00.085688\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1585.16503125\tTime: 0:00:00.014699\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1585.2406041666666\tTime: 0:00:00.084058\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1561.8605\tTime: 0:00:00.014997\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1565.5843125\tTime: 0:00:00.086010\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1533.66275\tTime: 0:00:00.011799\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1546.1131770833333\tTime: 0:00:00.086879\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1506.736\tTime: 0:00:00.014473\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1536.71115625\tTime: 0:00:00.087684\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1491.25153125\tTime: 0:00:00.011852\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1522.4967708333334\tTime: 0:00:00.084950\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1485.10575\tTime: 0:00:00.014580\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1514.8538958333334\tTime: 0:00:00.085979\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1469.2744375\tTime: 0:00:00.014725\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1502.7118645833334\tTime: 0:00:00.086385\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1467.27596875\tTime: 0:00:00.012166\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1497.54265625\tTime: 0:00:00.085640\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1460.2201875\tTime: 0:00:00.011806\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1493.4373333333333\tTime: 0:00:00.083737\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1459.2981875\tTime: 0:00:00.014777\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1482.2053333333333\tTime: 0:00:00.083912\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1446.738125\tTime: 0:00:00.014385\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1483.86484375\tTime: 0:00:00.085267\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1441.8224375\tTime: 0:00:00.014555\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1475.90034375\tTime: 0:00:00.085367\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1437.39690625\tTime: 0:00:00.014577\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1472.8668125\tTime: 0:00:00.084058\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1432.02528125\tTime: 0:00:00.016434\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1466.2298229166668\tTime: 0:00:00.085867\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1428.26903125\tTime: 0:00:00.011815\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1458.9396979166668\tTime: 0:00:00.083577\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1428.05428125\tTime: 0:00:00.012136\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1456.5822708333333\tTime: 0:00:00.085461\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1420.501125\tTime: 0:00:00.014354\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1456.97215625\tTime: 0:00:00.085227\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1419.9228125\tTime: 0:00:00.012221\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1452.3810208333334\tTime: 0:00:00.084334\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1418.8465\tTime: 0:00:00.011812\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1448.63015625\tTime: 0:00:00.083543\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1418.50296875\tTime: 0:00:00.012126\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1449.49159375\tTime: 0:00:00.083947\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1413.29140625\tTime: 0:00:00.011784\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1440.030046875\tTime: 0:00:00.084686\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1413.17271875\tTime: 0:00:00.012921\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1445.7766041666666\tTime: 0:00:00.084349\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1413.37340625\tTime: 0:00:00.011729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1441.85684375\tTime: 0:00:00.084525\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1409.42525\tTime: 0:00:00.012045\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1443.2652395833334\tTime: 0:00:00.084583\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1404.657125\tTime: 0:00:00.014408\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1433.874375\tTime: 0:00:00.084860\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1406.58853125\tTime: 0:00:00.012139\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1434.0292916666667\tTime: 0:00:00.085932\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1405.92296875\tTime: 0:00:00.011833\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1430.6100520833334\tTime: 0:00:00.083033\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1404.43153125\tTime: 0:00:00.012690\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1431.7517552083334\tTime: 0:00:00.085294\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1404.003125\tTime: 0:00:00.011695\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1429.67775\tTime: 0:00:00.084647\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1411.74121875\tTime: 0:00:00.012080\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1420.8721041666668\tTime: 0:00:00.083224\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1406.15515625\tTime: 0:00:00.011844\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1423.3593541666667\tTime: 0:00:00.084237\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1404.5133125\tTime: 0:00:00.015325\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1422.380125\tTime: 0:00:00.089275\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1400.71428125\tTime: 0:00:00.011832\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1422.6018854166666\tTime: 0:00:00.086731\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1397.6245625\tTime: 0:00:00.012159\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1419.93425\tTime: 0:00:00.085959\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1402.87565625\tTime: 0:00:00.014683\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1417.0329270833333\tTime: 0:00:00.091803\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1398.73809375\tTime: 0:00:00.012181\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1418.8566145833333\tTime: 0:00:00.082818\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1394.6254375\tTime: 0:00:00.011701\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1418.3718854166666\tTime: 0:00:00.085352\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1404.81321875\tTime: 0:00:00.012292\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1416.5027760416667\tTime: 0:00:00.086190\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1400.15003125\tTime: 0:00:00.014549\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1415.6506666666667\tTime: 0:00:00.087884\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1401.93446875\tTime: 0:00:00.012054\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1415.0208177083334\tTime: 0:00:00.084869\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1397.807125\tTime: 0:00:00.014563\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1411.2990208333333\tTime: 0:00:00.086704\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1396.1553125\tTime: 0:00:00.015112\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.854722565996908\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2746.159553201004\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1714.0504895833333\tTime: 0:00:00.082054\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1589.13425\tTime: 0:00:00.011656\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1686.47840625\tTime: 0:00:00.081649\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1597.8123125\tTime: 0:00:00.011297\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1653.84146875\tTime: 0:00:00.081478\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1610.99303125\tTime: 0:00:00.011684\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1623.7397083333333\tTime: 0:00:00.082601\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1604.16809375\tTime: 0:00:00.011337\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1596.71134375\tTime: 0:00:00.080999\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1577.12615625\tTime: 0:00:00.011515\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1576.8215\tTime: 0:00:00.081696\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1547.46171875\tTime: 0:00:00.011948\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1558.3071145833333\tTime: 0:00:00.081349\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1521.64740625\tTime: 0:00:00.011338\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1550.0264166666666\tTime: 0:00:00.082956\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1501.105875\tTime: 0:00:00.011669\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1534.2075\tTime: 0:00:00.082636\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1490.65290625\tTime: 0:00:00.011363\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1526.718\tTime: 0:00:00.082022\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1484.53503125\tTime: 0:00:00.011629\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1518.1814166666666\tTime: 0:00:00.084293\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1474.6304375\tTime: 0:00:00.011296\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1507.7597083333333\tTime: 0:00:00.081411\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1469.469125\tTime: 0:00:00.011677\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1505.9781666666668\tTime: 0:00:00.083961\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1461.0924375\tTime: 0:00:00.014023\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1499.2441770833334\tTime: 0:00:00.082903\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1455.94071875\tTime: 0:00:00.011784\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1491.80515625\tTime: 0:00:00.081276\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1448.13175\tTime: 0:00:00.011365\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1489.1856354166666\tTime: 0:00:00.083108\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1445.68690625\tTime: 0:00:00.011692\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1483.0074166666666\tTime: 0:00:00.081186\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1446.65975\tTime: 0:00:00.011604\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1485.8646145833334\tTime: 0:00:00.083670\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1436.80984375\tTime: 0:00:00.014450\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1472.7145416666667\tTime: 0:00:00.083465\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1434.2554375\tTime: 0:00:00.011325\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1469.6834479166666\tTime: 0:00:00.084699\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1430.81703125\tTime: 0:00:00.012062\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1464.9871875\tTime: 0:00:00.081582\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1429.38265625\tTime: 0:00:00.013866\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1464.6997395833334\tTime: 0:00:00.082623\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1422.24815625\tTime: 0:00:00.011915\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1463.695625\tTime: 0:00:00.083436\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1421.8309375\tTime: 0:00:00.011354\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1457.3869166666666\tTime: 0:00:00.081488\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1418.34140625\tTime: 0:00:00.011616\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1455.10521875\tTime: 0:00:00.083059\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1416.91240625\tTime: 0:00:00.011573\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1453.224\tTime: 0:00:00.083672\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1418.88103125\tTime: 0:00:00.011476\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1448.5374739583333\tTime: 0:00:00.083406\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1411.2768125\tTime: 0:00:00.012149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1449.7818020833333\tTime: 0:00:00.084056\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1411.2675\tTime: 0:00:00.011684\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1446.7981927083333\tTime: 0:00:00.081353\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1407.47059375\tTime: 0:00:00.011431\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1443.0095416666666\tTime: 0:00:00.083654\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1415.2958125\tTime: 0:00:00.011835\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1447.3311666666666\tTime: 0:00:00.080800\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1406.52346875\tTime: 0:00:00.011405\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1439.8180520833334\tTime: 0:00:00.081898\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1411.15740625\tTime: 0:00:00.011628\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1443.4343958333334\tTime: 0:00:00.081058\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1407.180375\tTime: 0:00:00.011852\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1438.25646875\tTime: 0:00:00.082529\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1407.3268125\tTime: 0:00:00.011503\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1437.3992395833334\tTime: 0:00:00.082308\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1405.99865625\tTime: 0:00:00.011665\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1440.5339791666668\tTime: 0:00:00.081522\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1405.21346875\tTime: 0:00:00.011307\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1431.6023385416668\tTime: 0:00:00.082262\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1402.73825\tTime: 0:00:00.011822\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1432.5866875\tTime: 0:00:00.080592\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1407.368625\tTime: 0:00:00.011385\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1429.5580625\tTime: 0:00:00.082382\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1406.798\tTime: 0:00:00.014000\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1433.8172708333334\tTime: 0:00:00.083190\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1402.24390625\tTime: 0:00:00.011851\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1432.9516145833334\tTime: 0:00:00.081788\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1410.63353125\tTime: 0:00:00.011565\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1429.1521666666667\tTime: 0:00:00.081517\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1403.127\tTime: 0:00:00.011503\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1428.3830104166666\tTime: 0:00:00.082446\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1401.8525\tTime: 0:00:00.011461\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1426.2543854166668\tTime: 0:00:00.082132\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1401.7763125\tTime: 0:00:00.011642\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1426.57478125\tTime: 0:00:00.083784\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1401.9445625\tTime: 0:00:00.011416\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1430.3192291666667\tTime: 0:00:00.082139\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1401.12653125\tTime: 0:00:00.011663\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1423.5529479166667\tTime: 0:00:00.081454\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1398.92865625\tTime: 0:00:00.011365\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1423.48740625\tTime: 0:00:00.081508\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1400.75603125\tTime: 0:00:00.011689\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1422.9569479166666\tTime: 0:00:00.081121\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1399.42740625\tTime: 0:00:00.011478\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1424.326765625\tTime: 0:00:00.081019\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1402.68946875\tTime: 0:00:00.011961\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1419.963265625\tTime: 0:00:00.081547\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1401.38134375\tTime: 0:00:00.011602\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1425.057109375\tTime: 0:00:00.080500\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1400.6936875\tTime: 0:00:00.011505\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.890455336636661\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2883.1757757931264\u001b[0m\n",
      "Nodes averages betas and thetas inf:  6.886096853139499 2868.0909007678174\n",
      "BASELINE\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m839.9446312942254\u001b[0m\n",
      "Executing for frozen topics  15\n",
      "Shape of thetas_bas (5000, 50)\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 41.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 41.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 41.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 40.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 40.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 50)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1756.98844375\tTime: 0:00:00.446861\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1679.587328125\tTime: 0:00:00.060101\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1670.81215625\tTime: 0:00:00.436473\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1594.641328125\tTime: 0:00:00.061439\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1629.8953427083334\tTime: 0:00:00.448639\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1566.410359375\tTime: 0:00:00.060722\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1605.440825\tTime: 0:00:00.443684\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1548.500265625\tTime: 0:00:00.061695\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1589.8961208333333\tTime: 0:00:00.453916\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1540.642503125\tTime: 0:00:00.061278\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1577.6112760416668\tTime: 0:00:00.447136\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1530.745128125\tTime: 0:00:00.061803\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1568.06229375\tTime: 0:00:00.464263\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1524.17344375\tTime: 0:00:00.079161\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1560.346621875\tTime: 0:00:00.447198\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1519.31076875\tTime: 0:00:00.061267\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1553.5274333333334\tTime: 0:00:00.449469\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1510.97018125\tTime: 0:00:00.060731\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1547.2136416666667\tTime: 0:00:00.445629\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1505.519303125\tTime: 0:00:00.061444\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1542.2776791666668\tTime: 0:00:00.441539\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1501.489815625\tTime: 0:00:00.060713\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1536.1337104166666\tTime: 0:00:00.446806\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1495.5219125\tTime: 0:00:00.061116\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1533.072265625\tTime: 0:00:00.452518\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1490.689846875\tTime: 0:00:00.061534\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1529.5982354166667\tTime: 0:00:00.460792\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1489.9495125\tTime: 0:00:00.061160\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1525.9756052083333\tTime: 0:00:00.551727\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1489.94774375\tTime: 0:00:00.061432\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1524.1939489583333\tTime: 0:00:00.444389\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1484.971759375\tTime: 0:00:00.061628\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1520.7582114583333\tTime: 0:00:00.457899\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1478.53744375\tTime: 0:00:00.060024\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1519.2533260416667\tTime: 0:00:00.452151\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1480.12003125\tTime: 0:00:00.062413\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1515.923309375\tTime: 0:00:00.452853\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1472.663128125\tTime: 0:00:00.061062\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1515.0892708333333\tTime: 0:00:00.448374\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1477.2410625\tTime: 0:00:00.070085\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1514.7486125\tTime: 0:00:00.449725\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1475.861559375\tTime: 0:00:00.065866\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1510.2651239583333\tTime: 0:00:00.452587\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1470.472984375\tTime: 0:00:00.061510\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1509.4775135416667\tTime: 0:00:00.446682\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1472.357940625\tTime: 0:00:00.060893\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1507.9094979166666\tTime: 0:00:00.448387\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1469.198359375\tTime: 0:00:00.061102\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1509.9054083333333\tTime: 0:00:00.447282\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1471.98575\tTime: 0:00:00.062059\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1504.5613583333334\tTime: 0:00:00.452316\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1468.998975\tTime: 0:00:00.063360\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1505.3713416666667\tTime: 0:00:00.454529\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1467.867025\tTime: 0:00:00.060580\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1504.2759822916667\tTime: 0:00:00.458894\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1466.602090625\tTime: 0:00:00.062076\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1505.6105458333334\tTime: 0:00:00.446863\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1467.701665625\tTime: 0:00:00.061302\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1501.9358833333333\tTime: 0:00:00.452546\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1462.7831625\tTime: 0:00:00.061089\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1502.2214958333334\tTime: 0:00:00.449512\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1466.302475\tTime: 0:00:00.061897\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1499.7408364583334\tTime: 0:00:00.450842\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1463.3691375\tTime: 0:00:00.062657\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1504.21180625\tTime: 0:00:00.451759\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1465.73601875\tTime: 0:00:00.062616\n",
      "Epoch: [34/100]\tSamples: [127500/375000]\tTrain Loss: 1501.6508197916667\tTime: 0:00:00.447327\n",
      "Epoch: [34/100]\tSamples: [1250/125000]\tValidation Loss: 1461.754453125\tTime: 0:00:00.061485\n",
      "Epoch: [35/100]\tSamples: [131250/375000]\tTrain Loss: 1499.4845854166667\tTime: 0:00:00.453259\n",
      "Epoch: [35/100]\tSamples: [1250/125000]\tValidation Loss: 1461.329284375\tTime: 0:00:00.061693\n",
      "Epoch: [36/100]\tSamples: [135000/375000]\tTrain Loss: 1499.155428125\tTime: 0:00:00.451567\n",
      "Epoch: [36/100]\tSamples: [1250/125000]\tValidation Loss: 1459.13128125\tTime: 0:00:00.061245\n",
      "Epoch: [37/100]\tSamples: [138750/375000]\tTrain Loss: 1498.968975\tTime: 0:00:00.449987\n",
      "Epoch: [37/100]\tSamples: [1250/125000]\tValidation Loss: 1459.320578125\tTime: 0:00:00.062231\n",
      "Epoch: [38/100]\tSamples: [142500/375000]\tTrain Loss: 1498.77276875\tTime: 0:00:00.507143\n",
      "Epoch: [38/100]\tSamples: [1250/125000]\tValidation Loss: 1465.320340625\tTime: 0:00:00.077459\n",
      "Epoch: [39/100]\tSamples: [146250/375000]\tTrain Loss: 1497.7324927083334\tTime: 0:00:00.526537\n",
      "Epoch: [39/100]\tSamples: [1250/125000]\tValidation Loss: 1463.98405625\tTime: 0:00:00.078716\n",
      "Epoch: [40/100]\tSamples: [150000/375000]\tTrain Loss: 1498.4125625\tTime: 0:00:00.454584\n",
      "Epoch: [40/100]\tSamples: [1250/125000]\tValidation Loss: 1460.686928125\tTime: 0:00:00.061347\n",
      "Epoch: [41/100]\tSamples: [153750/375000]\tTrain Loss: 1498.6549572916667\tTime: 0:00:00.448943\n",
      "Epoch: [41/100]\tSamples: [1250/125000]\tValidation Loss: 1461.954775\tTime: 0:00:00.062476\n",
      "Early stopping\n",
      "MAX BETAS:  0.00040632227\n",
      "MIN BETAS:  0.00014119889\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m8.503066902676839\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2429.6658153526905\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1734.7679166666667\tTime: 0:00:00.085151\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1605.8319375\tTime: 0:00:00.015123\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1711.8763333333334\tTime: 0:00:00.086708\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1611.02646875\tTime: 0:00:00.011898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1685.4216770833334\tTime: 0:00:00.087939\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1621.472875\tTime: 0:00:00.014910\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1660.3439479166666\tTime: 0:00:00.084971\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1617.12203125\tTime: 0:00:00.012069\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1634.9345\tTime: 0:00:00.086659\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1599.6018125\tTime: 0:00:00.012645\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1614.6361770833332\tTime: 0:00:00.084306\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1582.757\tTime: 0:00:00.014707\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1599.4869479166666\tTime: 0:00:00.085892\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1560.2925625\tTime: 0:00:00.012123\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1590.0615416666667\tTime: 0:00:00.083976\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1550.28059375\tTime: 0:00:00.011900\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1580.0996458333334\tTime: 0:00:00.090702\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1542.33290625\tTime: 0:00:00.014959\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1567.9899270833334\tTime: 0:00:00.084463\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1531.64178125\tTime: 0:00:00.012226\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1563.2214895833333\tTime: 0:00:00.084961\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1536.73346875\tTime: 0:00:00.014951\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1554.3172083333334\tTime: 0:00:00.084841\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1521.2285\tTime: 0:00:00.011944\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1549.3135729166668\tTime: 0:00:00.086394\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1519.06478125\tTime: 0:00:00.014794\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1548.6900625\tTime: 0:00:00.086101\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1513.9855625\tTime: 0:00:00.014670\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1536.2498541666666\tTime: 0:00:00.086755\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1512.5214375\tTime: 0:00:00.012228\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1534.5833125\tTime: 0:00:00.087763\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1501.9719375\tTime: 0:00:00.012193\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1527.9785208333333\tTime: 0:00:00.086726\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1505.83440625\tTime: 0:00:00.012124\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1520.8568020833334\tTime: 0:00:00.087976\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1502.98296875\tTime: 0:00:00.014705\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1521.20896875\tTime: 0:00:00.087420\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1498.47628125\tTime: 0:00:00.012474\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1517.7677604166668\tTime: 0:00:00.084904\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1496.91515625\tTime: 0:00:00.012012\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1514.630375\tTime: 0:00:00.083759\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1498.51553125\tTime: 0:00:00.011976\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1507.49\tTime: 0:00:00.084936\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1494.62615625\tTime: 0:00:00.014920\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1508.0712083333333\tTime: 0:00:00.087378\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1493.07790625\tTime: 0:00:00.014683\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1504.1445833333332\tTime: 0:00:00.085331\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1484.3374375\tTime: 0:00:00.015336\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1505.9324895833333\tTime: 0:00:00.103083\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1481.30159375\tTime: 0:00:00.014920\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1505.3448854166666\tTime: 0:00:00.085151\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1477.14475\tTime: 0:00:00.012047\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1499.15278125\tTime: 0:00:00.089907\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1484.18290625\tTime: 0:00:00.014841\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1493.5629375\tTime: 0:00:00.086876\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1480.09253125\tTime: 0:00:00.011775\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1493.9166145833333\tTime: 0:00:00.083502\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1478.8976875\tTime: 0:00:00.014958\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1494.6995\tTime: 0:00:00.084663\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1481.66953125\tTime: 0:00:00.014854\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1492.6744895833333\tTime: 0:00:00.084337\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1474.1925\tTime: 0:00:00.012049\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1489.6238125\tTime: 0:00:00.084532\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1472.54625\tTime: 0:00:00.012187\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1485.7787708333333\tTime: 0:00:00.083750\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1473.9345\tTime: 0:00:00.011947\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1487.8817395833332\tTime: 0:00:00.086224\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1473.766625\tTime: 0:00:00.015174\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1478.5765208333332\tTime: 0:00:00.086615\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1470.1724375\tTime: 0:00:00.014677\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1478.54696875\tTime: 0:00:00.086211\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1472.12859375\tTime: 0:00:00.012299\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1480.39753125\tTime: 0:00:00.083840\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1474.2380625\tTime: 0:00:00.011974\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1482.4690833333334\tTime: 0:00:00.088397\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1467.28309375\tTime: 0:00:00.012827\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1480.5228645833333\tTime: 0:00:00.084825\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1471.7529375\tTime: 0:00:00.012112\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1477.2411770833332\tTime: 0:00:00.086454\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1462.604875\tTime: 0:00:00.012272\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1474.5248854166666\tTime: 0:00:00.083996\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1468.7858125\tTime: 0:00:00.014802\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1477.6534270833333\tTime: 0:00:00.085486\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1468.89859375\tTime: 0:00:00.012283\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1468.6029166666667\tTime: 0:00:00.084285\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1459.8479375\tTime: 0:00:00.012669\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1469.97675\tTime: 0:00:00.085308\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1466.253875\tTime: 0:00:00.013068\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1472.0326041666667\tTime: 0:00:00.083748\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1460.72859375\tTime: 0:00:00.011929\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1464.5432291666666\tTime: 0:00:00.086350\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1462.1495625\tTime: 0:00:00.013012\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1468.141875\tTime: 0:00:00.084704\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1464.84084375\tTime: 0:00:00.011926\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1470.7859375\tTime: 0:00:00.090787\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1463.791875\tTime: 0:00:00.012768\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.134703394399862\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2585.708249701771\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1730.9556979166666\tTime: 0:00:00.086218\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1602.50965625\tTime: 0:00:00.015182\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1708.8691145833334\tTime: 0:00:00.086437\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1608.38465625\tTime: 0:00:00.012175\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1676.6166770833333\tTime: 0:00:00.083599\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1615.776125\tTime: 0:00:00.015383\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1650.0045\tTime: 0:00:00.085092\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1611.15753125\tTime: 0:00:00.015009\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1624.5848541666667\tTime: 0:00:00.085000\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1591.67896875\tTime: 0:00:00.012337\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1609.4378333333334\tTime: 0:00:00.087866\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1563.43596875\tTime: 0:00:00.012071\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1594.21378125\tTime: 0:00:00.087473\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1547.62871875\tTime: 0:00:00.015199\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1574.4195625\tTime: 0:00:00.090266\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1531.619625\tTime: 0:00:00.012164\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1568.3482604166666\tTime: 0:00:00.094783\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1518.2530625\tTime: 0:00:00.012491\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1556.1964479166666\tTime: 0:00:00.089126\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1514.202125\tTime: 0:00:00.011922\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1551.58259375\tTime: 0:00:00.087339\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1504.39334375\tTime: 0:00:00.015055\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1543.9869895833333\tTime: 0:00:00.088097\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1501.271375\tTime: 0:00:00.014977\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1539.0683229166666\tTime: 0:00:00.092509\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1490.0720625\tTime: 0:00:00.012430\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1530.232625\tTime: 0:00:00.087099\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1484.56890625\tTime: 0:00:00.012144\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1521.9238645833334\tTime: 0:00:00.085992\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1487.35215625\tTime: 0:00:00.015098\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1516.7359375\tTime: 0:00:00.089276\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1482.6715625\tTime: 0:00:00.014885\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1515.61509375\tTime: 0:00:00.087440\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1476.82878125\tTime: 0:00:00.012346\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1511.69115625\tTime: 0:00:00.085715\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1474.19778125\tTime: 0:00:00.015005\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1507.0673020833333\tTime: 0:00:00.088229\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1471.61859375\tTime: 0:00:00.012321\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1505.1961458333333\tTime: 0:00:00.084856\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1466.9286875\tTime: 0:00:00.012113\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1502.160875\tTime: 0:00:00.085429\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1466.8488125\tTime: 0:00:00.012435\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1494.0481354166666\tTime: 0:00:00.086245\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1466.9284375\tTime: 0:00:00.014975\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1491.6781770833334\tTime: 0:00:00.089296\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1469.08159375\tTime: 0:00:00.012541\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1493.1747291666666\tTime: 0:00:00.087479\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1462.5791875\tTime: 0:00:00.012005\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1489.7541041666666\tTime: 0:00:00.088619\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1455.416125\tTime: 0:00:00.012494\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1491.7908645833334\tTime: 0:00:00.085196\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1462.5293125\tTime: 0:00:00.012092\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1484.9050520833334\tTime: 0:00:00.089069\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1457.74621875\tTime: 0:00:00.012496\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1479.5725729166666\tTime: 0:00:00.087380\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1459.554\tTime: 0:00:00.014988\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1488.3056458333333\tTime: 0:00:00.087604\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1457.6705\tTime: 0:00:00.012730\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1479.9193125\tTime: 0:00:00.085287\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1450.5463125\tTime: 0:00:00.012035\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1475.40978125\tTime: 0:00:00.086896\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1457.4755\tTime: 0:00:00.015286\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1476.6534375\tTime: 0:00:00.085463\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1452.97503125\tTime: 0:00:00.011980\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1479.0174479166667\tTime: 0:00:00.086439\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1453.12625\tTime: 0:00:00.012944\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1473.20828125\tTime: 0:00:00.087596\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1451.6275\tTime: 0:00:00.012128\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1470.5100520833332\tTime: 0:00:00.086399\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1449.142625\tTime: 0:00:00.012113\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1469.5221666666666\tTime: 0:00:00.084939\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1450.43253125\tTime: 0:00:00.015269\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1465.1556979166667\tTime: 0:00:00.089963\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1444.13271875\tTime: 0:00:00.012132\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1468.767375\tTime: 0:00:00.086303\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1441.161625\tTime: 0:00:00.012444\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1464.3169583333333\tTime: 0:00:00.087381\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1445.68703125\tTime: 0:00:00.015000\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1465.0157395833332\tTime: 0:00:00.090255\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1447.91796875\tTime: 0:00:00.012718\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1465.6026354166668\tTime: 0:00:00.090537\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1441.4708125\tTime: 0:00:00.015361\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1462.374125\tTime: 0:00:00.089072\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1439.34009375\tTime: 0:00:00.012605\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1461.82734375\tTime: 0:00:00.087541\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1438.5840625\tTime: 0:00:00.012127\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1456.57134375\tTime: 0:00:00.085029\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1441.014\tTime: 0:00:00.012380\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1457.5828333333334\tTime: 0:00:00.089324\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1438.8136875\tTime: 0:00:00.012091\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1452.6524479166667\tTime: 0:00:00.083711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1440.574375\tTime: 0:00:00.013616\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1452.0973333333334\tTime: 0:00:00.088321\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1442.1759375\tTime: 0:00:00.012115\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1455.9779895833333\tTime: 0:00:00.089840\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1434.2628125\tTime: 0:00:00.014139\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1455.3304375\tTime: 0:00:00.087708\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1437.626625\tTime: 0:00:00.012046\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1455.9183958333333\tTime: 0:00:00.086625\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1437.447125\tTime: 0:00:00.012225\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1451.82596875\tTime: 0:00:00.083098\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1435.7015\tTime: 0:00:00.012105\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1451.9965416666666\tTime: 0:00:00.086949\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1436.08075\tTime: 0:00:00.015725\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1452.66771875\tTime: 0:00:00.086920\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1435.01925\tTime: 0:00:00.015133\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.106545346721447\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2662.4069532552335\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1735.6927604166667\tTime: 0:00:00.086893\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1608.650625\tTime: 0:00:00.015205\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1716.5214479166666\tTime: 0:00:00.083272\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1614.91196875\tTime: 0:00:00.011883\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1684.0374583333332\tTime: 0:00:00.082998\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1624.57540625\tTime: 0:00:00.012301\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1659.3364479166667\tTime: 0:00:00.085532\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1621.1556875\tTime: 0:00:00.012021\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1637.6353125\tTime: 0:00:00.083547\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1606.50053125\tTime: 0:00:00.012647\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1617.7609479166667\tTime: 0:00:00.083781\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1582.6835625\tTime: 0:00:00.014764\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1600.3720625\tTime: 0:00:00.087615\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1564.1440625\tTime: 0:00:00.015141\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1588.51875\tTime: 0:00:00.088100\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1553.44803125\tTime: 0:00:00.011963\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1577.52353125\tTime: 0:00:00.086066\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1541.27965625\tTime: 0:00:00.012347\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1572.4999270833334\tTime: 0:00:00.083744\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1538.69325\tTime: 0:00:00.015105\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1564.9387916666667\tTime: 0:00:00.086597\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1535.46975\tTime: 0:00:00.015084\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1556.7550416666666\tTime: 0:00:00.087095\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1523.43121875\tTime: 0:00:00.012009\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1548.2999375\tTime: 0:00:00.085830\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1518.570625\tTime: 0:00:00.012068\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1541.94878125\tTime: 0:00:00.086224\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1517.08821875\tTime: 0:00:00.012358\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1540.1416666666667\tTime: 0:00:00.087210\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1512.73559375\tTime: 0:00:00.012270\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1534.7215208333334\tTime: 0:00:00.085360\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1511.1756875\tTime: 0:00:00.011898\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1526.02121875\tTime: 0:00:00.086976\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1503.62028125\tTime: 0:00:00.014911\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1528.40734375\tTime: 0:00:00.084658\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1499.6986875\tTime: 0:00:00.011983\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1521.6780208333332\tTime: 0:00:00.088606\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1500.4826875\tTime: 0:00:00.012590\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1512.64165625\tTime: 0:00:00.085737\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1493.17415625\tTime: 0:00:00.014969\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1510.1091145833334\tTime: 0:00:00.088019\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1496.56209375\tTime: 0:00:00.015022\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1508.94234375\tTime: 0:00:00.084906\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1488.62784375\tTime: 0:00:00.012048\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1509.1138229166668\tTime: 0:00:00.100446\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1486.8568125\tTime: 0:00:00.015201\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1501.3328229166666\tTime: 0:00:00.099555\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1485.2779375\tTime: 0:00:00.012261\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1500.78484375\tTime: 0:00:00.086843\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1484.298625\tTime: 0:00:00.012271\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1503.5677291666666\tTime: 0:00:00.084367\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1485.36871875\tTime: 0:00:00.011963\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1498.0876145833333\tTime: 0:00:00.085761\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1481.1885625\tTime: 0:00:00.012190\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1495.2027604166667\tTime: 0:00:00.085080\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1479.4130625\tTime: 0:00:00.012104\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1494.18590625\tTime: 0:00:00.085303\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1481.5855625\tTime: 0:00:00.012287\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1491.0225833333334\tTime: 0:00:00.086156\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1473.94815625\tTime: 0:00:00.014835\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1486.1251875\tTime: 0:00:00.087340\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1474.6661875\tTime: 0:00:00.012295\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1481.1104895833334\tTime: 0:00:00.084452\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1473.99828125\tTime: 0:00:00.012090\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1481.8059375\tTime: 0:00:00.087884\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1472.58409375\tTime: 0:00:00.012656\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1481.2781458333334\tTime: 0:00:00.087059\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1472.13303125\tTime: 0:00:00.011977\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1477.3248541666667\tTime: 0:00:00.087582\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1476.19746875\tTime: 0:00:00.012294\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1471.85528125\tTime: 0:00:00.084384\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1470.6358125\tTime: 0:00:00.011961\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1475.2097083333333\tTime: 0:00:00.087105\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1468.80896875\tTime: 0:00:00.012174\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1476.6036875\tTime: 0:00:00.085087\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1468.5144375\tTime: 0:00:00.012030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1469.74059375\tTime: 0:00:00.084102\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1467.78071875\tTime: 0:00:00.012325\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1473.9649895833334\tTime: 0:00:00.086351\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1470.28559375\tTime: 0:00:00.014605\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1466.9344166666667\tTime: 0:00:00.084940\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1461.002125\tTime: 0:00:00.012255\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1467.3100520833334\tTime: 0:00:00.084466\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1463.5120625\tTime: 0:00:00.015085\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1470.0223541666667\tTime: 0:00:00.085433\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1465.996375\tTime: 0:00:00.012105\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1463.1127604166666\tTime: 0:00:00.084396\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1460.859\tTime: 0:00:00.012071\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1465.5816354166666\tTime: 0:00:00.087230\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1464.10034375\tTime: 0:00:00.015062\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1461.7638645833333\tTime: 0:00:00.085249\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1461.72471875\tTime: 0:00:00.011851\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1462.6208229166666\tTime: 0:00:00.083634\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1464.7483125\tTime: 0:00:00.012837\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1458.8918229166666\tTime: 0:00:00.085018\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1460.3645625\tTime: 0:00:00.011851\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1454.1693854166667\tTime: 0:00:00.085117\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1459.4768125\tTime: 0:00:00.012292\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1456.4698854166666\tTime: 0:00:00.084204\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1458.9908125\tTime: 0:00:00.011986\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1461.8689895833334\tTime: 0:00:00.086938\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1459.40575\tTime: 0:00:00.013151\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1457.5172708333334\tTime: 0:00:00.085963\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1455.0139375\tTime: 0:00:00.011863\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1456.0171875\tTime: 0:00:00.086994\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1453.718875\tTime: 0:00:00.012394\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1454.6930520833334\tTime: 0:00:00.083268\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1457.33571875\tTime: 0:00:00.012176\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1451.4046770833334\tTime: 0:00:00.086167\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1460.18190625\tTime: 0:00:00.012018\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1460.2313125\tTime: 0:00:00.083525\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1456.21109375\tTime: 0:00:00.011856\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1451.4509583333333\tTime: 0:00:00.085234\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1452.10715625\tTime: 0:00:00.015345\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1458.6787708333334\tTime: 0:00:00.089024\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1456.72990625\tTime: 0:00:00.012413\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1450.4183333333333\tTime: 0:00:00.089403\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1455.32775\tTime: 0:00:00.012208\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1446.9479166666667\tTime: 0:00:00.083881\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1450.28953125\tTime: 0:00:00.012135\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1449.2016770833334\tTime: 0:00:00.087157\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1452.97834375\tTime: 0:00:00.012379\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1448.076\tTime: 0:00:00.087812\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1453.72665625\tTime: 0:00:00.014849\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1449.3708020833333\tTime: 0:00:00.089085\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1454.31940625\tTime: 0:00:00.012157\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1451.90959375\tTime: 0:00:00.086328\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1454.6684375\tTime: 0:00:00.012063\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1444.9181354166667\tTime: 0:00:00.087338\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1448.022125\tTime: 0:00:00.012895\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1442.6561770833334\tTime: 0:00:00.086365\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1451.07703125\tTime: 0:00:00.012189\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1448.1762760416666\tTime: 0:00:00.087141\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1450.4355\tTime: 0:00:00.012323\n",
      "Epoch: [68/100]\tSamples: [51000/75000]\tTrain Loss: 1445.3347604166668\tTime: 0:00:00.087914\n",
      "Epoch: [68/100]\tSamples: [250/25000]\tValidation Loss: 1451.5356875\tTime: 0:00:00.012977\n",
      "Epoch: [69/100]\tSamples: [51750/75000]\tTrain Loss: 1440.4876979166668\tTime: 0:00:00.084806\n",
      "Epoch: [69/100]\tSamples: [250/25000]\tValidation Loss: 1448.068875\tTime: 0:00:00.012953\n",
      "Epoch: [70/100]\tSamples: [52500/75000]\tTrain Loss: 1448.2623802083333\tTime: 0:00:00.087052\n",
      "Epoch: [70/100]\tSamples: [250/25000]\tValidation Loss: 1447.60175\tTime: 0:00:00.014838\n",
      "Epoch: [71/100]\tSamples: [53250/75000]\tTrain Loss: 1440.2555677083333\tTime: 0:00:00.086217\n",
      "Epoch: [71/100]\tSamples: [250/25000]\tValidation Loss: 1451.3999375\tTime: 0:00:00.012499\n",
      "Epoch: [72/100]\tSamples: [54000/75000]\tTrain Loss: 1440.5573125\tTime: 0:00:00.085590\n",
      "Epoch: [72/100]\tSamples: [250/25000]\tValidation Loss: 1446.754375\tTime: 0:00:00.011859\n",
      "Epoch: [73/100]\tSamples: [54750/75000]\tTrain Loss: 1442.178390625\tTime: 0:00:00.086720\n",
      "Epoch: [73/100]\tSamples: [250/25000]\tValidation Loss: 1450.65215625\tTime: 0:00:00.012330\n",
      "Epoch: [74/100]\tSamples: [55500/75000]\tTrain Loss: 1441.1853229166666\tTime: 0:00:00.086028\n",
      "Epoch: [74/100]\tSamples: [250/25000]\tValidation Loss: 1450.653625\tTime: 0:00:00.012069\n",
      "Epoch: [75/100]\tSamples: [56250/75000]\tTrain Loss: 1445.2944375\tTime: 0:00:00.087691\n",
      "Epoch: [75/100]\tSamples: [250/25000]\tValidation Loss: 1443.32778125\tTime: 0:00:00.015607\n",
      "Epoch: [76/100]\tSamples: [57000/75000]\tTrain Loss: 1447.6631666666667\tTime: 0:00:00.085136\n",
      "Epoch: [76/100]\tSamples: [250/25000]\tValidation Loss: 1444.59471875\tTime: 0:00:00.011864\n",
      "Epoch: [77/100]\tSamples: [57750/75000]\tTrain Loss: 1441.2446666666667\tTime: 0:00:00.087051\n",
      "Epoch: [77/100]\tSamples: [250/25000]\tValidation Loss: 1449.8024375\tTime: 0:00:00.012326\n",
      "Epoch: [78/100]\tSamples: [58500/75000]\tTrain Loss: 1439.2695\tTime: 0:00:00.092750\n",
      "Epoch: [78/100]\tSamples: [250/25000]\tValidation Loss: 1447.6044375\tTime: 0:00:00.015168\n",
      "Epoch: [79/100]\tSamples: [59250/75000]\tTrain Loss: 1440.0225833333334\tTime: 0:00:00.089223\n",
      "Epoch: [79/100]\tSamples: [250/25000]\tValidation Loss: 1442.60796875\tTime: 0:00:00.012599\n",
      "Epoch: [80/100]\tSamples: [60000/75000]\tTrain Loss: 1443.9498125\tTime: 0:00:00.085922\n",
      "Epoch: [80/100]\tSamples: [250/25000]\tValidation Loss: 1443.85484375\tTime: 0:00:00.012183\n",
      "Epoch: [81/100]\tSamples: [60750/75000]\tTrain Loss: 1442.3886041666667\tTime: 0:00:00.088048\n",
      "Epoch: [81/100]\tSamples: [250/25000]\tValidation Loss: 1443.57209375\tTime: 0:00:00.012316\n",
      "Epoch: [82/100]\tSamples: [61500/75000]\tTrain Loss: 1441.1028020833332\tTime: 0:00:00.087504\n",
      "Epoch: [82/100]\tSamples: [250/25000]\tValidation Loss: 1446.0763125\tTime: 0:00:00.014868\n",
      "Epoch: [83/100]\tSamples: [62250/75000]\tTrain Loss: 1438.83634375\tTime: 0:00:00.089920\n",
      "Epoch: [83/100]\tSamples: [250/25000]\tValidation Loss: 1444.68109375\tTime: 0:00:00.012326\n",
      "Epoch: [84/100]\tSamples: [63000/75000]\tTrain Loss: 1438.9390208333334\tTime: 0:00:00.084734\n",
      "Epoch: [84/100]\tSamples: [250/25000]\tValidation Loss: 1440.4561875\tTime: 0:00:00.012138\n",
      "Epoch: [85/100]\tSamples: [63750/75000]\tTrain Loss: 1438.7526458333334\tTime: 0:00:00.090948\n",
      "Epoch: [85/100]\tSamples: [250/25000]\tValidation Loss: 1447.3184375\tTime: 0:00:00.012616\n",
      "Epoch: [86/100]\tSamples: [64500/75000]\tTrain Loss: 1436.78384375\tTime: 0:00:00.087685\n",
      "Epoch: [86/100]\tSamples: [250/25000]\tValidation Loss: 1446.2235\tTime: 0:00:00.012526\n",
      "Epoch: [87/100]\tSamples: [65250/75000]\tTrain Loss: 1440.27615625\tTime: 0:00:00.084687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87/100]\tSamples: [250/25000]\tValidation Loss: 1447.79725\tTime: 0:00:00.015827\n",
      "Epoch: [88/100]\tSamples: [66000/75000]\tTrain Loss: 1436.6013333333333\tTime: 0:00:00.087104\n",
      "Epoch: [88/100]\tSamples: [250/25000]\tValidation Loss: 1449.24765625\tTime: 0:00:00.012203\n",
      "Epoch: [89/100]\tSamples: [66750/75000]\tTrain Loss: 1439.63534375\tTime: 0:00:00.084306\n",
      "Epoch: [89/100]\tSamples: [250/25000]\tValidation Loss: 1440.43703125\tTime: 0:00:00.012134\n",
      "Epoch: [90/100]\tSamples: [67500/75000]\tTrain Loss: 1439.0148177083333\tTime: 0:00:00.088115\n",
      "Epoch: [90/100]\tSamples: [250/25000]\tValidation Loss: 1439.64565625\tTime: 0:00:00.015357\n",
      "Epoch: [91/100]\tSamples: [68250/75000]\tTrain Loss: 1434.9169583333332\tTime: 0:00:00.088300\n",
      "Epoch: [91/100]\tSamples: [250/25000]\tValidation Loss: 1439.86234375\tTime: 0:00:00.012142\n",
      "Epoch: [92/100]\tSamples: [69000/75000]\tTrain Loss: 1433.5605208333334\tTime: 0:00:00.088028\n",
      "Epoch: [92/100]\tSamples: [250/25000]\tValidation Loss: 1442.381125\tTime: 0:00:00.012364\n",
      "Epoch: [93/100]\tSamples: [69750/75000]\tTrain Loss: 1432.0416770833333\tTime: 0:00:00.089021\n",
      "Epoch: [93/100]\tSamples: [250/25000]\tValidation Loss: 1444.3068125\tTime: 0:00:00.012114\n",
      "Epoch: [94/100]\tSamples: [70500/75000]\tTrain Loss: 1431.2190208333334\tTime: 0:00:00.090123\n",
      "Epoch: [94/100]\tSamples: [250/25000]\tValidation Loss: 1444.492625\tTime: 0:00:00.012692\n",
      "Epoch: [95/100]\tSamples: [71250/75000]\tTrain Loss: 1443.7033333333334\tTime: 0:00:00.087038\n",
      "Epoch: [95/100]\tSamples: [250/25000]\tValidation Loss: 1443.064125\tTime: 0:00:00.012155\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.204235679114958\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2779.2899517257124\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1736.2595729166667\tTime: 0:00:00.086942\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1617.55034375\tTime: 0:00:00.012346\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1716.2578541666667\tTime: 0:00:00.088609\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1621.42525\tTime: 0:00:00.012305\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1688.56896875\tTime: 0:00:00.091075\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1630.86765625\tTime: 0:00:00.012402\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1660.6797395833332\tTime: 0:00:00.088232\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1626.87390625\tTime: 0:00:00.012489\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1642.4719895833334\tTime: 0:00:00.089226\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1610.319375\tTime: 0:00:00.015234\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1618.8159479166666\tTime: 0:00:00.089165\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1588.56015625\tTime: 0:00:00.015419\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1600.2711145833334\tTime: 0:00:00.090140\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1570.91228125\tTime: 0:00:00.012446\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1591.8017916666668\tTime: 0:00:00.086185\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1556.354875\tTime: 0:00:00.012280\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1581.3810520833333\tTime: 0:00:00.088108\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1551.32859375\tTime: 0:00:00.012638\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1571.3515416666667\tTime: 0:00:00.087473\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1538.95815625\tTime: 0:00:00.012198\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1561.47478125\tTime: 0:00:00.088254\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1539.1356875\tTime: 0:00:00.012412\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1557.35753125\tTime: 0:00:00.089541\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1530.4260625\tTime: 0:00:00.012144\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1550.0365416666666\tTime: 0:00:00.089035\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1524.77640625\tTime: 0:00:00.012392\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1543.2455208333333\tTime: 0:00:00.087229\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1517.04478125\tTime: 0:00:00.012106\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1539.6702291666666\tTime: 0:00:00.088066\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1516.95325\tTime: 0:00:00.012303\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1536.4165729166666\tTime: 0:00:00.086085\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1517.02759375\tTime: 0:00:00.015816\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1531.3418645833333\tTime: 0:00:00.094968\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1509.3618125\tTime: 0:00:00.015248\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1526.8492604166668\tTime: 0:00:00.101195\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1508.16371875\tTime: 0:00:00.015055\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1522.3476041666668\tTime: 0:00:00.101763\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1503.358125\tTime: 0:00:00.015422\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1520.1575\tTime: 0:00:00.101677\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1501.1939375\tTime: 0:00:00.013214\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1515.9083541666666\tTime: 0:00:00.088779\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1496.8475625\tTime: 0:00:00.012484\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1511.03675\tTime: 0:00:00.087749\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1494.11103125\tTime: 0:00:00.012219\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1507.10284375\tTime: 0:00:00.090289\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1492.48853125\tTime: 0:00:00.015423\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1507.7041979166668\tTime: 0:00:00.088914\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1487.09865625\tTime: 0:00:00.015175\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1502.8685520833333\tTime: 0:00:00.090963\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1485.37621875\tTime: 0:00:00.012455\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1503.7343854166666\tTime: 0:00:00.086789\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1482.51159375\tTime: 0:00:00.012261\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1499.8975833333334\tTime: 0:00:00.086500\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1483.35878125\tTime: 0:00:00.012295\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1497.82971875\tTime: 0:00:00.087945\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1480.452625\tTime: 0:00:00.012333\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1492.26128125\tTime: 0:00:00.087984\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1481.625875\tTime: 0:00:00.012489\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1492.9368541666668\tTime: 0:00:00.088634\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1475.0651875\tTime: 0:00:00.014900\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1487.2187395833334\tTime: 0:00:00.093677\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1474.73225\tTime: 0:00:00.012341\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1489.1353854166666\tTime: 0:00:00.086464\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1472.69540625\tTime: 0:00:00.012202\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1488.0324270833332\tTime: 0:00:00.088947\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1474.63046875\tTime: 0:00:00.012526\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1483.3836354166667\tTime: 0:00:00.086969\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1470.63934375\tTime: 0:00:00.012130\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1482.6216458333333\tTime: 0:00:00.101070\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1471.787125\tTime: 0:00:00.015710\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1478.3825\tTime: 0:00:00.089998\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1469.22840625\tTime: 0:00:00.012354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1476.2726979166666\tTime: 0:00:00.087898\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1464.96546875\tTime: 0:00:00.012530\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1477.8201145833334\tTime: 0:00:00.086164\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1466.912125\tTime: 0:00:00.015039\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1478.32815625\tTime: 0:00:00.091505\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1464.56634375\tTime: 0:00:00.012607\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1474.3924791666666\tTime: 0:00:00.089038\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1462.1481875\tTime: 0:00:00.014955\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1472.7205\tTime: 0:00:00.088253\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1461.3891875\tTime: 0:00:00.012528\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1474.25965625\tTime: 0:00:00.085799\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1462.41309375\tTime: 0:00:00.015193\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1472.7811666666666\tTime: 0:00:00.087512\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1459.5805\tTime: 0:00:00.012489\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1469.9113020833333\tTime: 0:00:00.086333\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1461.8768125\tTime: 0:00:00.014926\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1472.24203125\tTime: 0:00:00.090778\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1461.30421875\tTime: 0:00:00.012538\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1469.5438958333334\tTime: 0:00:00.089532\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1456.92034375\tTime: 0:00:00.012289\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1466.8518958333334\tTime: 0:00:00.090886\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1458.64953125\tTime: 0:00:00.012447\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1468.6053020833333\tTime: 0:00:00.089481\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1457.35846875\tTime: 0:00:00.015135\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1462.03778125\tTime: 0:00:00.089784\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1454.5316875\tTime: 0:00:00.012320\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1464.9630625\tTime: 0:00:00.088250\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1456.6509375\tTime: 0:00:00.012576\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1463.1464791666667\tTime: 0:00:00.090113\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1459.22278125\tTime: 0:00:00.012409\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1464.559625\tTime: 0:00:00.085949\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1458.61571875\tTime: 0:00:00.012423\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1463.8977291666667\tTime: 0:00:00.085813\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1455.2269375\tTime: 0:00:00.015766\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1460.20184375\tTime: 0:00:00.087525\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1450.990125\tTime: 0:00:00.012236\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1459.8938125\tTime: 0:00:00.089858\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1452.47234375\tTime: 0:00:00.012693\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1460.4524479166666\tTime: 0:00:00.085246\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1457.45346875\tTime: 0:00:00.012260\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1455.4934375\tTime: 0:00:00.088242\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1455.403875\tTime: 0:00:00.015898\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1457.0565729166667\tTime: 0:00:00.089488\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1449.61921875\tTime: 0:00:00.012393\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1452.9585208333333\tTime: 0:00:00.091821\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1455.42815625\tTime: 0:00:00.015357\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1458.5363125\tTime: 0:00:00.103110\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1456.04640625\tTime: 0:00:00.013133\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1454.9095729166668\tTime: 0:00:00.092565\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1449.07875\tTime: 0:00:00.012414\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1452.6297083333334\tTime: 0:00:00.085486\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1454.21090625\tTime: 0:00:00.015103\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1458.2221666666667\tTime: 0:00:00.090488\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1454.68525\tTime: 0:00:00.015060\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1452.0152916666666\tTime: 0:00:00.086595\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1452.623\tTime: 0:00:00.015000\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1453.9901145833333\tTime: 0:00:00.092578\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1453.4230625\tTime: 0:00:00.015212\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1451.4491197916666\tTime: 0:00:00.089715\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1446.99553125\tTime: 0:00:00.012355\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1449.7774375\tTime: 0:00:00.090781\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1448.1380625\tTime: 0:00:00.012253\n",
      "Epoch: [68/100]\tSamples: [51000/75000]\tTrain Loss: 1452.8844270833333\tTime: 0:00:00.090907\n",
      "Epoch: [68/100]\tSamples: [250/25000]\tValidation Loss: 1448.51659375\tTime: 0:00:00.012170\n",
      "Epoch: [69/100]\tSamples: [51750/75000]\tTrain Loss: 1450.0207395833334\tTime: 0:00:00.090371\n",
      "Epoch: [69/100]\tSamples: [250/25000]\tValidation Loss: 1447.348375\tTime: 0:00:00.012437\n",
      "Epoch: [70/100]\tSamples: [52500/75000]\tTrain Loss: 1448.262625\tTime: 0:00:00.084824\n",
      "Epoch: [70/100]\tSamples: [250/25000]\tValidation Loss: 1447.3584375\tTime: 0:00:00.012284\n",
      "Epoch: [71/100]\tSamples: [53250/75000]\tTrain Loss: 1447.3918125\tTime: 0:00:00.087598\n",
      "Epoch: [71/100]\tSamples: [250/25000]\tValidation Loss: 1443.678375\tTime: 0:00:00.013035\n",
      "Epoch: [72/100]\tSamples: [54000/75000]\tTrain Loss: 1446.0808229166666\tTime: 0:00:00.087897\n",
      "Epoch: [72/100]\tSamples: [250/25000]\tValidation Loss: 1445.93478125\tTime: 0:00:00.012270\n",
      "Epoch: [73/100]\tSamples: [54750/75000]\tTrain Loss: 1446.1041770833333\tTime: 0:00:00.088670\n",
      "Epoch: [73/100]\tSamples: [250/25000]\tValidation Loss: 1444.71709375\tTime: 0:00:00.012441\n",
      "Epoch: [74/100]\tSamples: [55500/75000]\tTrain Loss: 1445.4331875\tTime: 0:00:00.088568\n",
      "Epoch: [74/100]\tSamples: [250/25000]\tValidation Loss: 1449.183\tTime: 0:00:00.015113\n",
      "Epoch: [75/100]\tSamples: [56250/75000]\tTrain Loss: 1445.5153958333333\tTime: 0:00:00.087962\n",
      "Epoch: [75/100]\tSamples: [250/25000]\tValidation Loss: 1445.214375\tTime: 0:00:00.012582\n",
      "Epoch: [76/100]\tSamples: [57000/75000]\tTrain Loss: 1447.0437291666667\tTime: 0:00:00.085767\n",
      "Epoch: [76/100]\tSamples: [250/25000]\tValidation Loss: 1446.13034375\tTime: 0:00:00.012277\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.20116671791418\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2681.082436480928\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1739.6057604166667\tTime: 0:00:00.087368\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1624.71221875\tTime: 0:00:00.012873\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1718.5895520833333\tTime: 0:00:00.087121\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1629.23509375\tTime: 0:00:00.014946\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1694.2521666666667\tTime: 0:00:00.087751\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1636.5366875\tTime: 0:00:00.012621\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1670.6600625\tTime: 0:00:00.088423\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1633.0865\tTime: 0:00:00.012215\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1647.1801770833333\tTime: 0:00:00.085897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1618.7096875\tTime: 0:00:00.013072\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1627.0777604166667\tTime: 0:00:00.085626\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1598.04959375\tTime: 0:00:00.015079\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1614.49528125\tTime: 0:00:00.090294\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1583.80884375\tTime: 0:00:00.012781\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1598.8650416666667\tTime: 0:00:00.089934\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1571.1695625\tTime: 0:00:00.015018\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1587.2468854166666\tTime: 0:00:00.088502\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1561.697\tTime: 0:00:00.012296\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1579.6080104166667\tTime: 0:00:00.103481\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1549.2771875\tTime: 0:00:00.015092\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1571.158875\tTime: 0:00:00.103050\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1547.3058125\tTime: 0:00:00.016955\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1565.8696666666667\tTime: 0:00:00.102350\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1538.20640625\tTime: 0:00:00.012202\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1553.769\tTime: 0:00:00.086146\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1535.4755625\tTime: 0:00:00.012331\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1550.0106458333332\tTime: 0:00:00.086704\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1528.7731875\tTime: 0:00:00.012166\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1547.1824375\tTime: 0:00:00.088626\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1528.1970625\tTime: 0:00:00.012621\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1542.1861145833334\tTime: 0:00:00.086358\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1521.4469375\tTime: 0:00:00.012192\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1535.2808958333333\tTime: 0:00:00.088464\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1520.76240625\tTime: 0:00:00.012433\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1533.87821875\tTime: 0:00:00.087437\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1521.59675\tTime: 0:00:00.012153\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1527.9996666666666\tTime: 0:00:00.088446\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1512.9175625\tTime: 0:00:00.012421\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1527.6751041666666\tTime: 0:00:00.237053\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1506.9726875\tTime: 0:00:00.012498\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1522.65790625\tTime: 0:00:00.085477\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1506.35328125\tTime: 0:00:00.012586\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1514.1189895833334\tTime: 0:00:00.088022\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1508.41625\tTime: 0:00:00.012452\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1517.4042291666667\tTime: 0:00:00.086587\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1503.53803125\tTime: 0:00:00.012263\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1509.1499791666668\tTime: 0:00:00.086390\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1502.7459375\tTime: 0:00:00.012385\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1508.6352291666667\tTime: 0:00:00.088202\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1503.99078125\tTime: 0:00:00.015204\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1505.20665625\tTime: 0:00:00.087602\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1496.742625\tTime: 0:00:00.012684\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1505.8214895833332\tTime: 0:00:00.084779\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1492.43278125\tTime: 0:00:00.012328\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1501.5818854166666\tTime: 0:00:00.089144\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1491.81190625\tTime: 0:00:00.015472\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1495.8103645833332\tTime: 0:00:00.087064\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1491.11478125\tTime: 0:00:00.012293\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1489.9861770833334\tTime: 0:00:00.087995\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1489.0043125\tTime: 0:00:00.015226\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1489.1461979166668\tTime: 0:00:00.088335\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1483.27928125\tTime: 0:00:00.012048\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1494.1521458333334\tTime: 0:00:00.086433\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1486.45971875\tTime: 0:00:00.015272\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1491.2748854166666\tTime: 0:00:00.087985\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1482.3708125\tTime: 0:00:00.013163\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1487.2663958333333\tTime: 0:00:00.089149\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1484.9375\tTime: 0:00:00.015499\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1486.9848541666668\tTime: 0:00:00.086302\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1483.86265625\tTime: 0:00:00.012461\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1481.5974166666667\tTime: 0:00:00.088124\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1478.19321875\tTime: 0:00:00.015261\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1479.87784375\tTime: 0:00:00.102466\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1479.4349375\tTime: 0:00:00.014967\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1482.1229583333334\tTime: 0:00:00.095493\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1481.4904375\tTime: 0:00:00.012621\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1475.20371875\tTime: 0:00:00.090808\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1475.87103125\tTime: 0:00:00.012051\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1472.81003125\tTime: 0:00:00.086803\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1475.727875\tTime: 0:00:00.012494\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1476.48321875\tTime: 0:00:00.088469\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1470.54509375\tTime: 0:00:00.012227\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1472.92946875\tTime: 0:00:00.088497\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1475.067125\tTime: 0:00:00.012484\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1467.84315625\tTime: 0:00:00.088998\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1471.8279375\tTime: 0:00:00.012190\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1473.3132708333333\tTime: 0:00:00.088874\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1474.535625\tTime: 0:00:00.015300\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1472.62840625\tTime: 0:00:00.086235\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1471.73734375\tTime: 0:00:00.012400\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1471.5209791666666\tTime: 0:00:00.088090\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1471.60165625\tTime: 0:00:00.012612\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.1577127310378845\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2674.148581747753\u001b[0m\n",
      "Nodes averages betas and thetas inf:  7.160872773837665 2676.5272345822796\n",
      "BASELINE\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m822.7575848746245\u001b[0m\n",
      "Executing for frozen topics  40\n",
      "Shape of thetas_bas (5000, 50)\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 50)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1782.1469302083333\tTime: 0:00:00.468441\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1683.51815\tTime: 0:00:00.060719\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1733.1406208333333\tTime: 0:00:00.457644\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1674.97045\tTime: 0:00:00.061069\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1698.02710625\tTime: 0:00:00.472634\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1651.996209375\tTime: 0:00:00.078201\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1676.3840541666666\tTime: 0:00:00.457176\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1639.19593125\tTime: 0:00:00.061634\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1659.5575395833334\tTime: 0:00:00.457687\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1623.25691875\tTime: 0:00:00.060669\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1648.548671875\tTime: 0:00:00.439797\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1614.787990625\tTime: 0:00:00.061587\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1638.6132739583334\tTime: 0:00:00.450665\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1610.59719375\tTime: 0:00:00.063215\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1629.6554270833333\tTime: 0:00:00.454374\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1603.551846875\tTime: 0:00:00.061757\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1622.2955083333334\tTime: 0:00:00.454502\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1596.8810625\tTime: 0:00:00.061162\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1618.8688583333333\tTime: 0:00:00.447715\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1592.73019375\tTime: 0:00:00.061350\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1612.0654208333333\tTime: 0:00:00.452508\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1589.285525\tTime: 0:00:00.061608\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1606.9537416666667\tTime: 0:00:00.592256\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1586.185421875\tTime: 0:00:00.061643\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1601.8897822916667\tTime: 0:00:00.469280\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1581.735046875\tTime: 0:00:00.061600\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1600.0795114583334\tTime: 0:00:00.447291\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1576.339178125\tTime: 0:00:00.062380\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1596.37858125\tTime: 0:00:00.449919\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1578.4512875\tTime: 0:00:00.060903\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1594.4326458333333\tTime: 0:00:00.447517\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1572.509546875\tTime: 0:00:00.062158\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1589.7844645833334\tTime: 0:00:00.460717\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1572.13601875\tTime: 0:00:00.061477\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1587.023853125\tTime: 0:00:00.446264\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1564.65595\tTime: 0:00:00.062074\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1584.3936291666666\tTime: 0:00:00.450820\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1568.949909375\tTime: 0:00:00.061510\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1582.7009354166667\tTime: 0:00:00.451642\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1568.25688125\tTime: 0:00:00.079452\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1580.0755916666667\tTime: 0:00:00.451031\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1565.218240625\tTime: 0:00:00.060881\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1578.9784739583333\tTime: 0:00:00.453341\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1564.6710875\tTime: 0:00:00.062665\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1578.1725572916666\tTime: 0:00:00.459564\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1563.608678125\tTime: 0:00:00.062362\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1576.995503125\tTime: 0:00:00.447827\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1561.99051875\tTime: 0:00:00.062905\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1574.8516854166667\tTime: 0:00:00.446436\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1559.424303125\tTime: 0:00:00.062205\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1574.587028125\tTime: 0:00:00.450453\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1563.2778125\tTime: 0:00:00.064570\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1575.455859375\tTime: 0:00:00.448307\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1559.175653125\tTime: 0:00:00.061573\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1573.0691072916666\tTime: 0:00:00.454180\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1554.78143125\tTime: 0:00:00.064634\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1571.642409375\tTime: 0:00:00.456147\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1559.488346875\tTime: 0:00:00.061675\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1571.7354322916667\tTime: 0:00:00.452458\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1554.7836375\tTime: 0:00:00.062803\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1569.80426875\tTime: 0:00:00.452289\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1558.147396875\tTime: 0:00:00.061352\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1569.9002166666667\tTime: 0:00:00.457604\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1558.97408125\tTime: 0:00:00.078939\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1569.678953125\tTime: 0:00:00.459834\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1556.223953125\tTime: 0:00:00.063580\n",
      "Early stopping\n",
      "MAX BETAS:  0.0003929767\n",
      "MIN BETAS:  0.00013769591\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m8.409831097753043\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2314.630962025023\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1768.4954270833334\tTime: 0:00:00.086604\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1657.74490625\tTime: 0:00:00.012748\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1761.00953125\tTime: 0:00:00.101596\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1658.3483125\tTime: 0:00:00.015569\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1753.80584375\tTime: 0:00:00.098822\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1660.70471875\tTime: 0:00:00.012828\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1738.4443958333334\tTime: 0:00:00.083723\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1662.40653125\tTime: 0:00:00.012589\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1726.21675\tTime: 0:00:00.083409\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1660.57359375\tTime: 0:00:00.014514\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1710.568375\tTime: 0:00:00.083166\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1658.06534375\tTime: 0:00:00.012708\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.85691390096097\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2766.8056757112286\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1756.6331875\tTime: 0:00:00.086549\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1684.92915625\tTime: 0:00:00.012609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1750.0082916666668\tTime: 0:00:00.088646\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1685.991125\tTime: 0:00:00.012482\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1737.8505104166666\tTime: 0:00:00.085742\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1688.1615\tTime: 0:00:00.012228\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1725.5858645833334\tTime: 0:00:00.087013\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1689.08134375\tTime: 0:00:00.013203\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1716.9194583333333\tTime: 0:00:00.089639\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1687.22228125\tTime: 0:00:00.012298\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1700.802125\tTime: 0:00:00.088558\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1684.1843125\tTime: 0:00:00.013058\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1686.01840625\tTime: 0:00:00.085928\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1684.8281875\tTime: 0:00:00.012300\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1677.63590625\tTime: 0:00:00.087258\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1684.2038125\tTime: 0:00:00.012557\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1668.2617604166667\tTime: 0:00:00.086907\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1678.22084375\tTime: 0:00:00.012272\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1660.4166041666667\tTime: 0:00:00.088850\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1672.36740625\tTime: 0:00:00.012559\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1651.9350416666666\tTime: 0:00:00.085741\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1670.74590625\tTime: 0:00:00.012213\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1645.00225\tTime: 0:00:00.087768\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1666.45440625\tTime: 0:00:00.012510\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1640.5069583333334\tTime: 0:00:00.086563\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1661.51528125\tTime: 0:00:00.012293\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1632.31640625\tTime: 0:00:00.086747\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1658.502125\tTime: 0:00:00.012577\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1628.9081770833334\tTime: 0:00:00.086863\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1654.87734375\tTime: 0:00:00.012136\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1623.5772604166666\tTime: 0:00:00.090792\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1648.70853125\tTime: 0:00:00.012492\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1618.0804270833332\tTime: 0:00:00.087112\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1648.0355\tTime: 0:00:00.012341\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1615.7311145833332\tTime: 0:00:00.088488\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1645.47034375\tTime: 0:00:00.012538\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1614.50221875\tTime: 0:00:00.088112\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1642.31540625\tTime: 0:00:00.012347\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1608.8373541666667\tTime: 0:00:00.088240\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1642.33296875\tTime: 0:00:00.012568\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1601.0308645833334\tTime: 0:00:00.085535\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1637.633625\tTime: 0:00:00.012197\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1595.9862083333333\tTime: 0:00:00.088703\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1637.02265625\tTime: 0:00:00.012613\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1598.1441354166666\tTime: 0:00:00.086397\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1634.88196875\tTime: 0:00:00.015237\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1594.7886979166667\tTime: 0:00:00.089302\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1634.4635\tTime: 0:00:00.012611\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1591.0233541666666\tTime: 0:00:00.085621\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1633.28225\tTime: 0:00:00.012421\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1585.5235416666667\tTime: 0:00:00.087086\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1632.90521875\tTime: 0:00:00.012747\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1582.6825729166667\tTime: 0:00:00.089277\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1632.745\tTime: 0:00:00.012262\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1581.38653125\tTime: 0:00:00.091024\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1626.74146875\tTime: 0:00:00.012745\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1578.51525\tTime: 0:00:00.088670\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1625.72071875\tTime: 0:00:00.015392\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1578.4016145833334\tTime: 0:00:00.087861\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1627.37978125\tTime: 0:00:00.012539\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1575.4048645833334\tTime: 0:00:00.086342\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1622.7831875\tTime: 0:00:00.012365\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1573.69071875\tTime: 0:00:00.087000\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1622.34828125\tTime: 0:00:00.012502\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1571.3472395833332\tTime: 0:00:00.085966\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1622.4589375\tTime: 0:00:00.012192\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1567.6396666666667\tTime: 0:00:00.088645\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1618.78896875\tTime: 0:00:00.012507\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1565.16784375\tTime: 0:00:00.086183\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1618.137125\tTime: 0:00:00.012361\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1565.6771354166667\tTime: 0:00:00.087596\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1618.60590625\tTime: 0:00:00.012492\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1562.5946666666666\tTime: 0:00:00.086118\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1617.20415625\tTime: 0:00:00.012448\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1559.8332083333332\tTime: 0:00:00.088745\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1618.24775\tTime: 0:00:00.012655\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1558.8348854166666\tTime: 0:00:00.086755\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1617.48184375\tTime: 0:00:00.015256\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1557.5444791666666\tTime: 0:00:00.089072\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1614.1620625\tTime: 0:00:00.012675\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1555.6110625\tTime: 0:00:00.087487\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1616.64446875\tTime: 0:00:00.012252\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1554.4324895833333\tTime: 0:00:00.087986\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1614.9558125\tTime: 0:00:00.012686\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1553.9175833333334\tTime: 0:00:00.085827\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1612.20778125\tTime: 0:00:00.012408\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1549.4045\tTime: 0:00:00.087487\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1615.83528125\tTime: 0:00:00.012589\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1551.7591770833333\tTime: 0:00:00.088033\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1609.87071875\tTime: 0:00:00.012405\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1551.3310208333332\tTime: 0:00:00.088268\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1610.59528125\tTime: 0:00:00.012574\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1549.2227395833334\tTime: 0:00:00.087817\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1613.21840625\tTime: 0:00:00.012475\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1550.0014479166666\tTime: 0:00:00.085989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1609.96996875\tTime: 0:00:00.013204\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1545.3624583333333\tTime: 0:00:00.086063\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1609.13228125\tTime: 0:00:00.012371\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1543.0686770833333\tTime: 0:00:00.097419\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1609.471\tTime: 0:00:00.012680\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1545.7435625\tTime: 0:00:00.085825\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1606.99484375\tTime: 0:00:00.012170\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1539.9033854166667\tTime: 0:00:00.088595\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1608.79021875\tTime: 0:00:00.012649\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1542.59446875\tTime: 0:00:00.086958\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1607.96390625\tTime: 0:00:00.015278\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1540.2762604166667\tTime: 0:00:00.087715\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1607.3456875\tTime: 0:00:00.015316\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1538.4339375\tTime: 0:00:00.086848\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1609.86284375\tTime: 0:00:00.012286\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1539.5210208333333\tTime: 0:00:00.094514\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1605.9241875\tTime: 0:00:00.015585\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1536.4151354166668\tTime: 0:00:00.088179\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1602.3284375\tTime: 0:00:00.012754\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1530.2255104166666\tTime: 0:00:00.088005\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1601.1504375\tTime: 0:00:00.012654\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1532.0184375\tTime: 0:00:00.086645\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1603.93059375\tTime: 0:00:00.012479\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1531.6069479166667\tTime: 0:00:00.088107\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1601.130625\tTime: 0:00:00.012973\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1527.38128125\tTime: 0:00:00.087454\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1601.36975\tTime: 0:00:00.012408\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1536.11740625\tTime: 0:00:00.090025\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1601.36515625\tTime: 0:00:00.012503\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1529.7938958333334\tTime: 0:00:00.085546\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1602.7115\tTime: 0:00:00.012329\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1530.0233125\tTime: 0:00:00.085941\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1598.6296875\tTime: 0:00:00.013024\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1531.3353229166667\tTime: 0:00:00.086057\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1600.6660625\tTime: 0:00:00.012201\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1528.7358229166666\tTime: 0:00:00.087661\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1602.245125\tTime: 0:00:00.012589\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1522.6223958333333\tTime: 0:00:00.093091\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1597.2959375\tTime: 0:00:00.012425\n",
      "Epoch: [68/100]\tSamples: [51000/75000]\tTrain Loss: 1530.0923333333333\tTime: 0:00:00.090892\n",
      "Epoch: [68/100]\tSamples: [250/25000]\tValidation Loss: 1597.4406875\tTime: 0:00:00.012856\n",
      "Epoch: [69/100]\tSamples: [51750/75000]\tTrain Loss: 1521.6369270833334\tTime: 0:00:00.085935\n",
      "Epoch: [69/100]\tSamples: [250/25000]\tValidation Loss: 1596.83621875\tTime: 0:00:00.012401\n",
      "Epoch: [70/100]\tSamples: [52500/75000]\tTrain Loss: 1523.68353125\tTime: 0:00:00.089096\n",
      "Epoch: [70/100]\tSamples: [250/25000]\tValidation Loss: 1602.63609375\tTime: 0:00:00.012494\n",
      "Epoch: [71/100]\tSamples: [53250/75000]\tTrain Loss: 1526.8566770833334\tTime: 0:00:00.086367\n",
      "Epoch: [71/100]\tSamples: [250/25000]\tValidation Loss: 1601.68859375\tTime: 0:00:00.012223\n",
      "Epoch: [72/100]\tSamples: [54000/75000]\tTrain Loss: 1524.4704479166667\tTime: 0:00:00.087249\n",
      "Epoch: [72/100]\tSamples: [250/25000]\tValidation Loss: 1597.74740625\tTime: 0:00:00.013424\n",
      "Epoch: [73/100]\tSamples: [54750/75000]\tTrain Loss: 1521.2641458333333\tTime: 0:00:00.089069\n",
      "Epoch: [73/100]\tSamples: [250/25000]\tValidation Loss: 1601.5696875\tTime: 0:00:00.012560\n",
      "Epoch: [74/100]\tSamples: [55500/75000]\tTrain Loss: 1522.4035208333332\tTime: 0:00:00.088350\n",
      "Epoch: [74/100]\tSamples: [250/25000]\tValidation Loss: 1594.49859375\tTime: 0:00:00.013203\n",
      "Epoch: [75/100]\tSamples: [56250/75000]\tTrain Loss: 1522.69046875\tTime: 0:00:00.086732\n",
      "Epoch: [75/100]\tSamples: [250/25000]\tValidation Loss: 1597.60825\tTime: 0:00:00.012385\n",
      "Epoch: [76/100]\tSamples: [57000/75000]\tTrain Loss: 1522.6121041666668\tTime: 0:00:00.086677\n",
      "Epoch: [76/100]\tSamples: [250/25000]\tValidation Loss: 1601.66028125\tTime: 0:00:00.012676\n",
      "Epoch: [77/100]\tSamples: [57750/75000]\tTrain Loss: 1514.400375\tTime: 0:00:00.087084\n",
      "Epoch: [77/100]\tSamples: [250/25000]\tValidation Loss: 1598.305625\tTime: 0:00:00.012292\n",
      "Epoch: [78/100]\tSamples: [58500/75000]\tTrain Loss: 1521.1731458333334\tTime: 0:00:00.086038\n",
      "Epoch: [78/100]\tSamples: [250/25000]\tValidation Loss: 1596.2023125\tTime: 0:00:00.013091\n",
      "Epoch: [79/100]\tSamples: [59250/75000]\tTrain Loss: 1520.6707083333333\tTime: 0:00:00.086238\n",
      "Epoch: [79/100]\tSamples: [250/25000]\tValidation Loss: 1597.08540625\tTime: 0:00:00.012300\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.930634042395316\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2591.8418676758856\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1786.9755833333334\tTime: 0:00:00.087911\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1638.0774375\tTime: 0:00:00.012947\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1781.4886770833334\tTime: 0:00:00.083033\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1639.05121875\tTime: 0:00:00.012420\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1769.7710208333333\tTime: 0:00:00.085405\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1641.62971875\tTime: 0:00:00.012709\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1755.1829375\tTime: 0:00:00.085304\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1642.7219375\tTime: 0:00:00.012369\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1743.5949895833332\tTime: 0:00:00.082732\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1642.56046875\tTime: 0:00:00.013217\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1732.642375\tTime: 0:00:00.084473\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1639.29515625\tTime: 0:00:00.012295\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.880983824691029\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2835.392014283762\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1776.7087291666667\tTime: 0:00:00.087941\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1633.24115625\tTime: 0:00:00.012993\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1767.4700104166666\tTime: 0:00:00.086752\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1633.76640625\tTime: 0:00:00.012664\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1754.17390625\tTime: 0:00:00.088736\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1636.0265\tTime: 0:00:00.012905\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1745.0530833333332\tTime: 0:00:00.086381\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1637.81053125\tTime: 0:00:00.012547\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1732.4524375\tTime: 0:00:00.085772\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1637.11840625\tTime: 0:00:00.013790\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1718.70409375\tTime: 0:00:00.088787\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1635.2520625\tTime: 0:00:00.012718\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.92996033513607\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2815.464451162162\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1776.71275\tTime: 0:00:00.085732\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1663.84509375\tTime: 0:00:00.012625\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1767.5723854166667\tTime: 0:00:00.083547\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1664.3691875\tTime: 0:00:00.012419\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1754.8476770833333\tTime: 0:00:00.087227\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1665.83534375\tTime: 0:00:00.012798\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1740.185375\tTime: 0:00:00.085673\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1667.3939375\tTime: 0:00:00.015605\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1729.8159895833332\tTime: 0:00:00.084949\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1665.97521875\tTime: 0:00:00.013294\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1718.7105\tTime: 0:00:00.083690\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1660.85390625\tTime: 0:00:00.012481\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1700.6555416666667\tTime: 0:00:00.087182\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1660.531125\tTime: 0:00:00.012798\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1690.2876979166667\tTime: 0:00:00.084594\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1656.45415625\tTime: 0:00:00.012603\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1687.04725\tTime: 0:00:00.092418\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1654.66578125\tTime: 0:00:00.012880\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1681.75446875\tTime: 0:00:00.084112\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1649.5074375\tTime: 0:00:00.012632\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1670.6131666666668\tTime: 0:00:00.085589\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1648.34265625\tTime: 0:00:00.012831\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1661.5018541666666\tTime: 0:00:00.083347\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1641.27496875\tTime: 0:00:00.012530\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1652.6453333333334\tTime: 0:00:00.086674\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1635.70075\tTime: 0:00:00.012891\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1648.0976770833333\tTime: 0:00:00.090022\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1633.08259375\tTime: 0:00:00.012769\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1645.7947291666667\tTime: 0:00:00.086112\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1631.7681875\tTime: 0:00:00.012936\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1642.4310625\tTime: 0:00:00.086852\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1629.65615625\tTime: 0:00:00.012541\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1638.3659375\tTime: 0:00:00.084557\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1629.31525\tTime: 0:00:00.012820\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1633.9068020833333\tTime: 0:00:00.085526\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1629.13828125\tTime: 0:00:00.012464\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1631.27878125\tTime: 0:00:00.086129\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1627.868125\tTime: 0:00:00.012677\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1622.6827083333333\tTime: 0:00:00.084853\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1622.617\tTime: 0:00:00.015229\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1628.1335\tTime: 0:00:00.085280\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1622.4229375\tTime: 0:00:00.012823\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1616.17503125\tTime: 0:00:00.084370\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1616.97528125\tTime: 0:00:00.012405\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1612.8365729166667\tTime: 0:00:00.085754\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1618.84484375\tTime: 0:00:00.012833\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1610.8891666666666\tTime: 0:00:00.083888\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1615.4060625\tTime: 0:00:00.012544\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1615.0537395833333\tTime: 0:00:00.085240\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1612.51796875\tTime: 0:00:00.012656\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1610.7848333333334\tTime: 0:00:00.083217\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1612.13440625\tTime: 0:00:00.012446\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1603.90453125\tTime: 0:00:00.088284\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1613.23675\tTime: 0:00:00.015936\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1602.54725\tTime: 0:00:00.086932\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1608.463875\tTime: 0:00:00.012464\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1599.4445520833333\tTime: 0:00:00.085341\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1611.0473125\tTime: 0:00:00.012662\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1594.7630416666666\tTime: 0:00:00.084196\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1609.22140625\tTime: 0:00:00.012487\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1597.0751041666667\tTime: 0:00:00.084218\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1610.5025625\tTime: 0:00:00.013502\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1594.2733645833334\tTime: 0:00:00.084176\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1603.847875\tTime: 0:00:00.012522\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1592.9430833333333\tTime: 0:00:00.087933\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1606.3499375\tTime: 0:00:00.012719\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1588.65678125\tTime: 0:00:00.083585\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1606.61865625\tTime: 0:00:00.012469\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1588.96296875\tTime: 0:00:00.084989\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1606.2285625\tTime: 0:00:00.013421\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1583.3536979166668\tTime: 0:00:00.085368\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1604.365625\tTime: 0:00:00.012432\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1583.0818958333334\tTime: 0:00:00.084594\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1600.45359375\tTime: 0:00:00.015471\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1578.469125\tTime: 0:00:00.085412\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1601.0343125\tTime: 0:00:00.012781\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1577.9126979166667\tTime: 0:00:00.083513\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1600.54928125\tTime: 0:00:00.012266\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1577.0526979166666\tTime: 0:00:00.083275\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1601.686625\tTime: 0:00:00.013431\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1577.3668125\tTime: 0:00:00.083929\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1597.78275\tTime: 0:00:00.012378\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1576.8954895833333\tTime: 0:00:00.086205\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1603.81428125\tTime: 0:00:00.012895\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1573.296125\tTime: 0:00:00.086813\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1600.5265\tTime: 0:00:00.012862\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1568.0566041666666\tTime: 0:00:00.085301\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1598.5874375\tTime: 0:00:00.013564\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1569.9410729166666\tTime: 0:00:00.085797\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1598.835375\tTime: 0:00:00.012238\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1570.8114375\tTime: 0:00:00.083664\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1596.9784375\tTime: 0:00:00.012460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1564.9284375\tTime: 0:00:00.086030\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1594.869\tTime: 0:00:00.012815\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1561.9633229166666\tTime: 0:00:00.088522\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1593.08490625\tTime: 0:00:00.012561\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1558.2600208333333\tTime: 0:00:00.084334\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1592.36078125\tTime: 0:00:00.012770\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1557.0083541666668\tTime: 0:00:00.084166\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1592.739625\tTime: 0:00:00.015460\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1564.25615625\tTime: 0:00:00.087601\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1592.688625\tTime: 0:00:00.015944\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1557.7655416666666\tTime: 0:00:00.085010\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1595.337875\tTime: 0:00:00.012396\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1557.0187708333333\tTime: 0:00:00.085122\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1590.43490625\tTime: 0:00:00.013341\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1557.5285208333332\tTime: 0:00:00.083905\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1592.776625\tTime: 0:00:00.012502\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1557.3316145833332\tTime: 0:00:00.085159\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1592.1296875\tTime: 0:00:00.012651\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1554.8807916666667\tTime: 0:00:00.083706\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1588.869\tTime: 0:00:00.015597\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1554.7005729166667\tTime: 0:00:00.084648\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1589.991625\tTime: 0:00:00.012774\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1549.6949479166667\tTime: 0:00:00.083615\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1587.3100625\tTime: 0:00:00.012468\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1548.41284375\tTime: 0:00:00.086379\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1589.0789375\tTime: 0:00:00.012743\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1552.1717395833334\tTime: 0:00:00.084051\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1587.5846875\tTime: 0:00:00.012439\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1546.489625\tTime: 0:00:00.083253\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1591.6436875\tTime: 0:00:00.013190\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1549.7641354166667\tTime: 0:00:00.083759\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1584.681375\tTime: 0:00:00.012678\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1550.0441041666666\tTime: 0:00:00.087096\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1584.1943125\tTime: 0:00:00.012621\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1548.4573958333333\tTime: 0:00:00.083342\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1586.97525\tTime: 0:00:00.012517\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1544.0906979166666\tTime: 0:00:00.084403\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1584.7388125\tTime: 0:00:00.012662\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1546.8322395833334\tTime: 0:00:00.082484\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1582.4624375\tTime: 0:00:00.012378\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1544.1909270833332\tTime: 0:00:00.085561\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1583.2376875\tTime: 0:00:00.012590\n",
      "Epoch: [68/100]\tSamples: [51000/75000]\tTrain Loss: 1541.3858958333333\tTime: 0:00:00.085274\n",
      "Epoch: [68/100]\tSamples: [250/25000]\tValidation Loss: 1585.80178125\tTime: 0:00:00.012585\n",
      "Epoch: [69/100]\tSamples: [51750/75000]\tTrain Loss: 1540.3746458333333\tTime: 0:00:00.083712\n",
      "Epoch: [69/100]\tSamples: [250/25000]\tValidation Loss: 1581.9801875\tTime: 0:00:00.013524\n",
      "Epoch: [70/100]\tSamples: [52500/75000]\tTrain Loss: 1541.742\tTime: 0:00:00.085024\n",
      "Epoch: [70/100]\tSamples: [250/25000]\tValidation Loss: 1581.13421875\tTime: 0:00:00.012472\n",
      "Epoch: [71/100]\tSamples: [53250/75000]\tTrain Loss: 1540.2114166666668\tTime: 0:00:00.085200\n",
      "Epoch: [71/100]\tSamples: [250/25000]\tValidation Loss: 1579.8828125\tTime: 0:00:00.012662\n",
      "Epoch: [72/100]\tSamples: [54000/75000]\tTrain Loss: 1539.09328125\tTime: 0:00:00.083420\n",
      "Epoch: [72/100]\tSamples: [250/25000]\tValidation Loss: 1581.66303125\tTime: 0:00:00.012363\n",
      "Epoch: [73/100]\tSamples: [54750/75000]\tTrain Loss: 1539.0431666666666\tTime: 0:00:00.085346\n",
      "Epoch: [73/100]\tSamples: [250/25000]\tValidation Loss: 1583.71340625\tTime: 0:00:00.012836\n",
      "Epoch: [74/100]\tSamples: [55500/75000]\tTrain Loss: 1537.9763541666666\tTime: 0:00:00.086133\n",
      "Epoch: [74/100]\tSamples: [250/25000]\tValidation Loss: 1581.22959375\tTime: 0:00:00.012653\n",
      "Epoch: [75/100]\tSamples: [56250/75000]\tTrain Loss: 1544.2201145833333\tTime: 0:00:00.084685\n",
      "Epoch: [75/100]\tSamples: [250/25000]\tValidation Loss: 1579.56453125\tTime: 0:00:00.013171\n",
      "Epoch: [76/100]\tSamples: [57000/75000]\tTrain Loss: 1534.9678020833333\tTime: 0:00:00.086389\n",
      "Epoch: [76/100]\tSamples: [250/25000]\tValidation Loss: 1582.32740625\tTime: 0:00:00.012340\n",
      "Epoch: [77/100]\tSamples: [57750/75000]\tTrain Loss: 1535.0921145833333\tTime: 0:00:00.084658\n",
      "Epoch: [77/100]\tSamples: [250/25000]\tValidation Loss: 1579.973125\tTime: 0:00:00.012779\n",
      "Epoch: [78/100]\tSamples: [58500/75000]\tTrain Loss: 1536.34825\tTime: 0:00:00.083503\n",
      "Epoch: [78/100]\tSamples: [250/25000]\tValidation Loss: 1581.181625\tTime: 0:00:00.012677\n",
      "Epoch: [79/100]\tSamples: [59250/75000]\tTrain Loss: 1530.1777604166666\tTime: 0:00:00.083623\n",
      "Epoch: [79/100]\tSamples: [250/25000]\tValidation Loss: 1575.6510625\tTime: 0:00:00.013325\n",
      "Epoch: [80/100]\tSamples: [60000/75000]\tTrain Loss: 1538.431\tTime: 0:00:00.084084\n",
      "Epoch: [80/100]\tSamples: [250/25000]\tValidation Loss: 1580.46484375\tTime: 0:00:00.012591\n",
      "Epoch: [81/100]\tSamples: [60750/75000]\tTrain Loss: 1534.04046875\tTime: 0:00:00.087461\n",
      "Epoch: [81/100]\tSamples: [250/25000]\tValidation Loss: 1576.0930625\tTime: 0:00:00.012757\n",
      "Epoch: [82/100]\tSamples: [61500/75000]\tTrain Loss: 1534.9524270833333\tTime: 0:00:00.083296\n",
      "Epoch: [82/100]\tSamples: [250/25000]\tValidation Loss: 1574.8626875\tTime: 0:00:00.012535\n",
      "Epoch: [83/100]\tSamples: [62250/75000]\tTrain Loss: 1531.557625\tTime: 0:00:00.086971\n",
      "Epoch: [83/100]\tSamples: [250/25000]\tValidation Loss: 1582.24028125\tTime: 0:00:00.012786\n",
      "Epoch: [84/100]\tSamples: [63000/75000]\tTrain Loss: 1530.5478229166667\tTime: 0:00:00.085304\n",
      "Epoch: [84/100]\tSamples: [250/25000]\tValidation Loss: 1579.020875\tTime: 0:00:00.012559\n",
      "Epoch: [85/100]\tSamples: [63750/75000]\tTrain Loss: 1530.9303541666666\tTime: 0:00:00.084061\n",
      "Epoch: [85/100]\tSamples: [250/25000]\tValidation Loss: 1579.50840625\tTime: 0:00:00.013668\n",
      "Epoch: [86/100]\tSamples: [64500/75000]\tTrain Loss: 1530.2693333333334\tTime: 0:00:00.084143\n",
      "Epoch: [86/100]\tSamples: [250/25000]\tValidation Loss: 1579.4733125\tTime: 0:00:00.015380\n",
      "Epoch: [87/100]\tSamples: [65250/75000]\tTrain Loss: 1526.6778645833333\tTime: 0:00:00.085472\n",
      "Epoch: [87/100]\tSamples: [250/25000]\tValidation Loss: 1576.88346875\tTime: 0:00:00.012802\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.816422593442675\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2613.027792061037\u001b[0m\n",
      "Nodes averages betas and thetas inf:  7.882982939325212 2724.506360178815\n",
      "BASELINE\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m671.4755874485298\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "frozen_topics_list = [5,10,15,40]\n",
    "\n",
    "sim_betas_centralized = []\n",
    "sim_thetas_centralized = []\n",
    "sim_betas_non_colab = []\n",
    "sim_thetas_non_colab = []\n",
    "sim_thetas_baseline = []\n",
    "\n",
    "for frozen_topics in frozen_topics_list:\n",
    "    print(\"Executing for frozen topics \", str(frozen_topics))\n",
    "    \n",
    "    # Recalculate centralized settings\n",
    "    prior_frozen = frozen_topics * [alpha]\n",
    "    own_topics = int((n_topics-frozen_topics)/n_nodes)\n",
    "    prior_nofrozen = own_topics * [alpha] + (n_topics-frozen_topics-own_topics) * [alpha/10000]\n",
    "\n",
    "    centralized_settings = {\n",
    "        \"n_nodes\": n_nodes,\n",
    "        \"frozen_topics\": frozen_topics,\n",
    "        \"prior_frozen\": prior_frozen,\n",
    "        \"own_topics\": own_topics,\n",
    "        \"prior_nofrozen\": prior_nofrozen\n",
    "    }\n",
    "    \n",
    "    # Baseline doc-topics generation\n",
    "    topic_vectors, doc_topics_all, _ = generateSynthetic(True, False, **tm_settings, **centralized_settings)\n",
    "\n",
    "    for i in range(len(doc_topics_all)):\n",
    "        if i == 0:\n",
    "            thetas_bas = doc_topics_all[i]\n",
    "        else:\n",
    "            thetas_bas = np.concatenate((thetas_bas,doc_topics_all[i]))\n",
    "    print(\"Shape of thetas_bas\", str(thetas_bas.shape))\n",
    "    \n",
    "    # Generate documents\n",
    "    topic_vectors, doc_topics_all, documents_all = generateSynthetic(False, True, **tm_settings, **centralized_settings)\n",
    "    \n",
    "    # Generate inference corpus and its docs_topics\n",
    "    inf = [doc for docs_node in documents_all for doc in docs_node[n_docs:(n_docs+n_docs_global_inf)]]\n",
    "    print(\"Length of the inference corpus \", str(len(inf)))\n",
    "\n",
    "    for i in range(len(doc_topics_all)):\n",
    "        if i == 0:\n",
    "            inf_doc_topics = doc_topics_all[i][n_docs:(n_docs+n_docs_global_inf)]\n",
    "        else:\n",
    "            inf_doc_topics = np.concatenate((inf_doc_topics,doc_topics_all[i][n_docs:(n_docs+n_docs_global_inf)])) \n",
    "    print(\"Shape of inf_doc_topics\", str(inf_doc_topics.shape))\n",
    "    \n",
    "    ########################\n",
    "    # Centralized training #\n",
    "    ########################\n",
    "    print(\"CENTRALIZED\")\n",
    "    # Define corpus\n",
    "    corpus = [doc for docs_node in documents_all for doc in docs_node[0:n_docs]]\n",
    "    print(\"Size of centralized corpus \", str(len(corpus)))\n",
    "\n",
    "    # Train model \n",
    "    modelname = \"prod_centralized\"\n",
    "    modeldir, avitm, cv, id2token, idx2token = train_avitm(modelname, modelsdir, corpus)\n",
    "    \n",
    "    # Get betas\n",
    "    betas = avitm.get_topic_word_mat()#avitm.get_topic_word_distribution()\n",
    "    betas = softmax(betas, axis=1)\n",
    "    print(\"MAX BETAS: \", np.max(betas))\n",
    "    print(\"MIN BETAS: \", np.min(betas))\n",
    "    all_words = ['wd'+str(word) for word in np.arange(vocab_size+1) if word > 0]\n",
    "    betas = convert_topic_word_to_init_size(vocab_size=vocab_size,\n",
    "                                            model=avitm,\n",
    "                                            model_type=\"avitm\",\n",
    "                                            ntopics=n_topics,\n",
    "                                            id2token=id2token,\n",
    "                                            all_words=all_words)\n",
    "\n",
    "    # Get thetas\n",
    "    #thetas = np.asarray(avitm.get_doc_topic_distribution(avitm.train_data))[0:n_docs,:]\n",
    "    #thetas_theoretical = doc_topics_all[0][0:n_docs]\n",
    "\n",
    "    # Eval betas and thetas\n",
    "    betas_31 = eval_betas(betas, topic_vectors)\n",
    "    #thetas_31 = eval_thetas(thetas_theoretical, thetas, len(thetas))\n",
    "    sim_betas_centralized.append(betas_31)\n",
    "    \n",
    "    # Inference\n",
    "    # Get inferred thetas\n",
    "    docs_val_conv = [\" \".join(inf[i]) for i in np.arange(len(inf))]\n",
    "    val_bow = cv.transform(docs_val_conv)\n",
    "    val_bow = val_bow.toarray()\n",
    "    val_data = BOWDataset(val_bow, idx2token)\n",
    "\n",
    "    thetas_inf = np.asarray(avitm.get_thetas(val_data))#get_doc_topic_distribution\n",
    "    thetas_theoretical = inf_doc_topics\n",
    "\n",
    "    # Eval thetas\n",
    "    thetas_312 = eval_thetas(thetas_theoretical, thetas_inf, len(thetas_inf))\n",
    "    sim_thetas_centralized.append(thetas_312)\n",
    "    \n",
    "    #############################\n",
    "    # Non-colaborative training #\n",
    "    #############################\n",
    "    betas_nodes = []\n",
    "    thetas_nodes = []\n",
    "    for node in range(n_nodes):\n",
    "        print(\"NON-COLLABORATIVE of node \", str(node))\n",
    "        # Define corpus\n",
    "        corpus = documents_all[node][0:n_docs]\n",
    "        print(\"Size of non-collaborative corpus \", str(len(corpus)))\n",
    "\n",
    "        # Train model \n",
    "        modelname = \"prodlda_node\"\n",
    "        modeldir, avitm, cv, id2token, idx2token = train_avitm(modelname, modelsdir, corpus)\n",
    "\n",
    "        # Get betas\n",
    "        betas = avitm.get_topic_word_mat()#avitm.get_topic_word_distribution()\n",
    "        betas = softmax(betas, axis=1)\n",
    "        all_words = ['wd'+str(word) for word in np.arange(vocab_size+1) if word > 0]\n",
    "        betas = convert_topic_word_to_init_size(vocab_size=vocab_size,\n",
    "                                                model=avitm,\n",
    "                                                model_type=\"avitm\",\n",
    "                                                ntopics=n_topics,\n",
    "                                                id2token=id2token,\n",
    "                                                all_words=all_words)\n",
    "\n",
    "        # Get thetas\n",
    "        #thetas = np.asarray(avitm.get_doc_topic_distribution(avitm.train_data))\n",
    "        #thetas_theoretical = doc_topics_all[0][0:n_docs]\n",
    "\n",
    "\n",
    "        # Eval betas and thetas\n",
    "        betas_32 = eval_betas(betas, topic_vectors)\n",
    "        betas_nodes.append(betas_32)\n",
    "\n",
    "        #thetas_32 = eval_thetas(thetas_theoretical, thetas, len(thetas))\n",
    "\n",
    "        # Inference\n",
    "        # Get inferred thetas\n",
    "        docs_val_conv = [\" \".join(inf[i]) for i in np.arange(len(inf))]\n",
    "        val_bow = cv.transform(docs_val_conv)\n",
    "        val_bow = val_bow.toarray()\n",
    "        val_data = BOWDataset(val_bow, idx2token)\n",
    "\n",
    "        thetas_inf = np.asarray(avitm.get_thetas(val_data))#get_doc_topic_distribution\n",
    "\n",
    "        thetas_theoretical = inf_doc_topics\n",
    "\n",
    "        # Eval thetas\n",
    "        thetas_322 = eval_thetas(thetas_theoretical, thetas_inf, len(thetas_inf))\n",
    "        thetas_nodes.append(thetas_322)\n",
    "    \n",
    "    avg1 = sum(betas_nodes)/n_nodes\n",
    "    avg2 = sum(thetas_nodes)/n_nodes\n",
    "    sim_betas_non_colab.append(avg1)\n",
    "    print(\"Nodes averages betas and thetas inf: \", str(avg1), str(avg2))\n",
    "    sim_thetas_non_colab.append(avg2)\n",
    "    \n",
    "    ########################\n",
    "    #       Baseline       #\n",
    "    ########################\n",
    "    print(\"BASELINE\")\n",
    "    thetas_theoretical = inf_doc_topics\n",
    "    thetas_baseline = eval_thetas(thetas_theoretical, thetas_bas, len(thetas_bas))\n",
    "    sim_thetas_baseline.append(thetas_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e8be89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.569492878037615, 8.499583087413269, 8.503066902676839, 8.409831097753043]\n",
      "[6.54351305650348, 6.886096853139499, 7.160872773837665, 7.882982939325212]\n"
     ]
    }
   ],
   "source": [
    "print(sim_betas_centralized)\n",
    "print(sim_betas_non_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "241bf025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 267,
       "width": 401
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(frozen_topics_list, sim_thetas_centralized, label=\"Prod-Centr\", marker=\"x\")\n",
    "plt.semilogx(frozen_topics_list, sim_thetas_non_colab, label=\"Prod-Non-Collaborative\", marker=\"x\")\n",
    "#plt.plot(frozen_topics_list, sim_thetas_baseline, label=\"Baseline\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.xlabel('Number of common topics', fontsize=16)\n",
    "plt.ylabel('Doc similarity score', fontsize=16)\n",
    "plt.xticks(frozen_topics_list, [5,10,15,40])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1861bc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 274,
       "width": 398
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(frozen_topics_list, sim_betas_centralized, label=\"Prod-Centr\")\n",
    "plt.plot(frozen_topics_list, sim_betas_non_colab, label=\"Prod-Non-Collaborative\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.xlabel('Number of common topics', fontsize=16)\n",
    "plt.ylabel('Topics correctly identified', fontsize=16)\n",
    "plt.xticks(frozen_topics_list, [5,10,15,40])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97f7367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing for eta equals to  0.01\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:48<00:00, 40.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:49<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 20)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1661.918875\tTime: 0:00:00.431487\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1611.928678125\tTime: 0:00:00.059181\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1545.0308875\tTime: 0:00:00.422055\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1482.83561875\tTime: 0:00:00.077948\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1504.6511020833334\tTime: 0:00:00.420083\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1460.824390625\tTime: 0:00:00.075642\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1486.5191760416667\tTime: 0:00:00.412250\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1449.23605625\tTime: 0:00:00.062407\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1472.3179416666667\tTime: 0:00:00.420410\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1431.607140625\tTime: 0:00:00.059540\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1459.2307395833334\tTime: 0:00:00.412875\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1425.4746875\tTime: 0:00:00.061744\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1450.2124135416666\tTime: 0:00:00.417941\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1413.924928125\tTime: 0:00:00.059977\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1442.4606385416666\tTime: 0:00:00.413750\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1410.06\tTime: 0:00:00.062322\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1437.6530947916667\tTime: 0:00:00.419700\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1404.449971875\tTime: 0:00:00.060789\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1428.3425041666667\tTime: 0:00:00.414279\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1394.60345625\tTime: 0:00:00.061721\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1426.9944958333333\tTime: 0:00:00.424070\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1392.101515625\tTime: 0:00:00.060306\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1420.1498375\tTime: 0:00:00.417051\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1388.37441875\tTime: 0:00:00.061798\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1416.562096875\tTime: 0:00:00.438534\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1384.82083125\tTime: 0:00:00.061591\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1416.5951885416666\tTime: 0:00:00.416922\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1379.608296875\tTime: 0:00:00.079171\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1413.228625\tTime: 0:00:00.418325\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1384.655646875\tTime: 0:00:00.060709\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1411.893440625\tTime: 0:00:00.413209\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1381.573334375\tTime: 0:00:00.060887\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1406.645725\tTime: 0:00:00.418191\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1373.21958125\tTime: 0:00:00.059964\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1408.3109697916666\tTime: 0:00:00.432519\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1376.106096875\tTime: 0:00:00.073813\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1404.01295625\tTime: 0:00:00.424959\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1374.56295\tTime: 0:00:00.059652\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1402.60266875\tTime: 0:00:00.421001\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1372.736171875\tTime: 0:00:00.061535\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1403.9721229166666\tTime: 0:00:00.422929\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1372.569859375\tTime: 0:00:00.060159\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1401.1522979166666\tTime: 0:00:00.417240\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1371.877440625\tTime: 0:00:00.078172\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1403.2233854166666\tTime: 0:00:00.433738\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1369.666634375\tTime: 0:00:00.078241\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1401.1741541666668\tTime: 0:00:00.566646\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1371.758590625\tTime: 0:00:00.061419\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1402.37930625\tTime: 0:00:00.422049\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1373.11134375\tTime: 0:00:00.060587\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1401.2170614583333\tTime: 0:00:00.421531\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1371.90903125\tTime: 0:00:00.061593\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1399.3729333333333\tTime: 0:00:00.426022\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1372.65071875\tTime: 0:00:00.061304\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1399.913271875\tTime: 0:00:00.424136\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1368.101103125\tTime: 0:00:00.061632\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1397.4865354166666\tTime: 0:00:00.440548\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1373.89763125\tTime: 0:00:00.061526\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1394.0860395833333\tTime: 0:00:00.419865\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1362.377353125\tTime: 0:00:00.062867\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1395.6882322916667\tTime: 0:00:00.425662\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1369.9653625\tTime: 0:00:00.061480\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1395.2451760416666\tTime: 0:00:00.422225\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1366.12390625\tTime: 0:00:00.068604\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1396.3369458333334\tTime: 0:00:00.428901\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1363.64898125\tTime: 0:00:00.061920\n",
      "Epoch: [34/100]\tSamples: [127500/375000]\tTrain Loss: 1395.856053125\tTime: 0:00:00.418892\n",
      "Epoch: [34/100]\tSamples: [1250/125000]\tValidation Loss: 1362.6936875\tTime: 0:00:00.064148\n",
      "Epoch: [35/100]\tSamples: [131250/375000]\tTrain Loss: 1396.9199979166667\tTime: 0:00:00.419769\n",
      "Epoch: [35/100]\tSamples: [1250/125000]\tValidation Loss: 1361.616875\tTime: 0:00:00.079071\n",
      "Epoch: [36/100]\tSamples: [135000/375000]\tTrain Loss: 1396.2845708333334\tTime: 0:00:00.427905\n",
      "Epoch: [36/100]\tSamples: [1250/125000]\tValidation Loss: 1363.903271875\tTime: 0:00:00.063243\n",
      "Epoch: [37/100]\tSamples: [138750/375000]\tTrain Loss: 1393.4315479166667\tTime: 0:00:00.427038\n",
      "Epoch: [37/100]\tSamples: [1250/125000]\tValidation Loss: 1362.85604375\tTime: 0:00:00.078686\n",
      "Epoch: [38/100]\tSamples: [142500/375000]\tTrain Loss: 1393.715409375\tTime: 0:00:00.421581\n",
      "Epoch: [38/100]\tSamples: [1250/125000]\tValidation Loss: 1359.542771875\tTime: 0:00:00.062766\n",
      "Epoch: [39/100]\tSamples: [146250/375000]\tTrain Loss: 1394.51625\tTime: 0:00:00.452160\n",
      "Epoch: [39/100]\tSamples: [1250/125000]\tValidation Loss: 1362.38989375\tTime: 0:00:00.061611\n",
      "Epoch: [40/100]\tSamples: [150000/375000]\tTrain Loss: 1393.4441\tTime: 0:00:00.422009\n",
      "Epoch: [40/100]\tSamples: [1250/125000]\tValidation Loss: 1362.822859375\tTime: 0:00:00.062137\n",
      "Epoch: [41/100]\tSamples: [153750/375000]\tTrain Loss: 1390.6931479166667\tTime: 0:00:00.425769\n",
      "Epoch: [41/100]\tSamples: [1250/125000]\tValidation Loss: 1360.89106875\tTime: 0:00:00.061618\n",
      "Epoch: [42/100]\tSamples: [157500/375000]\tTrain Loss: 1392.9237072916667\tTime: 0:00:00.425578\n",
      "Epoch: [42/100]\tSamples: [1250/125000]\tValidation Loss: 1364.82831875\tTime: 0:00:00.063521\n",
      "Epoch: [43/100]\tSamples: [161250/375000]\tTrain Loss: 1390.59728125\tTime: 0:00:00.436744\n",
      "Epoch: [43/100]\tSamples: [1250/125000]\tValidation Loss: 1360.1222125\tTime: 0:00:00.062024\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m7.48790820163805\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2127.826984901447\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1660.3941041666667\tTime: 0:00:00.091337\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1575.22696875\tTime: 0:00:00.012171\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1621.7773333333334\tTime: 0:00:00.088860\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1588.00378125\tTime: 0:00:00.012309\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1573.472\tTime: 0:00:00.091559\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1592.50896875\tTime: 0:00:00.012106\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1538.9836979166666\tTime: 0:00:00.089648\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1571.7765\tTime: 0:00:00.012222\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1508.2769166666667\tTime: 0:00:00.089678\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1536.337625\tTime: 0:00:00.012083\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1486.1121354166667\tTime: 0:00:00.088073\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1490.71184375\tTime: 0:00:00.012226\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1466.7690729166666\tTime: 0:00:00.090706\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1460.99525\tTime: 0:00:00.012116\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1457.8606770833333\tTime: 0:00:00.092857\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1441.30696875\tTime: 0:00:00.012115\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1444.8387083333334\tTime: 0:00:00.091702\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1430.368125\tTime: 0:00:00.012332\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1436.1376041666667\tTime: 0:00:00.090851\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1426.97128125\tTime: 0:00:00.014964\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1425.84184375\tTime: 0:00:00.092355\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1412.0971875\tTime: 0:00:00.012127\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1417.230484375\tTime: 0:00:00.090259\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1403.36015625\tTime: 0:00:00.012773\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1413.647\tTime: 0:00:00.088237\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1398.5606875\tTime: 0:00:00.012129\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1411.6087708333334\tTime: 0:00:00.090807\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1393.19328125\tTime: 0:00:00.013064\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1397.513671875\tTime: 0:00:00.087774\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1391.336625\tTime: 0:00:00.012121\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1399.0493333333334\tTime: 0:00:00.090364\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1388.88565625\tTime: 0:00:00.012250\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1396.6140416666667\tTime: 0:00:00.094680\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1389.95209375\tTime: 0:00:00.012156\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1393.3758541666666\tTime: 0:00:00.089194\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1377.2208125\tTime: 0:00:00.012001\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1387.5429479166667\tTime: 0:00:00.088573\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1383.327625\tTime: 0:00:00.014679\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1382.87490625\tTime: 0:00:00.091573\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1377.6143125\tTime: 0:00:00.012110\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1380.1633802083334\tTime: 0:00:00.090568\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1377.87065625\tTime: 0:00:00.015170\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1383.3946197916666\tTime: 0:00:00.091632\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1379.45903125\tTime: 0:00:00.012246\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1372.2585\tTime: 0:00:00.089888\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1377.89646875\tTime: 0:00:00.012220\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.250335720392737\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2153.4362801455045\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1681.32965625\tTime: 0:00:00.088160\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1566.7359375\tTime: 0:00:00.012590\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1634.7244583333334\tTime: 0:00:00.088085\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1582.26865625\tTime: 0:00:00.014857\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1592.26621875\tTime: 0:00:00.090832\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1586.2218125\tTime: 0:00:00.012558\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1551.8000625\tTime: 0:00:00.088017\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1564.64559375\tTime: 0:00:00.012517\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1520.9529791666666\tTime: 0:00:00.096063\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1524.70409375\tTime: 0:00:00.012616\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1499.795\tTime: 0:00:00.090743\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1477.063375\tTime: 0:00:00.012205\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1484.46503125\tTime: 0:00:00.089932\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1445.41834375\tTime: 0:00:00.015187\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1473.2098645833332\tTime: 0:00:00.088226\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1426.0405\tTime: 0:00:00.012125\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1465.9891145833333\tTime: 0:00:00.089994\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1411.6773125\tTime: 0:00:00.012372\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1447.141921875\tTime: 0:00:00.091711\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1404.096875\tTime: 0:00:00.012179\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1440.5293697916666\tTime: 0:00:00.089365\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1397.01253125\tTime: 0:00:00.012387\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1432.4540989583334\tTime: 0:00:00.087795\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1393.61746875\tTime: 0:00:00.012256\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1428.1209739583333\tTime: 0:00:00.089145\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1387.01771875\tTime: 0:00:00.012361\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1425.7011770833333\tTime: 0:00:00.086824\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1378.33175\tTime: 0:00:00.012161\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1422.1906354166667\tTime: 0:00:00.088774\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1379.70915625\tTime: 0:00:00.015179\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1422.98865625\tTime: 0:00:00.091057\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1372.39071875\tTime: 0:00:00.014832\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1415.1088177083334\tTime: 0:00:00.090371\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1372.65025\tTime: 0:00:00.012578\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1410.3590833333333\tTime: 0:00:00.089915\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1370.7905\tTime: 0:00:00.012210\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1407.4833541666667\tTime: 0:00:00.089208\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1369.93446875\tTime: 0:00:00.012237\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1403.3873802083333\tTime: 0:00:00.103447\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1369.13321875\tTime: 0:00:00.014978\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1409.9929270833334\tTime: 0:00:00.104183\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1363.078875\tTime: 0:00:00.014908\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1397.7954166666666\tTime: 0:00:00.102249\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1364.1715625\tTime: 0:00:00.012422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1399.5378385416666\tTime: 0:00:00.088218\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1363.54796875\tTime: 0:00:00.012435\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1395.0648020833332\tTime: 0:00:00.087142\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1362.53109375\tTime: 0:00:00.012544\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1390.5323385416666\tTime: 0:00:00.101774\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1355.914625\tTime: 0:00:00.015076\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1391.880484375\tTime: 0:00:00.089438\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1359.64721875\tTime: 0:00:00.012227\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1391.92875\tTime: 0:00:00.091361\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1357.01753125\tTime: 0:00:00.015376\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1388.743109375\tTime: 0:00:00.089529\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1361.2830625\tTime: 0:00:00.012265\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1389.0795364583332\tTime: 0:00:00.088831\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1353.92453125\tTime: 0:00:00.012482\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1388.586328125\tTime: 0:00:00.087476\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1355.327125\tTime: 0:00:00.012324\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1385.1252395833333\tTime: 0:00:00.094536\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1351.32265625\tTime: 0:00:00.012424\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1385.83246875\tTime: 0:00:00.087579\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1356.73921875\tTime: 0:00:00.014976\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1384.948703125\tTime: 0:00:00.090278\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1357.510375\tTime: 0:00:00.015108\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1379.89228125\tTime: 0:00:00.090741\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1353.000875\tTime: 0:00:00.012307\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1382.0344270833334\tTime: 0:00:00.089378\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1350.82834375\tTime: 0:00:00.012305\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1381.58425\tTime: 0:00:00.103946\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1348.85053125\tTime: 0:00:00.015099\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1380.22428125\tTime: 0:00:00.090265\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1353.62996875\tTime: 0:00:00.012531\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1380.3753541666667\tTime: 0:00:00.088384\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1346.5150625\tTime: 0:00:00.012369\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1378.31409375\tTime: 0:00:00.090541\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1349.84184375\tTime: 0:00:00.012524\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1374.6779010416667\tTime: 0:00:00.086826\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1346.279625\tTime: 0:00:00.014978\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1378.3451822916666\tTime: 0:00:00.090030\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1354.7053125\tTime: 0:00:00.012537\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1381.797453125\tTime: 0:00:00.090651\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1348.65921875\tTime: 0:00:00.012264\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1382.85815625\tTime: 0:00:00.088998\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1350.2569375\tTime: 0:00:00.012466\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1370.162546875\tTime: 0:00:00.089793\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1352.8480625\tTime: 0:00:00.012412\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1371.923578125\tTime: 0:00:00.091457\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1349.9818125\tTime: 0:00:00.012405\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.218003596866104\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2250.603479391145\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1664.6017291666667\tTime: 0:00:00.089142\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1563.5859375\tTime: 0:00:00.012079\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1616.0644895833334\tTime: 0:00:00.089450\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1578.87796875\tTime: 0:00:00.011964\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1566.3435208333333\tTime: 0:00:00.088015\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1580.34634375\tTime: 0:00:00.012154\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1530.2639791666666\tTime: 0:00:00.086715\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1556.5625\tTime: 0:00:00.012060\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1507.1165\tTime: 0:00:00.091344\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1513.87553125\tTime: 0:00:00.012233\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1490.6139479166666\tTime: 0:00:00.088533\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1465.36771875\tTime: 0:00:00.011950\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1466.9920729166668\tTime: 0:00:00.088210\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1432.69278125\tTime: 0:00:00.012355\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1451.8040104166666\tTime: 0:00:00.089494\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1415.3776875\tTime: 0:00:00.012016\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1440.9682708333332\tTime: 0:00:00.097170\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1399.31321875\tTime: 0:00:00.012253\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1435.4158645833334\tTime: 0:00:00.092486\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1387.950625\tTime: 0:00:00.012000\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1427.7309895833334\tTime: 0:00:00.089343\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1384.56421875\tTime: 0:00:00.011984\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1423.4944427083333\tTime: 0:00:00.087612\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1376.541625\tTime: 0:00:00.014631\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1420.1585104166666\tTime: 0:00:00.090091\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1370.75090625\tTime: 0:00:00.012051\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1413.0126145833333\tTime: 0:00:00.087506\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1368.79909375\tTime: 0:00:00.012358\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1407.2075364583334\tTime: 0:00:00.091296\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1363.52634375\tTime: 0:00:00.011937\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1401.060078125\tTime: 0:00:00.088580\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1358.16984375\tTime: 0:00:00.012183\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1396.828296875\tTime: 0:00:00.090871\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1365.0664375\tTime: 0:00:00.012199\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1399.9002864583333\tTime: 0:00:00.088861\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1355.82575\tTime: 0:00:00.014672\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1397.4006875\tTime: 0:00:00.089619\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1357.96609375\tTime: 0:00:00.012204\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1389.707078125\tTime: 0:00:00.088649\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1359.74259375\tTime: 0:00:00.012161\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1392.579125\tTime: 0:00:00.094199\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1353.505375\tTime: 0:00:00.014590\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1387.81865625\tTime: 0:00:00.090746\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1350.7776875\tTime: 0:00:00.014868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1385.52175\tTime: 0:00:00.090124\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1344.277625\tTime: 0:00:00.014772\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1383.354578125\tTime: 0:00:00.089152\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1348.64371875\tTime: 0:00:00.014659\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1380.9956041666667\tTime: 0:00:00.091031\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1347.496625\tTime: 0:00:00.012335\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1380.3148385416666\tTime: 0:00:00.086841\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1343.59478125\tTime: 0:00:00.012411\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1380.2859322916668\tTime: 0:00:00.086177\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1345.37896875\tTime: 0:00:00.012192\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1376.61946875\tTime: 0:00:00.088257\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1345.739\tTime: 0:00:00.012015\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1380.1628854166668\tTime: 0:00:00.090590\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1346.532\tTime: 0:00:00.012001\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1372.1411666666668\tTime: 0:00:00.088576\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1348.46465625\tTime: 0:00:00.011928\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1370.6761979166668\tTime: 0:00:00.090169\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1344.18678125\tTime: 0:00:00.012201\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.217250619999482\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2112.7979115086164\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1668.1144166666666\tTime: 0:00:00.087418\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1531.5285625\tTime: 0:00:00.012387\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1626.7344791666667\tTime: 0:00:00.088984\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1544.2166875\tTime: 0:00:00.012123\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1579.1303229166667\tTime: 0:00:00.089119\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1546.4004375\tTime: 0:00:00.012246\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1544.2715416666667\tTime: 0:00:00.088192\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1529.55728125\tTime: 0:00:00.012050\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1510.74240625\tTime: 0:00:00.091930\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1491.5535625\tTime: 0:00:00.012121\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1489.7652083333332\tTime: 0:00:00.090215\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1448.10009375\tTime: 0:00:00.014572\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1474.0263229166667\tTime: 0:00:00.089471\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1418.831875\tTime: 0:00:00.015129\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1458.03090625\tTime: 0:00:00.088304\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1397.0386875\tTime: 0:00:00.012334\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1447.7899791666666\tTime: 0:00:00.090772\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1384.84565625\tTime: 0:00:00.012390\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1437.5278645833334\tTime: 0:00:00.088560\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1377.5305\tTime: 0:00:00.012150\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1430.415125\tTime: 0:00:00.105684\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1373.57615625\tTime: 0:00:00.013281\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1424.2087916666667\tTime: 0:00:00.091219\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1366.733\tTime: 0:00:00.012129\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1417.690875\tTime: 0:00:00.090741\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1363.96184375\tTime: 0:00:00.012245\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1415.433328125\tTime: 0:00:00.089124\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1360.96059375\tTime: 0:00:00.011966\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1410.0878020833334\tTime: 0:00:00.089682\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1359.9901875\tTime: 0:00:00.012374\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1409.9730833333333\tTime: 0:00:00.089243\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1356.1239375\tTime: 0:00:00.012274\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1401.5307604166667\tTime: 0:00:00.091007\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1358.38965625\tTime: 0:00:00.014731\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1401.4302447916666\tTime: 0:00:00.088589\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1358.65903125\tTime: 0:00:00.011984\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1395.6992447916666\tTime: 0:00:00.089410\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1351.97546875\tTime: 0:00:00.012525\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1395.1107135416667\tTime: 0:00:00.089222\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1348.49375\tTime: 0:00:00.012033\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1391.2848489583334\tTime: 0:00:00.090993\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1349.66471875\tTime: 0:00:00.012464\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1390.6247864583333\tTime: 0:00:00.088431\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1345.433125\tTime: 0:00:00.011996\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1388.7841666666666\tTime: 0:00:00.090341\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1344.52803125\tTime: 0:00:00.012518\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1384.8061770833333\tTime: 0:00:00.089273\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1342.428625\tTime: 0:00:00.014828\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1383.78096875\tTime: 0:00:00.089097\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1338.6614375\tTime: 0:00:00.015149\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1383.5188385416666\tTime: 0:00:00.087293\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1341.35903125\tTime: 0:00:00.012030\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1382.4217708333333\tTime: 0:00:00.089635\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1339.3425625\tTime: 0:00:00.012296\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1386.5775416666668\tTime: 0:00:00.089853\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1335.47328125\tTime: 0:00:00.012199\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1380.035359375\tTime: 0:00:00.091478\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1335.1881875\tTime: 0:00:00.012227\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1376.1460416666666\tTime: 0:00:00.091335\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1336.895875\tTime: 0:00:00.012767\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1374.0539583333334\tTime: 0:00:00.094423\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1333.7868125\tTime: 0:00:00.012424\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1381.0194739583333\tTime: 0:00:00.090562\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1333.15015625\tTime: 0:00:00.011973\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1372.0778854166667\tTime: 0:00:00.088015\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1335.0425625\tTime: 0:00:00.012416\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1369.4696875\tTime: 0:00:00.092338\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1336.33228125\tTime: 0:00:00.012209\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1371.3048697916668\tTime: 0:00:00.089300\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1331.015\tTime: 0:00:00.012254\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1375.930234375\tTime: 0:00:00.087108\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1334.37871875\tTime: 0:00:00.012385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1368.1661666666666\tTime: 0:00:00.088159\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1335.983875\tTime: 0:00:00.012321\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1365.18934375\tTime: 0:00:00.087658\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1332.64896875\tTime: 0:00:00.014813\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1369.9045833333332\tTime: 0:00:00.090750\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1329.1305625\tTime: 0:00:00.012910\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1365.8764791666667\tTime: 0:00:00.091858\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1333.9825\tTime: 0:00:00.012256\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1367.1751510416666\tTime: 0:00:00.087981\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1333.19353125\tTime: 0:00:00.012478\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1366.8305\tTime: 0:00:00.089371\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1330.4330625\tTime: 0:00:00.014945\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1363.6543802083334\tTime: 0:00:00.089515\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1326.987375\tTime: 0:00:00.015041\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1363.8146354166668\tTime: 0:00:00.092147\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1329.8424375\tTime: 0:00:00.014741\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1363.5745364583333\tTime: 0:00:00.094444\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1326.463625\tTime: 0:00:00.012240\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1359.6215572916667\tTime: 0:00:00.093248\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1331.1320625\tTime: 0:00:00.012067\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1364.3250729166666\tTime: 0:00:00.089861\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1323.96003125\tTime: 0:00:00.015254\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1363.8890677083334\tTime: 0:00:00.090782\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1325.85278125\tTime: 0:00:00.012998\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1363.7630677083334\tTime: 0:00:00.091079\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1333.3175\tTime: 0:00:00.015257\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1362.709203125\tTime: 0:00:00.089508\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1328.7106875\tTime: 0:00:00.012255\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1360.6664270833332\tTime: 0:00:00.088596\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1328.503375\tTime: 0:00:00.012360\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1359.105328125\tTime: 0:00:00.089425\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1321.27784375\tTime: 0:00:00.012433\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1362.2098229166666\tTime: 0:00:00.091606\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1324.1431875\tTime: 0:00:00.012364\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1360.5419635416667\tTime: 0:00:00.087751\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1327.13190625\tTime: 0:00:00.012156\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1356.8614010416666\tTime: 0:00:00.089390\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1328.62390625\tTime: 0:00:00.012311\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1358.0759635416666\tTime: 0:00:00.088857\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1320.202625\tTime: 0:00:00.012152\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1352.4281666666666\tTime: 0:00:00.091745\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1327.4129375\tTime: 0:00:00.015047\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1357.7269375\tTime: 0:00:00.093484\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1323.51159375\tTime: 0:00:00.012046\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1353.2070729166667\tTime: 0:00:00.089305\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1317.9353125\tTime: 0:00:00.012417\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1351.3501510416668\tTime: 0:00:00.090647\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1319.61978125\tTime: 0:00:00.014801\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1349.8207135416667\tTime: 0:00:00.090353\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1323.86359375\tTime: 0:00:00.012316\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1348.33303125\tTime: 0:00:00.089515\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1317.730625\tTime: 0:00:00.012083\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1353.4484010416666\tTime: 0:00:00.089359\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1324.557\tTime: 0:00:00.012634\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1350.1117760416666\tTime: 0:00:00.088673\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1314.5459375\tTime: 0:00:00.014930\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1353.692828125\tTime: 0:00:00.090856\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1319.13409375\tTime: 0:00:00.012396\n",
      "Epoch: [66/100]\tSamples: [49500/75000]\tTrain Loss: 1350.475953125\tTime: 0:00:00.088428\n",
      "Epoch: [66/100]\tSamples: [250/25000]\tValidation Loss: 1317.3271875\tTime: 0:00:00.012252\n",
      "Epoch: [67/100]\tSamples: [50250/75000]\tTrain Loss: 1352.1378697916666\tTime: 0:00:00.087708\n",
      "Epoch: [67/100]\tSamples: [250/25000]\tValidation Loss: 1317.915\tTime: 0:00:00.012340\n",
      "Epoch: [68/100]\tSamples: [51000/75000]\tTrain Loss: 1352.3924114583333\tTime: 0:00:00.087430\n",
      "Epoch: [68/100]\tSamples: [250/25000]\tValidation Loss: 1317.33315625\tTime: 0:00:00.012168\n",
      "Epoch: [69/100]\tSamples: [51750/75000]\tTrain Loss: 1353.177875\tTime: 0:00:00.091143\n",
      "Epoch: [69/100]\tSamples: [250/25000]\tValidation Loss: 1321.84871875\tTime: 0:00:00.012304\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.2559337715722\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2388.595085015866\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1666.97328125\tTime: 0:00:00.091599\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1547.28484375\tTime: 0:00:00.012211\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1628.4527395833334\tTime: 0:00:00.101822\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1564.91659375\tTime: 0:00:00.012677\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1586.5419791666666\tTime: 0:00:00.088878\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1569.91225\tTime: 0:00:00.012205\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1549.0348541666667\tTime: 0:00:00.089579\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1548.98353125\tTime: 0:00:00.012032\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1519.1376458333334\tTime: 0:00:00.087779\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1510.46703125\tTime: 0:00:00.011766\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1490.3349166666667\tTime: 0:00:00.090582\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1467.17040625\tTime: 0:00:00.012129\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1476.2538541666668\tTime: 0:00:00.087968\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1438.81125\tTime: 0:00:00.014417\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1464.4411770833333\tTime: 0:00:00.089636\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1416.75753125\tTime: 0:00:00.012120\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1456.2368541666667\tTime: 0:00:00.089400\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1405.76678125\tTime: 0:00:00.011846\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1449.3302708333333\tTime: 0:00:00.090684\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1391.1840625\tTime: 0:00:00.011901\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1438.7034791666667\tTime: 0:00:00.090058\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1388.602\tTime: 0:00:00.011955\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1430.216546875\tTime: 0:00:00.086929\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1381.57815625\tTime: 0:00:00.015008\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1426.3590104166667\tTime: 0:00:00.088419\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1378.50771875\tTime: 0:00:00.012597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1422.356375\tTime: 0:00:00.088248\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1376.3429375\tTime: 0:00:00.012155\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1419.4046041666666\tTime: 0:00:00.089832\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1368.47940625\tTime: 0:00:00.014807\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1406.3789791666666\tTime: 0:00:00.090942\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1368.145625\tTime: 0:00:00.014959\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1402.2508802083332\tTime: 0:00:00.089533\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1358.04353125\tTime: 0:00:00.011961\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1406.5926510416666\tTime: 0:00:00.088422\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1358.30634375\tTime: 0:00:00.012130\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1400.8625364583334\tTime: 0:00:00.088811\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1355.6821875\tTime: 0:00:00.011918\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1395.7345677083333\tTime: 0:00:00.089088\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1354.16315625\tTime: 0:00:00.012175\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1393.8051614583333\tTime: 0:00:00.088003\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1355.3201875\tTime: 0:00:00.011782\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1387.3884479166666\tTime: 0:00:00.088369\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1346.68334375\tTime: 0:00:00.012387\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1386.732640625\tTime: 0:00:00.087865\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1349.57371875\tTime: 0:00:00.011927\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1390.2466770833332\tTime: 0:00:00.092504\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1345.2853125\tTime: 0:00:00.012140\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1387.40959375\tTime: 0:00:00.087737\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1345.32065625\tTime: 0:00:00.011920\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1388.0632291666666\tTime: 0:00:00.091905\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1343.6446875\tTime: 0:00:00.014821\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1383.37225\tTime: 0:00:00.088909\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1345.40390625\tTime: 0:00:00.011883\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1386.9655208333334\tTime: 0:00:00.089531\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1338.06809375\tTime: 0:00:00.012583\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1380.6210520833333\tTime: 0:00:00.087080\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1340.1938125\tTime: 0:00:00.011737\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1379.8041979166667\tTime: 0:00:00.090777\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1332.6693125\tTime: 0:00:00.012124\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1372.6369635416668\tTime: 0:00:00.092002\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1340.5298125\tTime: 0:00:00.012292\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1376.8211875\tTime: 0:00:00.090249\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1338.847875\tTime: 0:00:00.012160\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1367.681421875\tTime: 0:00:00.090748\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1339.6850625\tTime: 0:00:00.014546\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1370.54946875\tTime: 0:00:00.091627\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1343.642\tTime: 0:00:00.012244\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1365.7774583333332\tTime: 0:00:00.090708\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1336.58975\tTime: 0:00:00.011877\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m6.217952642327538\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2196.987983400532\u001b[0m\n",
      "Nodes averages betas and thetas inf:  6.231895270231613 2220.4841478923327\n",
      "Executing for eta equals to  0.02\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:56<00:00, 35.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:55<00:00, 36.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:55<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:55<00:00, 35.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:55<00:00, 35.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 20)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1726.4901479166667\tTime: 0:00:00.455330\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1663.02848125\tTime: 0:00:00.061485\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1614.287684375\tTime: 0:00:00.440262\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1550.854653125\tTime: 0:00:00.060727\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1574.6043427083334\tTime: 0:00:00.452854\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1524.81839375\tTime: 0:00:00.058852\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1551.522684375\tTime: 0:00:00.449553\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1512.203759375\tTime: 0:00:00.077121\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1540.794246875\tTime: 0:00:00.441538\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1499.85148125\tTime: 0:00:00.059171\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1531.2131875\tTime: 0:00:00.441943\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1493.80660625\tTime: 0:00:00.060430\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1521.56205625\tTime: 0:00:00.437199\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1487.70244375\tTime: 0:00:00.076832\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1514.7501364583334\tTime: 0:00:00.444106\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1480.122378125\tTime: 0:00:00.060290\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1509.6232364583334\tTime: 0:00:00.457400\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1476.2359125\tTime: 0:00:00.077554\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1503.3107833333333\tTime: 0:00:00.438142\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1470.552309375\tTime: 0:00:00.060830\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1498.8296375\tTime: 0:00:00.442737\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1469.44583125\tTime: 0:00:00.059794\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1495.3824020833333\tTime: 0:00:00.452111\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1461.79000625\tTime: 0:00:00.060491\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1491.7344114583334\tTime: 0:00:00.452116\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1457.69854375\tTime: 0:00:00.060192\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1491.5428125\tTime: 0:00:00.451703\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1456.4612375\tTime: 0:00:00.060865\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1489.35713125\tTime: 0:00:00.460402\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1454.346940625\tTime: 0:00:00.077868\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1485.7578197916666\tTime: 0:00:00.451004\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1460.2653\tTime: 0:00:00.061210\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1484.5900333333334\tTime: 0:00:00.444589\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1452.016475\tTime: 0:00:00.078683\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1485.4622822916667\tTime: 0:00:00.465760\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1451.155525\tTime: 0:00:00.061260\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1483.89751875\tTime: 0:00:00.450020\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1450.232103125\tTime: 0:00:00.060576\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1483.1588333333334\tTime: 0:00:00.450384\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1450.4544625\tTime: 0:00:00.061382\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1480.6996708333334\tTime: 0:00:00.449774\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1456.62234375\tTime: 0:00:00.078069\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1480.4701895833334\tTime: 0:00:00.457373\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1451.1678375\tTime: 0:00:00.062369\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1480.6541864583332\tTime: 0:00:00.452684\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1448.579284375\tTime: 0:00:00.061181\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1479.1070947916667\tTime: 0:00:00.462942\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1445.0369\tTime: 0:00:00.061761\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1478.2750020833332\tTime: 0:00:00.448920\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1448.74601875\tTime: 0:00:00.061328\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1476.6689635416667\tTime: 0:00:00.600434\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1444.476246875\tTime: 0:00:00.062717\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1478.120978125\tTime: 0:00:00.443974\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1448.25828125\tTime: 0:00:00.061489\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1479.25736875\tTime: 0:00:00.449646\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1444.85523125\tTime: 0:00:00.062209\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1475.0263822916668\tTime: 0:00:00.448289\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1444.303784375\tTime: 0:00:00.063358\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1476.45228125\tTime: 0:00:00.452760\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1444.555509375\tTime: 0:00:00.062124\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1476.05076875\tTime: 0:00:00.448536\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1444.94065625\tTime: 0:00:00.061437\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1475.1015041666667\tTime: 0:00:00.451235\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1436.89215625\tTime: 0:00:00.065481\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1472.2721135416666\tTime: 0:00:00.446206\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1441.689903125\tTime: 0:00:00.061495\n",
      "Epoch: [34/100]\tSamples: [127500/375000]\tTrain Loss: 1476.2290291666666\tTime: 0:00:00.445768\n",
      "Epoch: [34/100]\tSamples: [1250/125000]\tValidation Loss: 1443.1710625\tTime: 0:00:00.062821\n",
      "Epoch: [35/100]\tSamples: [131250/375000]\tTrain Loss: 1472.82670625\tTime: 0:00:00.449827\n",
      "Epoch: [35/100]\tSamples: [1250/125000]\tValidation Loss: 1445.939775\tTime: 0:00:00.079177\n",
      "Epoch: [36/100]\tSamples: [135000/375000]\tTrain Loss: 1472.94065625\tTime: 0:00:00.456139\n",
      "Epoch: [36/100]\tSamples: [1250/125000]\tValidation Loss: 1440.4516875\tTime: 0:00:00.080085\n",
      "Epoch: [37/100]\tSamples: [138750/375000]\tTrain Loss: 1471.0750895833332\tTime: 0:00:00.456404\n",
      "Epoch: [37/100]\tSamples: [1250/125000]\tValidation Loss: 1442.822559375\tTime: 0:00:00.061850\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m11.52863365367631\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2174.5977078494275\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1738.2951354166667\tTime: 0:00:00.095181\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1635.423625\tTime: 0:00:00.012938\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1698.9650208333333\tTime: 0:00:00.091551\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1647.86225\tTime: 0:00:00.012517\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1660.6924583333334\tTime: 0:00:00.090650\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1656.1545625\tTime: 0:00:00.015495\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1619.9916145833333\tTime: 0:00:00.091606\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1638.6005\tTime: 0:00:00.015292\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1587.9788125\tTime: 0:00:00.092954\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1604.50440625\tTime: 0:00:00.012878\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1575.54103125\tTime: 0:00:00.091273\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1564.56659375\tTime: 0:00:00.012686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1552.0727604166666\tTime: 0:00:00.092477\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1536.551125\tTime: 0:00:00.012859\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1542.9789166666667\tTime: 0:00:00.093777\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1516.74525\tTime: 0:00:00.012512\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1527.89565625\tTime: 0:00:00.091668\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1509.10334375\tTime: 0:00:00.015581\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1515.7240208333333\tTime: 0:00:00.094954\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1499.9065625\tTime: 0:00:00.012596\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1516.2701458333333\tTime: 0:00:00.092933\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1493.10578125\tTime: 0:00:00.015458\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1502.81771875\tTime: 0:00:00.094177\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1492.41009375\tTime: 0:00:00.012445\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1499.993625\tTime: 0:00:00.094122\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1482.889625\tTime: 0:00:00.014485\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1497.7694270833333\tTime: 0:00:00.091237\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1477.64271875\tTime: 0:00:00.012632\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1493.5396666666666\tTime: 0:00:00.090841\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1484.55121875\tTime: 0:00:00.015502\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1491.4462083333333\tTime: 0:00:00.092943\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1473.450375\tTime: 0:00:00.012523\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1485.7899270833334\tTime: 0:00:00.091983\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1471.57090625\tTime: 0:00:00.012625\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1482.7609166666666\tTime: 0:00:00.092205\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1469.268375\tTime: 0:00:00.012608\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1478.0297083333332\tTime: 0:00:00.091328\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1472.41921875\tTime: 0:00:00.015686\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1477.4977916666667\tTime: 0:00:00.092666\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1473.21525\tTime: 0:00:00.012395\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1467.4163333333333\tTime: 0:00:00.091070\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1466.67434375\tTime: 0:00:00.012571\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1471.5707916666668\tTime: 0:00:00.092336\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1465.363875\tTime: 0:00:00.012439\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1467.0942395833333\tTime: 0:00:00.088643\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1459.64509375\tTime: 0:00:00.015588\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1466.71790625\tTime: 0:00:00.088374\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1460.87775\tTime: 0:00:00.012420\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1468.7591875\tTime: 0:00:00.091985\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1457.2636875\tTime: 0:00:00.015618\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1463.55796875\tTime: 0:00:00.096673\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1459.14096875\tTime: 0:00:00.012523\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1463.5700833333333\tTime: 0:00:00.093411\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1453.6975625\tTime: 0:00:00.013387\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1457.51625\tTime: 0:00:00.093313\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1455.12571875\tTime: 0:00:00.012727\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1459.3312083333333\tTime: 0:00:00.093067\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1455.9190625\tTime: 0:00:00.012966\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1461.8221875\tTime: 0:00:00.094319\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1453.05496875\tTime: 0:00:00.012584\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1457.3847291666666\tTime: 0:00:00.092427\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1453.72365625\tTime: 0:00:00.012699\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1454.1459895833334\tTime: 0:00:00.093438\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1455.0486875\tTime: 0:00:00.015151\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1455.1527395833334\tTime: 0:00:00.091260\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1457.0706875\tTime: 0:00:00.012657\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1455.0171770833333\tTime: 0:00:00.092529\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1455.00884375\tTime: 0:00:00.012547\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1455.4453541666667\tTime: 0:00:00.089542\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1453.384\tTime: 0:00:00.013087\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m10.100774978637727\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2216.530051847179\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1725.6394479166668\tTime: 0:00:00.096102\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1641.47090625\tTime: 0:00:00.015820\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1693.2080625\tTime: 0:00:00.087334\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1651.25734375\tTime: 0:00:00.012602\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1650.2385520833334\tTime: 0:00:00.092819\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1657.9911875\tTime: 0:00:00.013760\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1615.9890833333334\tTime: 0:00:00.089322\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1645.23775\tTime: 0:00:00.012646\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1593.8883020833334\tTime: 0:00:00.090383\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1612.04959375\tTime: 0:00:00.012830\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1565.82059375\tTime: 0:00:00.103015\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1575.0836875\tTime: 0:00:00.015613\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1551.1789270833333\tTime: 0:00:00.103711\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1546.85640625\tTime: 0:00:00.015618\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1538.012875\tTime: 0:00:00.102149\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1528.3834375\tTime: 0:00:00.016134\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1528.8949791666666\tTime: 0:00:00.103418\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1522.61409375\tTime: 0:00:00.015787\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1516.0710416666666\tTime: 0:00:00.105309\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1516.198125\tTime: 0:00:00.015650\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1512.1510833333334\tTime: 0:00:00.104586\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1507.5253125\tTime: 0:00:00.012690\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1502.1114895833334\tTime: 0:00:00.091812\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1504.7741875\tTime: 0:00:00.012690\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1495.6607083333333\tTime: 0:00:00.092181\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1496.06909375\tTime: 0:00:00.012846\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1494.9322604166666\tTime: 0:00:00.086520\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1492.17765625\tTime: 0:00:00.012935\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1490.4117395833334\tTime: 0:00:00.085649\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1486.83340625\tTime: 0:00:00.013038\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1487.8518541666667\tTime: 0:00:00.087430\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1482.9799375\tTime: 0:00:00.012603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1482.8194479166666\tTime: 0:00:00.087623\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1480.89265625\tTime: 0:00:00.012815\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1474.7712916666667\tTime: 0:00:00.089652\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1479.28325\tTime: 0:00:00.012613\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1477.3341041666667\tTime: 0:00:00.086295\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1480.38240625\tTime: 0:00:00.012763\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1473.5276666666666\tTime: 0:00:00.086645\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1469.752875\tTime: 0:00:00.012587\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1475.8100729166667\tTime: 0:00:00.091255\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1472.0383125\tTime: 0:00:00.012726\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1468.5973229166666\tTime: 0:00:00.092338\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1474.7880625\tTime: 0:00:00.012975\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1465.6439791666667\tTime: 0:00:00.090051\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1472.10184375\tTime: 0:00:00.012887\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1462.4522291666667\tTime: 0:00:00.087479\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1467.97503125\tTime: 0:00:00.012927\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1466.73190625\tTime: 0:00:00.090270\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1471.3160625\tTime: 0:00:00.015463\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1457.8864166666667\tTime: 0:00:00.089036\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1467.99784375\tTime: 0:00:00.013334\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1464.7574791666666\tTime: 0:00:00.090501\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1469.4690625\tTime: 0:00:00.012731\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1458.7471458333334\tTime: 0:00:00.084816\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1466.743625\tTime: 0:00:00.012524\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1460.245875\tTime: 0:00:00.101739\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1463.75884375\tTime: 0:00:00.012739\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1454.2850208333334\tTime: 0:00:00.089980\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1465.09446875\tTime: 0:00:00.012858\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1453.0914583333333\tTime: 0:00:00.090267\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1463.1226875\tTime: 0:00:00.013033\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1451.2479791666667\tTime: 0:00:00.089414\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1460.341375\tTime: 0:00:00.012351\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1451.2418229166667\tTime: 0:00:00.085961\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1461.0875\tTime: 0:00:00.012721\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1451.5087083333333\tTime: 0:00:00.089574\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1459.7265625\tTime: 0:00:00.012750\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1449.5955260416667\tTime: 0:00:00.089400\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1461.418375\tTime: 0:00:00.015764\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1449.82121875\tTime: 0:00:00.088425\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1456.7650625\tTime: 0:00:00.012659\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1449.2210729166666\tTime: 0:00:00.087797\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1454.53709375\tTime: 0:00:00.012881\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1449.40234375\tTime: 0:00:00.089262\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1456.08646875\tTime: 0:00:00.012595\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1449.4919166666666\tTime: 0:00:00.091265\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1455.7935\tTime: 0:00:00.012833\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1443.7556666666667\tTime: 0:00:00.087802\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1461.2425\tTime: 0:00:00.012532\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1442.6820833333334\tTime: 0:00:00.092564\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1459.94109375\tTime: 0:00:00.012806\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1447.631796875\tTime: 0:00:00.089421\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1453.26190625\tTime: 0:00:00.012595\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1444.8073333333334\tTime: 0:00:00.090939\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1457.44146875\tTime: 0:00:00.012688\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1442.6645520833333\tTime: 0:00:00.091543\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1456.09428125\tTime: 0:00:00.012660\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1440.2354427083333\tTime: 0:00:00.091030\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1459.44875\tTime: 0:00:00.012988\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1445.012375\tTime: 0:00:00.090195\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1455.8525\tTime: 0:00:00.012514\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1442.4301666666668\tTime: 0:00:00.090209\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1456.49459375\tTime: 0:00:00.015739\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m10.173468101608155\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2246.711661848474\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1762.491375\tTime: 0:00:00.086995\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1635.1911875\tTime: 0:00:00.012343\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1731.7260416666666\tTime: 0:00:00.085222\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1646.0995625\tTime: 0:00:00.012274\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1690.2914270833332\tTime: 0:00:00.087427\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1659.06615625\tTime: 0:00:00.012590\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1654.5073645833334\tTime: 0:00:00.086585\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1648.37459375\tTime: 0:00:00.012198\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1625.8812291666666\tTime: 0:00:00.085692\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1615.40428125\tTime: 0:00:00.013043\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1604.513875\tTime: 0:00:00.085938\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1571.17253125\tTime: 0:00:00.012158\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1587.6635416666666\tTime: 0:00:00.092027\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1543.95746875\tTime: 0:00:00.012305\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1575.53615625\tTime: 0:00:00.085372\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1530.54159375\tTime: 0:00:00.012083\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1561.2163020833334\tTime: 0:00:00.086383\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1511.03475\tTime: 0:00:00.012416\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1552.6323020833333\tTime: 0:00:00.088324\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1503.981625\tTime: 0:00:00.012276\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1545.46084375\tTime: 0:00:00.085645\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1493.59265625\tTime: 0:00:00.012456\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1536.2973958333334\tTime: 0:00:00.084402\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1492.08684375\tTime: 0:00:00.012151\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1531.1874479166668\tTime: 0:00:00.085412\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1480.84234375\tTime: 0:00:00.012193\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1526.3812395833334\tTime: 0:00:00.087347\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1484.821625\tTime: 0:00:00.012321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1521.3002916666667\tTime: 0:00:00.090347\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1476.27003125\tTime: 0:00:00.012462\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1520.0101979166666\tTime: 0:00:00.087584\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1479.16278125\tTime: 0:00:00.012075\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1517.9504479166667\tTime: 0:00:00.085748\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1470.45990625\tTime: 0:00:00.012337\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1509.66653125\tTime: 0:00:00.088406\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1472.91053125\tTime: 0:00:00.014871\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1512.2873541666668\tTime: 0:00:00.088684\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1469.06078125\tTime: 0:00:00.012386\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1507.9392916666666\tTime: 0:00:00.085889\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1466.07703125\tTime: 0:00:00.012173\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1504.9694166666666\tTime: 0:00:00.086474\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1464.89015625\tTime: 0:00:00.012370\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1500.76646875\tTime: 0:00:00.085353\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1467.0884375\tTime: 0:00:00.012002\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1499.3098125\tTime: 0:00:00.084639\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1460.97078125\tTime: 0:00:00.012340\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1496.7310729166666\tTime: 0:00:00.100672\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1462.01228125\tTime: 0:00:00.013051\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1494.3452395833333\tTime: 0:00:00.088806\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1462.17446875\tTime: 0:00:00.012076\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1495.8730520833333\tTime: 0:00:00.091230\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1459.179625\tTime: 0:00:00.012303\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1489.4869583333334\tTime: 0:00:00.086581\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1457.01759375\tTime: 0:00:00.012055\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1490.1907291666666\tTime: 0:00:00.086898\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1456.4131875\tTime: 0:00:00.012410\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1488.99990625\tTime: 0:00:00.087113\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1456.41565625\tTime: 0:00:00.012059\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1490.3135\tTime: 0:00:00.088998\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1451.61075\tTime: 0:00:00.012424\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1487.15578125\tTime: 0:00:00.085601\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1452.85171875\tTime: 0:00:00.012098\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1483.9085833333334\tTime: 0:00:00.085849\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1451.5021875\tTime: 0:00:00.012459\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1487.4292395833334\tTime: 0:00:00.089548\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1452.0411875\tTime: 0:00:00.012304\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1482.2786875\tTime: 0:00:00.088734\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1450.884125\tTime: 0:00:00.012472\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1484.642875\tTime: 0:00:00.086694\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1451.1525\tTime: 0:00:00.012259\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1481.0602708333333\tTime: 0:00:00.086026\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1449.27028125\tTime: 0:00:00.012692\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1481.5958958333333\tTime: 0:00:00.086413\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1443.684625\tTime: 0:00:00.011989\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1482.15259375\tTime: 0:00:00.089056\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1453.57053125\tTime: 0:00:00.012613\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1480.0235\tTime: 0:00:00.090174\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1446.81965625\tTime: 0:00:00.012176\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1477.4362916666666\tTime: 0:00:00.090481\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1445.7775\tTime: 0:00:00.012229\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1475.6589583333334\tTime: 0:00:00.086103\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1446.25684375\tTime: 0:00:00.014874\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1479.08390625\tTime: 0:00:00.088644\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1446.3141875\tTime: 0:00:00.012504\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m10.15924712467838\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2263.635981934255\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1745.8983854166668\tTime: 0:00:00.091769\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1615.19884375\tTime: 0:00:00.012506\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1720.2467291666667\tTime: 0:00:00.093828\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1624.95903125\tTime: 0:00:00.012120\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1679.3965729166666\tTime: 0:00:00.090936\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1634.38984375\tTime: 0:00:00.015247\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1640.95271875\tTime: 0:00:00.091319\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1622.42903125\tTime: 0:00:00.012237\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1610.7741875\tTime: 0:00:00.090784\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1591.782\tTime: 0:00:00.012628\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1586.9603020833333\tTime: 0:00:00.093118\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1552.98925\tTime: 0:00:00.012305\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1566.5831979166667\tTime: 0:00:00.090910\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1521.541\tTime: 0:00:00.012559\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1559.9275104166666\tTime: 0:00:00.091492\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1505.609875\tTime: 0:00:00.012263\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1537.66096875\tTime: 0:00:00.094155\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1490.59584375\tTime: 0:00:00.012614\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1527.65371875\tTime: 0:00:00.104546\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1491.52678125\tTime: 0:00:00.013151\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1518.1873541666666\tTime: 0:00:00.087850\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1474.79121875\tTime: 0:00:00.012242\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1516.6913854166667\tTime: 0:00:00.093059\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1468.6126875\tTime: 0:00:00.012638\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1511.2233125\tTime: 0:00:00.089772\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1467.14940625\tTime: 0:00:00.012293\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1506.0765729166667\tTime: 0:00:00.091688\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1462.41896875\tTime: 0:00:00.012657\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1498.9166979166666\tTime: 0:00:00.093334\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1457.40340625\tTime: 0:00:00.012279\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1498.8423958333333\tTime: 0:00:00.089888\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1453.4925625\tTime: 0:00:00.012475\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1494.0574270833333\tTime: 0:00:00.095399\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1457.025\tTime: 0:00:00.012310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1491.58825\tTime: 0:00:00.088894\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1449.2229375\tTime: 0:00:00.012507\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1488.6694791666666\tTime: 0:00:00.088661\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1441.8683125\tTime: 0:00:00.012301\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1488.0365416666666\tTime: 0:00:00.093391\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1445.27203125\tTime: 0:00:00.015598\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1480.0659479166666\tTime: 0:00:00.093975\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1450.07275\tTime: 0:00:00.014934\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1480.6513854166667\tTime: 0:00:00.096643\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1440.5831875\tTime: 0:00:00.012695\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1481.748875\tTime: 0:00:00.091079\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1441.13475\tTime: 0:00:00.012246\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1476.14740625\tTime: 0:00:00.094438\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1443.19853125\tTime: 0:00:00.012620\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1472.9967395833332\tTime: 0:00:00.091213\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1439.8626875\tTime: 0:00:00.012384\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1471.3238645833333\tTime: 0:00:00.093743\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1436.05525\tTime: 0:00:00.012807\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1470.2420833333333\tTime: 0:00:00.089101\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1434.47809375\tTime: 0:00:00.012346\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1476.6604166666666\tTime: 0:00:00.086859\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1431.76340625\tTime: 0:00:00.012662\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1469.9409791666667\tTime: 0:00:00.102102\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1435.5063125\tTime: 0:00:00.015111\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1466.6700520833333\tTime: 0:00:00.100659\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1437.14371875\tTime: 0:00:00.012612\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1465.5571770833333\tTime: 0:00:00.090113\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1433.32071875\tTime: 0:00:00.014896\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1466.58959375\tTime: 0:00:00.094201\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1431.10559375\tTime: 0:00:00.012636\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1464.1889375\tTime: 0:00:00.104103\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1438.4995\tTime: 0:00:00.015172\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1459.6568645833333\tTime: 0:00:00.103709\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1436.3081875\tTime: 0:00:00.015491\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1462.25659375\tTime: 0:00:00.103317\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1431.849625\tTime: 0:00:00.012569\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1465.0333020833334\tTime: 0:00:00.093736\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1427.91003125\tTime: 0:00:00.015444\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1456.6568020833333\tTime: 0:00:00.092590\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1432.40115625\tTime: 0:00:00.012174\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1456.3788958333334\tTime: 0:00:00.090804\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1433.77234375\tTime: 0:00:00.013306\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1457.8088125\tTime: 0:00:00.088089\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1430.750625\tTime: 0:00:00.012824\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1457.1426458333333\tTime: 0:00:00.088593\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1426.95175\tTime: 0:00:00.012708\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1458.90053125\tTime: 0:00:00.088479\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1431.87753125\tTime: 0:00:00.012279\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1453.3638958333333\tTime: 0:00:00.090606\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1430.255375\tTime: 0:00:00.012576\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1452.3351875\tTime: 0:00:00.086860\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1424.475\tTime: 0:00:00.012317\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1452.9233125\tTime: 0:00:00.094143\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1428.506875\tTime: 0:00:00.012668\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1456.0703854166666\tTime: 0:00:00.091503\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1428.55621875\tTime: 0:00:00.012389\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1454.2140833333333\tTime: 0:00:00.093065\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1425.9906875\tTime: 0:00:00.012619\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1453.6896875\tTime: 0:00:00.089270\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1425.011125\tTime: 0:00:00.012287\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1450.5114322916668\tTime: 0:00:00.095240\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1425.253875\tTime: 0:00:00.012576\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m10.092526318315022\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2258.8104013571187\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1734.3117604166666\tTime: 0:00:00.092933\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1621.29734375\tTime: 0:00:00.012517\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1702.1551666666667\tTime: 0:00:00.090164\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1632.36778125\tTime: 0:00:00.012167\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1659.6578541666668\tTime: 0:00:00.090089\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1643.0715\tTime: 0:00:00.012485\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1624.9837916666668\tTime: 0:00:00.086798\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1629.00640625\tTime: 0:00:00.015006\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1593.7406041666666\tTime: 0:00:00.090819\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1592.7771875\tTime: 0:00:00.012226\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1574.4982916666668\tTime: 0:00:00.089292\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1547.890625\tTime: 0:00:00.012119\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1552.57134375\tTime: 0:00:00.088985\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1520.407375\tTime: 0:00:00.012341\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1543.2189270833333\tTime: 0:00:00.092028\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1495.5594375\tTime: 0:00:00.012442\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1532.5275833333333\tTime: 0:00:00.092297\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1494.32621875\tTime: 0:00:00.012364\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1521.3683958333334\tTime: 0:00:00.089196\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1479.233625\tTime: 0:00:00.014734\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1516.1058020833334\tTime: 0:00:00.094660\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1470.30603125\tTime: 0:00:00.012356\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1508.517140625\tTime: 0:00:00.089119\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1471.54603125\tTime: 0:00:00.014953\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1507.29609375\tTime: 0:00:00.090789\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1471.2863125\tTime: 0:00:00.012363\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1501.4885416666666\tTime: 0:00:00.086426\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1465.9256875\tTime: 0:00:00.012256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1499.7162291666666\tTime: 0:00:00.089079\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1456.22428125\tTime: 0:00:00.012723\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1494.1773229166668\tTime: 0:00:00.090510\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1456.123\tTime: 0:00:00.012106\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1489.5823645833334\tTime: 0:00:00.085605\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1455.54271875\tTime: 0:00:00.012241\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1492.07671875\tTime: 0:00:00.087844\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1452.18165625\tTime: 0:00:00.012137\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1488.1498333333334\tTime: 0:00:00.087725\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1450.01784375\tTime: 0:00:00.015088\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1480.9183645833334\tTime: 0:00:00.089094\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1447.42140625\tTime: 0:00:00.012057\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1480.7986770833334\tTime: 0:00:00.090922\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1449.8800625\tTime: 0:00:00.012458\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1478.8081666666667\tTime: 0:00:00.089764\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1440.42\tTime: 0:00:00.012022\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1475.4900104166666\tTime: 0:00:00.092412\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1441.66171875\tTime: 0:00:00.015292\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1473.4043229166666\tTime: 0:00:00.086539\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1441.97346875\tTime: 0:00:00.012169\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1473.2835833333334\tTime: 0:00:00.088401\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1437.6213125\tTime: 0:00:00.012418\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1472.380125\tTime: 0:00:00.092749\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1442.2961875\tTime: 0:00:00.015123\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1468.7897291666666\tTime: 0:00:00.103861\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1442.57209375\tTime: 0:00:00.015297\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1466.6539375\tTime: 0:00:00.092552\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1436.171125\tTime: 0:00:00.011953\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1473.5807291666667\tTime: 0:00:00.089211\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1439.3903125\tTime: 0:00:00.012393\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1466.06871875\tTime: 0:00:00.088824\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1439.702875\tTime: 0:00:00.012985\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1462.0955208333332\tTime: 0:00:00.094173\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1436.14078125\tTime: 0:00:00.012395\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1463.9064479166666\tTime: 0:00:00.088361\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1435.14040625\tTime: 0:00:00.012047\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1462.1494166666666\tTime: 0:00:00.089591\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1434.3415625\tTime: 0:00:00.012355\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1463.809265625\tTime: 0:00:00.090192\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1433.83834375\tTime: 0:00:00.012098\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1462.1223333333332\tTime: 0:00:00.085488\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1431.84015625\tTime: 0:00:00.012321\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1458.6591197916666\tTime: 0:00:00.087756\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1436.48446875\tTime: 0:00:00.012288\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1456.2031145833334\tTime: 0:00:00.089285\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1439.925\tTime: 0:00:00.012491\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1462.1435520833334\tTime: 0:00:00.090725\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1433.5245\tTime: 0:00:00.012192\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1456.6335416666666\tTime: 0:00:00.091323\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1436.3548125\tTime: 0:00:00.012217\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1456.7179895833333\tTime: 0:00:00.088148\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1437.128125\tTime: 0:00:00.012011\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m10.067265782362064\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2217.493704087822\u001b[0m\n",
      "Nodes averages betas and thetas inf:  10.11865646112027 2240.63636021497\n",
      "Executing for eta equals to  0.03\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 35.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:56<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:56<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:56<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 20)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1757.312825\tTime: 0:00:00.461030\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1702.099796875\tTime: 0:00:00.062099\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1657.14185\tTime: 0:00:00.454808\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1614.83\tTime: 0:00:00.061585\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1614.7720489583332\tTime: 0:00:00.455523\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1583.980696875\tTime: 0:00:00.062032\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1591.6524104166667\tTime: 0:00:00.456882\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1567.5440625\tTime: 0:00:00.061331\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1576.8683125\tTime: 0:00:00.463124\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1556.19261875\tTime: 0:00:00.062041\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1567.2680479166668\tTime: 0:00:00.457614\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1547.71224375\tTime: 0:00:00.062324\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1559.822278125\tTime: 0:00:00.604133\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1540.49788125\tTime: 0:00:00.061618\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1552.9026875\tTime: 0:00:00.458535\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1532.525484375\tTime: 0:00:00.061687\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1547.8196322916667\tTime: 0:00:00.458439\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1530.187103125\tTime: 0:00:00.062261\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1543.8207947916667\tTime: 0:00:00.457355\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1524.8329125\tTime: 0:00:00.062288\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1538.1890739583334\tTime: 0:00:00.461548\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1520.48638125\tTime: 0:00:00.062292\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1534.2302635416668\tTime: 0:00:00.450976\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1516.35250625\tTime: 0:00:00.061006\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1530.9612104166667\tTime: 0:00:00.457948\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1513.6023875\tTime: 0:00:00.061673\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1527.9558625\tTime: 0:00:00.462434\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1509.35075\tTime: 0:00:00.061958\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1524.990434375\tTime: 0:00:00.462152\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1508.089053125\tTime: 0:00:00.060320\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1523.1837375\tTime: 0:00:00.457853\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1502.5745\tTime: 0:00:00.062241\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1520.8226020833333\tTime: 0:00:00.461822\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1503.532684375\tTime: 0:00:00.062130\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1516.9668552083333\tTime: 0:00:00.463096\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1501.00925\tTime: 0:00:00.061609\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1519.0557885416667\tTime: 0:00:00.459061\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1499.879565625\tTime: 0:00:00.062415\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1515.7251260416667\tTime: 0:00:00.463226\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1500.908615625\tTime: 0:00:00.062834\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1511.401359375\tTime: 0:00:00.458985\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1499.384509375\tTime: 0:00:00.063080\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1512.1003739583334\tTime: 0:00:00.460948\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1500.36849375\tTime: 0:00:00.062236\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1513.3237916666667\tTime: 0:00:00.456186\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1498.834675\tTime: 0:00:00.061517\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1511.19123125\tTime: 0:00:00.458921\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1496.253353125\tTime: 0:00:00.062454\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1512.131921875\tTime: 0:00:00.465826\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1497.7924\tTime: 0:00:00.062015\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1509.90698125\tTime: 0:00:00.460180\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1493.556775\tTime: 0:00:00.062604\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1508.1385854166667\tTime: 0:00:00.477028\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1489.1039625\tTime: 0:00:00.080625\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1507.1973885416667\tTime: 0:00:00.468230\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1494.63556875\tTime: 0:00:00.062365\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1506.9925229166668\tTime: 0:00:00.456046\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1493.461221875\tTime: 0:00:00.062178\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1507.3884927083334\tTime: 0:00:00.467031\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1490.6138375\tTime: 0:00:00.062357\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1507.9954916666666\tTime: 0:00:00.450848\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1492.4672125\tTime: 0:00:00.061820\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1506.2627135416667\tTime: 0:00:00.457075\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1495.65055625\tTime: 0:00:00.064838\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m14.458031268828853\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2158.8918216912907\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1759.2305208333332\tTime: 0:00:00.088406\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1681.15015625\tTime: 0:00:00.012814\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1735.2488958333333\tTime: 0:00:00.087969\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1689.446125\tTime: 0:00:00.012573\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1697.8648333333333\tTime: 0:00:00.086263\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1698.71646875\tTime: 0:00:00.012683\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1662.48521875\tTime: 0:00:00.085117\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1689.37128125\tTime: 0:00:00.012607\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1638.1096979166666\tTime: 0:00:00.084056\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1666.29584375\tTime: 0:00:00.013734\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1614.879875\tTime: 0:00:00.085472\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1629.77890625\tTime: 0:00:00.012692\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1599.33896875\tTime: 0:00:00.086120\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1607.95734375\tTime: 0:00:00.012655\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1587.0131041666666\tTime: 0:00:00.085606\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1590.06971875\tTime: 0:00:00.012504\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1574.9407083333333\tTime: 0:00:00.085463\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1582.69309375\tTime: 0:00:00.012455\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1567.3432916666666\tTime: 0:00:00.087345\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1571.5230625\tTime: 0:00:00.012854\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1559.4942083333333\tTime: 0:00:00.103695\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1568.8938125\tTime: 0:00:00.015843\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1552.5596041666668\tTime: 0:00:00.103294\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1560.755625\tTime: 0:00:00.015694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1547.4382083333333\tTime: 0:00:00.100967\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1552.25809375\tTime: 0:00:00.015519\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1538.7460104166666\tTime: 0:00:00.085488\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1549.11603125\tTime: 0:00:00.012616\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1536.1281354166667\tTime: 0:00:00.087716\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1545.8115625\tTime: 0:00:00.012826\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1535.6643333333334\tTime: 0:00:00.087560\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1542.92621875\tTime: 0:00:00.012620\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1524.7964166666666\tTime: 0:00:00.086402\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1541.4295\tTime: 0:00:00.013108\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1524.5111770833332\tTime: 0:00:00.085951\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1540.751875\tTime: 0:00:00.012455\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1521.9880416666667\tTime: 0:00:00.084614\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1537.0565625\tTime: 0:00:00.012677\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1521.5454895833334\tTime: 0:00:00.086510\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1532.7243125\tTime: 0:00:00.012528\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1515.0801666666666\tTime: 0:00:00.089746\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1522.2390625\tTime: 0:00:00.013070\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1513.5419166666666\tTime: 0:00:00.086746\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1527.37740625\tTime: 0:00:00.012553\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1514.4307083333333\tTime: 0:00:00.085818\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1523.14928125\tTime: 0:00:00.012495\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1506.8155833333333\tTime: 0:00:00.084494\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1523.18865625\tTime: 0:00:00.015650\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1505.7007916666666\tTime: 0:00:00.085907\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1530.54425\tTime: 0:00:00.013277\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1508.1184479166666\tTime: 0:00:00.084868\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1523.06046875\tTime: 0:00:00.012695\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m13.216922129000112\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2226.9365855131127\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1769.8318229166666\tTime: 0:00:00.088307\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1660.5165625\tTime: 0:00:00.012247\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1747.1945833333334\tTime: 0:00:00.087309\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1668.57025\tTime: 0:00:00.012045\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1712.55725\tTime: 0:00:00.088276\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1680.07253125\tTime: 0:00:00.012469\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1678.6814166666666\tTime: 0:00:00.087066\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1672.76734375\tTime: 0:00:00.012056\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1655.03928125\tTime: 0:00:00.085838\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1645.028\tTime: 0:00:00.012835\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1634.0420416666666\tTime: 0:00:00.087331\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1610.05009375\tTime: 0:00:00.011974\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1616.7784270833333\tTime: 0:00:00.089533\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1584.7290625\tTime: 0:00:00.012244\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1602.0850416666667\tTime: 0:00:00.089752\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1566.19665625\tTime: 0:00:00.012812\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1591.1081666666666\tTime: 0:00:00.090223\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1554.56928125\tTime: 0:00:00.012197\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1580.8828958333334\tTime: 0:00:00.105447\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1545.6219375\tTime: 0:00:00.015191\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1569.0555520833334\tTime: 0:00:00.103524\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1540.17621875\tTime: 0:00:00.012317\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1562.8290416666666\tTime: 0:00:00.087504\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1533.11653125\tTime: 0:00:00.012021\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1559.8750416666667\tTime: 0:00:00.090590\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1525.0945625\tTime: 0:00:00.012199\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1555.8789166666666\tTime: 0:00:00.087805\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1520.386875\tTime: 0:00:00.012115\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1548.4311354166666\tTime: 0:00:00.087035\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1519.31390625\tTime: 0:00:00.012522\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1545.5645520833334\tTime: 0:00:00.087721\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1515.1400625\tTime: 0:00:00.012090\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1542.33309375\tTime: 0:00:00.088172\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1510.5185\tTime: 0:00:00.012237\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1531.6186770833333\tTime: 0:00:00.087660\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1506.58528125\tTime: 0:00:00.012136\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1534.2260104166667\tTime: 0:00:00.087592\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1503.9788125\tTime: 0:00:00.012219\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1533.1215104166668\tTime: 0:00:00.090041\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1502.00490625\tTime: 0:00:00.015005\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1529.365375\tTime: 0:00:00.089666\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1497.13259375\tTime: 0:00:00.014940\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1526.00678125\tTime: 0:00:00.091569\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1501.66\tTime: 0:00:00.012153\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1524.6401354166667\tTime: 0:00:00.088220\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1501.81409375\tTime: 0:00:00.012289\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1520.6870416666666\tTime: 0:00:00.087487\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1499.9954375\tTime: 0:00:00.012104\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1520.01509375\tTime: 0:00:00.087329\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1492.2065625\tTime: 0:00:00.013183\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1521.6011041666666\tTime: 0:00:00.090316\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1495.85009375\tTime: 0:00:00.012231\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1521.0053541666666\tTime: 0:00:00.088297\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1489.5855\tTime: 0:00:00.012450\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1516.1735\tTime: 0:00:00.088319\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1494.65678125\tTime: 0:00:00.012276\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1511.39021875\tTime: 0:00:00.092966\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1492.22221875\tTime: 0:00:00.012739\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1513.3919895833333\tTime: 0:00:00.089784\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1491.41\tTime: 0:00:00.012343\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1513.7941354166667\tTime: 0:00:00.087479\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1491.07709375\tTime: 0:00:00.012486\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1512.7129895833334\tTime: 0:00:00.087552\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1482.9446875\tTime: 0:00:00.012059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1512.8543125\tTime: 0:00:00.090892\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1489.40171875\tTime: 0:00:00.012451\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1511.0090520833332\tTime: 0:00:00.090020\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1487.174125\tTime: 0:00:00.012181\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1510.6380520833334\tTime: 0:00:00.088463\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1486.68175\tTime: 0:00:00.012486\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1507.8781875\tTime: 0:00:00.088991\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1485.841875\tTime: 0:00:00.012177\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1506.634375\tTime: 0:00:00.088295\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1485.2583125\tTime: 0:00:00.012816\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m13.234614343077254\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2207.7253899820853\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1775.00515625\tTime: 0:00:00.084945\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1638.257875\tTime: 0:00:00.012311\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1751.9558020833333\tTime: 0:00:00.084827\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1643.6244375\tTime: 0:00:00.011855\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1718.27565625\tTime: 0:00:00.084544\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1654.38725\tTime: 0:00:00.012480\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1686.8382916666667\tTime: 0:00:00.085557\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1648.55528125\tTime: 0:00:00.012102\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1658.6593645833334\tTime: 0:00:00.082731\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1627.6008125\tTime: 0:00:00.012811\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1637.218375\tTime: 0:00:00.083249\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1596.37675\tTime: 0:00:00.012067\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1619.4789270833332\tTime: 0:00:00.087904\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1574.84228125\tTime: 0:00:00.015215\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1605.0461145833333\tTime: 0:00:00.102032\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1556.65434375\tTime: 0:00:00.014814\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1590.01375\tTime: 0:00:00.085173\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1545.2899375\tTime: 0:00:00.012131\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1584.3408333333334\tTime: 0:00:00.227828\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1536.5429375\tTime: 0:00:00.012378\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1571.5359791666667\tTime: 0:00:00.084313\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1529.4136875\tTime: 0:00:00.012089\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1567.7859895833333\tTime: 0:00:00.085045\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1524.6081875\tTime: 0:00:00.012193\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1562.0393645833333\tTime: 0:00:00.084913\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1513.98846875\tTime: 0:00:00.011982\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1552.86225\tTime: 0:00:00.088340\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1511.76684375\tTime: 0:00:00.012184\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1550.8035104166668\tTime: 0:00:00.084386\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1508.28165625\tTime: 0:00:00.012147\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1544.4239375\tTime: 0:00:00.085209\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1507.674375\tTime: 0:00:00.012244\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1543.0630104166667\tTime: 0:00:00.085582\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1505.87640625\tTime: 0:00:00.011934\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1533.94965625\tTime: 0:00:00.086961\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1498.0775625\tTime: 0:00:00.015271\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1538.2298125\tTime: 0:00:00.087943\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1493.22446875\tTime: 0:00:00.012113\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1529.3154479166667\tTime: 0:00:00.084537\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1494.182875\tTime: 0:00:00.012380\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1523.8957083333332\tTime: 0:00:00.084242\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1495.22703125\tTime: 0:00:00.012006\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1524.4042604166666\tTime: 0:00:00.085832\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1493.8716875\tTime: 0:00:00.013195\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1526.22909375\tTime: 0:00:00.084443\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1490.53084375\tTime: 0:00:00.012049\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1523.61625\tTime: 0:00:00.102739\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1488.005875\tTime: 0:00:00.015142\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1518.04171875\tTime: 0:00:00.102329\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1486.37003125\tTime: 0:00:00.014834\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1517.5900208333333\tTime: 0:00:00.117586\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1489.16396875\tTime: 0:00:00.015817\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1512.2596041666666\tTime: 0:00:00.100157\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1485.7130625\tTime: 0:00:00.011925\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1514.4728645833334\tTime: 0:00:00.089035\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1482.40784375\tTime: 0:00:00.012676\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1514.5076666666666\tTime: 0:00:00.087485\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1482.99709375\tTime: 0:00:00.012188\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1511.3544166666666\tTime: 0:00:00.088348\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1480.6745625\tTime: 0:00:00.012781\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1511.2679895833332\tTime: 0:00:00.088122\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1479.518\tTime: 0:00:00.012293\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1509.3648333333333\tTime: 0:00:00.084996\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1480.2368125\tTime: 0:00:00.012403\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1510.58396875\tTime: 0:00:00.085106\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1476.539\tTime: 0:00:00.012327\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1505.5728020833333\tTime: 0:00:00.088902\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1479.9113125\tTime: 0:00:00.012647\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1507.2836458333334\tTime: 0:00:00.087173\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1481.32309375\tTime: 0:00:00.011924\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1502.3689375\tTime: 0:00:00.083718\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1478.553\tTime: 0:00:00.013180\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1508.4324583333334\tTime: 0:00:00.085384\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1478.7259375\tTime: 0:00:00.011985\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1506.7572083333334\tTime: 0:00:00.087385\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1474.504375\tTime: 0:00:00.012033\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1506.7846458333333\tTime: 0:00:00.085471\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1475.0525625\tTime: 0:00:00.012191\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1500.19784375\tTime: 0:00:00.084018\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1478.88040625\tTime: 0:00:00.012151\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1500.1604166666666\tTime: 0:00:00.086868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1481.0975\tTime: 0:00:00.013206\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1497.9418020833334\tTime: 0:00:00.087281\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1475.823625\tTime: 0:00:00.012426\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1500.301390625\tTime: 0:00:00.086851\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1475.90921875\tTime: 0:00:00.013072\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m13.27122513505293\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2288.2382743164762\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1771.89503125\tTime: 0:00:00.086190\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1622.84021875\tTime: 0:00:00.012199\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1746.4743333333333\tTime: 0:00:00.083469\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1630.13678125\tTime: 0:00:00.012043\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1714.2731770833334\tTime: 0:00:00.084792\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1636.97840625\tTime: 0:00:00.012268\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1680.1133541666666\tTime: 0:00:00.083392\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1629.065375\tTime: 0:00:00.011926\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1651.7982083333334\tTime: 0:00:00.083061\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1606.16190625\tTime: 0:00:00.012722\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1636.0270104166666\tTime: 0:00:00.086335\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1576.47703125\tTime: 0:00:00.011982\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1617.6449895833334\tTime: 0:00:00.085283\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1551.0544375\tTime: 0:00:00.012170\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1601.5290520833332\tTime: 0:00:00.084338\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1536.16175\tTime: 0:00:00.012181\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1590.6228958333334\tTime: 0:00:00.087948\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1524.1669375\tTime: 0:00:00.012441\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1585.1567604166667\tTime: 0:00:00.086740\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1519.3075625\tTime: 0:00:00.012191\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1576.5021041666666\tTime: 0:00:00.089726\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1513.60784375\tTime: 0:00:00.012692\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1572.8292395833334\tTime: 0:00:00.086703\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1510.59134375\tTime: 0:00:00.012343\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1564.45196875\tTime: 0:00:00.087068\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1506.38140625\tTime: 0:00:00.012570\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1555.3610729166667\tTime: 0:00:00.086669\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1498.932\tTime: 0:00:00.012474\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1557.3553645833333\tTime: 0:00:00.086721\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1496.36859375\tTime: 0:00:00.012650\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1549.0921979166667\tTime: 0:00:00.087388\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1495.82346875\tTime: 0:00:00.012324\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1548.3156145833334\tTime: 0:00:00.086869\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1494.17628125\tTime: 0:00:00.012706\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1543.6742291666667\tTime: 0:00:00.086462\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1489.45803125\tTime: 0:00:00.012340\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1535.987875\tTime: 0:00:00.086251\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1490.28221875\tTime: 0:00:00.012541\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1538.14146875\tTime: 0:00:00.089688\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1482.74134375\tTime: 0:00:00.012225\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1534.0018333333333\tTime: 0:00:00.085226\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1479.80109375\tTime: 0:00:00.012399\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1528.37728125\tTime: 0:00:00.083938\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1479.39640625\tTime: 0:00:00.012057\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1530.7030520833334\tTime: 0:00:00.086200\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1481.10596875\tTime: 0:00:00.012463\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1526.3779270833334\tTime: 0:00:00.085086\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1474.72621875\tTime: 0:00:00.012139\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1526.0202083333334\tTime: 0:00:00.086157\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1473.080125\tTime: 0:00:00.012264\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1524.3147395833332\tTime: 0:00:00.083189\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1473.1945625\tTime: 0:00:00.012089\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1521.02565625\tTime: 0:00:00.087406\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1471.17615625\tTime: 0:00:00.012502\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1517.7085729166668\tTime: 0:00:00.085821\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1474.20575\tTime: 0:00:00.012212\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1517.1285625\tTime: 0:00:00.086637\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1472.25409375\tTime: 0:00:00.015034\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1518.5918645833333\tTime: 0:00:00.084601\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1472.08490625\tTime: 0:00:00.012282\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1517.896625\tTime: 0:00:00.083285\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1472.69334375\tTime: 0:00:00.012999\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1513.8671979166666\tTime: 0:00:00.084309\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1466.27103125\tTime: 0:00:00.012198\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1508.8637604166668\tTime: 0:00:00.087189\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1467.12884375\tTime: 0:00:00.012341\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1515.6742604166666\tTime: 0:00:00.083745\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1466.5626875\tTime: 0:00:00.012049\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1513.1879166666668\tTime: 0:00:00.083793\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1469.198375\tTime: 0:00:00.013088\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1510.3347708333333\tTime: 0:00:00.087649\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1470.77084375\tTime: 0:00:00.015503\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1507.228\tTime: 0:00:00.084714\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1465.51009375\tTime: 0:00:00.013095\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1509.0524270833334\tTime: 0:00:00.083471\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1462.81609375\tTime: 0:00:00.012296\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1506.8411145833334\tTime: 0:00:00.084289\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1465.40715625\tTime: 0:00:00.012194\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1508.9768958333334\tTime: 0:00:00.083046\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1465.79815625\tTime: 0:00:00.011864\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1505.4934166666667\tTime: 0:00:00.084378\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1465.388625\tTime: 0:00:00.013306\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1506.48715625\tTime: 0:00:00.086279\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1462.05009375\tTime: 0:00:00.012203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1500.9651979166667\tTime: 0:00:00.086149\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1459.1114375\tTime: 0:00:00.012732\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1500.9369375\tTime: 0:00:00.083770\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1461.666125\tTime: 0:00:00.012231\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1505.0481458333334\tTime: 0:00:00.089491\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1463.43784375\tTime: 0:00:00.012438\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1505.9027604166668\tTime: 0:00:00.083819\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1462.2928125\tTime: 0:00:00.012038\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1503.1745104166666\tTime: 0:00:00.085605\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1462.82678125\tTime: 0:00:00.013017\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1500.8227708333334\tTime: 0:00:00.084390\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1462.63503125\tTime: 0:00:00.015007\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m13.23618042626674\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2273.2131112134493\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1763.5029583333333\tTime: 0:00:00.084405\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1660.69440625\tTime: 0:00:00.012312\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1737.1667395833333\tTime: 0:00:00.085093\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1670.00596875\tTime: 0:00:00.012186\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1702.1786041666667\tTime: 0:00:00.086083\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1685.48940625\tTime: 0:00:00.012677\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1668.2451041666666\tTime: 0:00:00.086339\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1675.001\tTime: 0:00:00.012459\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1642.422125\tTime: 0:00:00.086428\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1648.40003125\tTime: 0:00:00.013371\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1616.5943645833333\tTime: 0:00:00.085303\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1614.25478125\tTime: 0:00:00.012163\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1604.4926770833333\tTime: 0:00:00.083691\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1584.84325\tTime: 0:00:00.012505\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1591.8689791666666\tTime: 0:00:00.083280\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1568.89028125\tTime: 0:00:00.012120\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1576.71665625\tTime: 0:00:00.084866\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1559.76525\tTime: 0:00:00.012387\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1570.0360625\tTime: 0:00:00.083460\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1549.43625\tTime: 0:00:00.012106\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1558.93990625\tTime: 0:00:00.100926\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1538.490125\tTime: 0:00:00.015483\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1552.9706354166667\tTime: 0:00:00.100978\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1536.9574375\tTime: 0:00:00.015198\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1548.0807916666668\tTime: 0:00:00.117460\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1531.17559375\tTime: 0:00:00.015718\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1544.6046354166667\tTime: 0:00:00.102090\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1528.57265625\tTime: 0:00:00.015199\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1535.5149583333334\tTime: 0:00:00.101283\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1523.8411875\tTime: 0:00:00.012938\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1531.1387708333334\tTime: 0:00:00.082918\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1525.33734375\tTime: 0:00:00.012267\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1532.2870729166666\tTime: 0:00:00.087289\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1513.77609375\tTime: 0:00:00.012317\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1527.4243020833333\tTime: 0:00:00.083344\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1516.00390625\tTime: 0:00:00.015026\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1525.0479895833334\tTime: 0:00:00.087751\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1512.23475\tTime: 0:00:00.012508\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1522.07340625\tTime: 0:00:00.083613\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1506.12471875\tTime: 0:00:00.012129\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1514.8703541666666\tTime: 0:00:00.084850\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1503.87678125\tTime: 0:00:00.012423\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1515.80521875\tTime: 0:00:00.086398\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1503.74378125\tTime: 0:00:00.012018\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1513.3554583333334\tTime: 0:00:00.083778\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1502.4045\tTime: 0:00:00.012367\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1513.853125\tTime: 0:00:00.083306\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1501.28665625\tTime: 0:00:00.012259\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1513.29909375\tTime: 0:00:00.083223\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1496.82875\tTime: 0:00:00.012344\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1510.1960833333333\tTime: 0:00:00.085665\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1500.0215\tTime: 0:00:00.011959\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1505.0153229166667\tTime: 0:00:00.083536\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1502.9656875\tTime: 0:00:00.012407\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1507.82703125\tTime: 0:00:00.082851\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1501.54959375\tTime: 0:00:00.012114\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1502.42484375\tTime: 0:00:00.082862\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1497.02721875\tTime: 0:00:00.014153\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1506.8839375\tTime: 0:00:00.083146\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1494.47228125\tTime: 0:00:00.012315\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1502.9978541666667\tTime: 0:00:00.085807\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1495.6069375\tTime: 0:00:00.012440\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1502.2564479166667\tTime: 0:00:00.082542\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1494.49575\tTime: 0:00:00.012176\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1499.8733333333332\tTime: 0:00:00.083055\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1493.5490625\tTime: 0:00:00.014019\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1500.6029375\tTime: 0:00:00.082554\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1493.0440625\tTime: 0:00:00.012081\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1500.6838958333333\tTime: 0:00:00.084306\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1497.54928125\tTime: 0:00:00.012649\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1496.1963645833334\tTime: 0:00:00.083028\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1492.4631875\tTime: 0:00:00.012082\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1498.0219895833334\tTime: 0:00:00.093647\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1492.76859375\tTime: 0:00:00.012719\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1498.41046875\tTime: 0:00:00.084347\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1493.43140625\tTime: 0:00:00.012206\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1497.9006875\tTime: 0:00:00.082629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1490.32978125\tTime: 0:00:00.014415\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1498.2565833333333\tTime: 0:00:00.083381\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1490.64984375\tTime: 0:00:00.012242\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1493.7924895833332\tTime: 0:00:00.084509\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1489.777375\tTime: 0:00:00.012360\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1491.658625\tTime: 0:00:00.082783\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1489.7679375\tTime: 0:00:00.012133\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1490.5809479166667\tTime: 0:00:00.083427\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1488.9830625\tTime: 0:00:00.012445\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1493.7775208333333\tTime: 0:00:00.083521\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1485.8436875\tTime: 0:00:00.012096\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1491.1378854166667\tTime: 0:00:00.083381\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1489.574125\tTime: 0:00:00.012465\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1491.0903541666667\tTime: 0:00:00.085141\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1488.14596875\tTime: 0:00:00.015156\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1491.6043020833333\tTime: 0:00:00.084015\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1486.364875\tTime: 0:00:00.013871\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1489.0436770833333\tTime: 0:00:00.084272\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1488.1711875\tTime: 0:00:00.012204\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1489.0602291666667\tTime: 0:00:00.082664\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1488.0896875\tTime: 0:00:00.012199\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m13.238388686651534\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2341.578099034987\u001b[0m\n",
      "Nodes averages betas and thetas inf:  13.239466144009715 2267.538292012022\n",
      "Executing for eta equals to  0.04\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 34.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 34.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:57<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 20)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1771.37105\tTime: 0:00:00.462871\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1718.92275\tTime: 0:00:00.079516\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1681.7371760416668\tTime: 0:00:00.468186\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1646.642353125\tTime: 0:00:00.062232\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1638.7904416666668\tTime: 0:00:00.467891\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1615.627196875\tTime: 0:00:00.062393\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1615.3104875\tTime: 0:00:00.464020\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1599.8172125\tTime: 0:00:00.062706\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1601.3077770833333\tTime: 0:00:00.469686\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1588.06165\tTime: 0:00:00.062430\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1589.5819864583334\tTime: 0:00:00.466426\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1580.00929375\tTime: 0:00:00.062907\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1581.7041416666666\tTime: 0:00:00.463919\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1574.670128125\tTime: 0:00:00.060782\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1575.8233104166666\tTime: 0:00:00.453899\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1569.864875\tTime: 0:00:00.062426\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1571.4816875\tTime: 0:00:00.456842\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1562.826115625\tTime: 0:00:00.079859\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1567.0373125\tTime: 0:00:00.459513\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1557.25981875\tTime: 0:00:00.062938\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1562.2550395833334\tTime: 0:00:00.461353\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1551.855753125\tTime: 0:00:00.062584\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1559.107225\tTime: 0:00:00.458668\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1550.621728125\tTime: 0:00:00.064252\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1554.9702770833333\tTime: 0:00:00.461038\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1546.33888125\tTime: 0:00:00.062804\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1553.54064375\tTime: 0:00:00.456349\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1543.195753125\tTime: 0:00:00.062252\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1548.951578125\tTime: 0:00:00.458437\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1541.514784375\tTime: 0:00:00.062794\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1548.6909197916666\tTime: 0:00:00.459672\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1543.13528125\tTime: 0:00:00.062361\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1544.9688270833333\tTime: 0:00:00.460164\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1536.8465125\tTime: 0:00:00.063242\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1543.7958979166667\tTime: 0:00:00.458946\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1536.72419375\tTime: 0:00:00.062874\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1545.0253822916666\tTime: 0:00:00.461811\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1530.147453125\tTime: 0:00:00.063162\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1540.4791958333333\tTime: 0:00:00.613446\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1531.839959375\tTime: 0:00:00.063988\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1541.2449864583334\tTime: 0:00:00.466064\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1533.882734375\tTime: 0:00:00.062502\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1538.22745625\tTime: 0:00:00.467561\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1529.38789375\tTime: 0:00:00.063348\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1537.9044583333334\tTime: 0:00:00.466197\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1531.652153125\tTime: 0:00:00.064118\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1536.94708125\tTime: 0:00:00.459325\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1527.2532125\tTime: 0:00:00.063639\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1534.0635427083334\tTime: 0:00:00.458931\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1524.40555625\tTime: 0:00:00.063453\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1536.1461958333334\tTime: 0:00:00.462914\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1525.570865625\tTime: 0:00:00.063511\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1535.5713083333333\tTime: 0:00:00.465753\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1523.679459375\tTime: 0:00:00.062920\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1531.9886625\tTime: 0:00:00.458606\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1522.41860625\tTime: 0:00:00.062750\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1535.3051875\tTime: 0:00:00.468120\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1526.75075625\tTime: 0:00:00.063555\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1534.0795927083334\tTime: 0:00:00.461360\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1520.370259375\tTime: 0:00:00.063568\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1532.4915791666667\tTime: 0:00:00.458490\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1527.140909375\tTime: 0:00:00.063800\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1533.6557854166667\tTime: 0:00:00.467466\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1525.890471875\tTime: 0:00:00.064257\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1530.5316177083334\tTime: 0:00:00.462454\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1524.63829375\tTime: 0:00:00.063663\n",
      "Epoch: [34/100]\tSamples: [127500/375000]\tTrain Loss: 1533.8758104166666\tTime: 0:00:00.461927\n",
      "Epoch: [34/100]\tSamples: [1250/125000]\tValidation Loss: 1528.0782375\tTime: 0:00:00.065380\n",
      "Epoch: [35/100]\tSamples: [131250/375000]\tTrain Loss: 1530.4084875\tTime: 0:00:00.461838\n",
      "Epoch: [35/100]\tSamples: [1250/125000]\tValidation Loss: 1525.936075\tTime: 0:00:00.063109\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m16.584951307589545\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2084.5207407247385\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1801.4797395833334\tTime: 0:00:00.098513\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1670.9124375\tTime: 0:00:00.013171\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1785.2119270833334\tTime: 0:00:00.091110\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1676.3521875\tTime: 0:00:00.012668\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1749.8872708333333\tTime: 0:00:00.092451\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1684.3555625\tTime: 0:00:00.013121\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1721.3304375\tTime: 0:00:00.091118\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1682.41546875\tTime: 0:00:00.015769\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1695.0129270833334\tTime: 0:00:00.093805\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1664.54740625\tTime: 0:00:00.012835\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1673.2292083333334\tTime: 0:00:00.091324\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1634.7130625\tTime: 0:00:00.012808\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1653.5151770833334\tTime: 0:00:00.092247\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1610.4315625\tTime: 0:00:00.012785\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1640.0461041666667\tTime: 0:00:00.094524\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1591.05275\tTime: 0:00:00.015736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1629.7915625\tTime: 0:00:00.238717\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1589.057875\tTime: 0:00:00.012944\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1619.2229270833334\tTime: 0:00:00.098673\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1569.17375\tTime: 0:00:00.015811\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1610.1208229166666\tTime: 0:00:00.105025\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1567.0444375\tTime: 0:00:00.016028\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1595.4068333333332\tTime: 0:00:00.106470\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1560.042125\tTime: 0:00:00.016814\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1595.1064166666667\tTime: 0:00:00.098547\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1550.28140625\tTime: 0:00:00.012773\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1590.1363229166666\tTime: 0:00:00.104458\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1552.20178125\tTime: 0:00:00.015895\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1581.6863854166666\tTime: 0:00:00.105454\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1550.99690625\tTime: 0:00:00.015563\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1579.1050104166666\tTime: 0:00:00.106542\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1545.45040625\tTime: 0:00:00.016107\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1580.9552083333333\tTime: 0:00:00.099691\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1541.91515625\tTime: 0:00:00.012474\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1572.9597083333333\tTime: 0:00:00.093887\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1540.57275\tTime: 0:00:00.013024\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1567.1653020833332\tTime: 0:00:00.095139\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1537.4026875\tTime: 0:00:00.012690\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1566.1237604166668\tTime: 0:00:00.094603\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1537.191375\tTime: 0:00:00.013115\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1563.8613645833334\tTime: 0:00:00.105774\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1532.6729375\tTime: 0:00:00.015649\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1560.8000625\tTime: 0:00:00.104945\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1530.03815625\tTime: 0:00:00.016130\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1557.7848229166666\tTime: 0:00:00.093204\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1536.5971875\tTime: 0:00:00.015636\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1556.14659375\tTime: 0:00:00.095455\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1535.44603125\tTime: 0:00:00.013151\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1563.3181875\tTime: 0:00:00.094666\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1530.8254375\tTime: 0:00:00.012650\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1559.31115625\tTime: 0:00:00.094345\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1526.5545625\tTime: 0:00:00.013134\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1555.7838333333334\tTime: 0:00:00.093876\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1530.61003125\tTime: 0:00:00.012762\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1553.5542708333332\tTime: 0:00:00.093979\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1526.803\tTime: 0:00:00.013108\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1556.77671875\tTime: 0:00:00.096980\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1528.534375\tTime: 0:00:00.012577\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1551.07221875\tTime: 0:00:00.093078\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1525.31734375\tTime: 0:00:00.013128\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1555.84903125\tTime: 0:00:00.093334\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1527.468625\tTime: 0:00:00.012732\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1544.0991666666666\tTime: 0:00:00.093456\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1525.43146875\tTime: 0:00:00.013228\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1546.6753958333334\tTime: 0:00:00.093205\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1525.37159375\tTime: 0:00:00.012675\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1548.3377291666666\tTime: 0:00:00.093436\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1522.90840625\tTime: 0:00:00.012928\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1544.6869791666666\tTime: 0:00:00.100137\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1526.1485625\tTime: 0:00:00.012625\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1542.3141354166667\tTime: 0:00:00.093374\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1524.3709375\tTime: 0:00:00.013243\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1546.6106875\tTime: 0:00:00.093539\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1524.83715625\tTime: 0:00:00.012708\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1543.783875\tTime: 0:00:00.093816\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1522.79728125\tTime: 0:00:00.013042\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1542.95790625\tTime: 0:00:00.105867\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1527.53215625\tTime: 0:00:00.015672\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1543.7623229166666\tTime: 0:00:00.093730\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1519.9276875\tTime: 0:00:00.012875\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1538.9802604166666\tTime: 0:00:00.095080\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1523.15075\tTime: 0:00:00.012890\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1539.89528125\tTime: 0:00:00.094754\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1519.36315625\tTime: 0:00:00.013246\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1538.327\tTime: 0:00:00.098013\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1521.85728125\tTime: 0:00:00.012738\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1541.32665625\tTime: 0:00:00.094710\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1525.8389375\tTime: 0:00:00.012956\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1538.4310625\tTime: 0:00:00.091702\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1519.026375\tTime: 0:00:00.012594\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1537.6845104166666\tTime: 0:00:00.090219\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1521.37878125\tTime: 0:00:00.013135\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1536.3859791666666\tTime: 0:00:00.092537\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1520.1209375\tTime: 0:00:00.015399\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1539.5176354166667\tTime: 0:00:00.089403\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1520.043125\tTime: 0:00:00.013138\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1537.2998541666666\tTime: 0:00:00.091549\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1519.8518125\tTime: 0:00:00.012763\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1538.9362708333333\tTime: 0:00:00.094820\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1520.05253125\tTime: 0:00:00.013043\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m15.439855692809283\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2352.143437514461\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1792.4682604166667\tTime: 0:00:00.090558\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1662.09615625\tTime: 0:00:00.013083\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1775.5106145833333\tTime: 0:00:00.090324\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1666.33909375\tTime: 0:00:00.012643\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1745.8547916666666\tTime: 0:00:00.090604\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1678.1349375\tTime: 0:00:00.012726\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1715.8078645833334\tTime: 0:00:00.087698\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1676.51525\tTime: 0:00:00.012586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1688.3565208333334\tTime: 0:00:00.093857\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1655.31171875\tTime: 0:00:00.013110\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1671.5216979166667\tTime: 0:00:00.086940\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1627.8594375\tTime: 0:00:00.012632\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1652.4687291666667\tTime: 0:00:00.091208\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1609.0580625\tTime: 0:00:00.015865\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1635.3984583333333\tTime: 0:00:00.089664\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1592.23084375\tTime: 0:00:00.012703\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1627.1002395833334\tTime: 0:00:00.093056\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1581.0385\tTime: 0:00:00.012796\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1612.8683020833334\tTime: 0:00:00.093553\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1572.976375\tTime: 0:00:00.012732\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1609.58540625\tTime: 0:00:00.092356\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1566.46953125\tTime: 0:00:00.012984\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1601.4252708333333\tTime: 0:00:00.089609\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1558.55071875\tTime: 0:00:00.012656\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1596.0338541666667\tTime: 0:00:00.090902\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1553.00296875\tTime: 0:00:00.012768\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1589.58146875\tTime: 0:00:00.091939\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1548.3894375\tTime: 0:00:00.012756\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1584.0889583333333\tTime: 0:00:00.087533\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1547.1461875\tTime: 0:00:00.012953\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1579.1787916666667\tTime: 0:00:00.090197\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1545.4176875\tTime: 0:00:00.012728\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1574.0653958333332\tTime: 0:00:00.090244\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1536.14521875\tTime: 0:00:00.012776\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1574.9069895833334\tTime: 0:00:00.087648\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1537.216375\tTime: 0:00:00.012703\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1572.2906979166667\tTime: 0:00:00.090271\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1536.52334375\tTime: 0:00:00.012931\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1565.7921458333333\tTime: 0:00:00.090433\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1528.8511875\tTime: 0:00:00.012602\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1562.0704166666667\tTime: 0:00:00.092606\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1530.98159375\tTime: 0:00:00.013123\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1565.5854583333332\tTime: 0:00:00.086245\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1528.80921875\tTime: 0:00:00.012646\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1558.55959375\tTime: 0:00:00.092491\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1528.690375\tTime: 0:00:00.015625\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1554.0667395833334\tTime: 0:00:00.089994\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1525.54471875\tTime: 0:00:00.012656\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1555.8875625\tTime: 0:00:00.089550\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1525.62815625\tTime: 0:00:00.012796\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1556.1074895833333\tTime: 0:00:00.090909\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1521.26290625\tTime: 0:00:00.012903\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1547.2424791666667\tTime: 0:00:00.088640\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1519.59440625\tTime: 0:00:00.013136\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1550.11890625\tTime: 0:00:00.088083\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1520.9031875\tTime: 0:00:00.013254\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1547.4148229166667\tTime: 0:00:00.088692\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1522.9271875\tTime: 0:00:00.013110\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1545.39715625\tTime: 0:00:00.088399\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1520.5759375\tTime: 0:00:00.012785\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1545.8153958333332\tTime: 0:00:00.092146\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1523.2219375\tTime: 0:00:00.015640\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1540.7057083333334\tTime: 0:00:00.089830\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1520.650625\tTime: 0:00:00.012772\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m15.519847661362375\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2213.5280420817194\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1793.5741770833333\tTime: 0:00:00.089734\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1661.32246875\tTime: 0:00:00.013045\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1775.1237395833334\tTime: 0:00:00.092320\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1665.2210625\tTime: 0:00:00.012686\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1743.5273541666666\tTime: 0:00:00.088177\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1674.0980625\tTime: 0:00:00.013012\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1716.37646875\tTime: 0:00:00.093837\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1669.67634375\tTime: 0:00:00.012497\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1687.8804583333333\tTime: 0:00:00.086043\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1652.49121875\tTime: 0:00:00.012887\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1672.1358333333333\tTime: 0:00:00.087713\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1631.6631875\tTime: 0:00:00.015661\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1650.5903958333333\tTime: 0:00:00.086908\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1607.4305\tTime: 0:00:00.012993\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1638.0769479166668\tTime: 0:00:00.084777\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1597.69028125\tTime: 0:00:00.012625\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1630.2215833333332\tTime: 0:00:00.089023\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1591.344875\tTime: 0:00:00.015943\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1617.9679375\tTime: 0:00:00.089798\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1578.96234375\tTime: 0:00:00.012671\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1603.7353229166667\tTime: 0:00:00.089306\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1572.34171875\tTime: 0:00:00.012915\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1600.9705208333332\tTime: 0:00:00.090103\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1569.181\tTime: 0:00:00.012689\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1599.14590625\tTime: 0:00:00.088671\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1566.95503125\tTime: 0:00:00.012984\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1588.3637083333333\tTime: 0:00:00.089311\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1561.381125\tTime: 0:00:00.012774\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1584.43590625\tTime: 0:00:00.089982\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1553.36946875\tTime: 0:00:00.013042\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1582.7136458333334\tTime: 0:00:00.090539\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1552.69196875\tTime: 0:00:00.012567\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1576.2213645833333\tTime: 0:00:00.086708\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1547.36928125\tTime: 0:00:00.012848\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1571.9823645833333\tTime: 0:00:00.089779\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1545.72778125\tTime: 0:00:00.012774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1564.3858020833334\tTime: 0:00:00.085792\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1538.82028125\tTime: 0:00:00.013188\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1565.1237083333333\tTime: 0:00:00.090517\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1537.483\tTime: 0:00:00.012796\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1566.9943541666667\tTime: 0:00:00.094482\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1538.136\tTime: 0:00:00.013163\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1554.9808125\tTime: 0:00:00.089739\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1537.78375\tTime: 0:00:00.012815\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1555.0480520833332\tTime: 0:00:00.087434\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1534.8286875\tTime: 0:00:00.012769\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1549.5873020833333\tTime: 0:00:00.086822\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1530.78603125\tTime: 0:00:00.012732\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1548.7273229166667\tTime: 0:00:00.089470\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1532.9909375\tTime: 0:00:00.015837\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1551.1275\tTime: 0:00:00.084905\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1524.6838125\tTime: 0:00:00.012829\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1549.3853229166666\tTime: 0:00:00.104449\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1528.6044375\tTime: 0:00:00.016295\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1547.164625\tTime: 0:00:00.091463\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1528.34328125\tTime: 0:00:00.012684\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1547.0674583333334\tTime: 0:00:00.091095\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1526.52740625\tTime: 0:00:00.013128\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1538.8645625\tTime: 0:00:00.090145\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1524.00265625\tTime: 0:00:00.015517\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1544.6007708333334\tTime: 0:00:00.086603\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1524.62425\tTime: 0:00:00.013100\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1539.0718854166666\tTime: 0:00:00.088856\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1526.795625\tTime: 0:00:00.012880\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1538.5692708333333\tTime: 0:00:00.089992\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1525.26128125\tTime: 0:00:00.012846\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1537.7106041666666\tTime: 0:00:00.091460\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1524.79975\tTime: 0:00:00.015738\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1538.6103229166667\tTime: 0:00:00.092498\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1522.05128125\tTime: 0:00:00.012786\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1538.0295208333334\tTime: 0:00:00.089308\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1521.78075\tTime: 0:00:00.015739\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1538.4134166666668\tTime: 0:00:00.089927\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1519.6195\tTime: 0:00:00.012842\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1536.8300625\tTime: 0:00:00.088743\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1518.6315\tTime: 0:00:00.012940\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1533.7418958333333\tTime: 0:00:00.089040\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1521.50890625\tTime: 0:00:00.012937\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1533.9632916666667\tTime: 0:00:00.084088\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1516.7095625\tTime: 0:00:00.012614\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1531.81265625\tTime: 0:00:00.088490\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1518.3240625\tTime: 0:00:00.013024\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1529.84725\tTime: 0:00:00.087839\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1522.252625\tTime: 0:00:00.012624\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1532.0395833333334\tTime: 0:00:00.089447\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1517.90115625\tTime: 0:00:00.013093\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1528.5279791666667\tTime: 0:00:00.087118\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1519.4278125\tTime: 0:00:00.015756\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1528.4469375\tTime: 0:00:00.091272\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1522.30378125\tTime: 0:00:00.013186\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m15.498765997148768\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2329.960654531132\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1772.5755625\tTime: 0:00:00.093671\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1674.57984375\tTime: 0:00:00.013242\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1759.8369270833334\tTime: 0:00:00.090474\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1677.05046875\tTime: 0:00:00.013047\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1734.9124583333332\tTime: 0:00:00.094957\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1684.7215625\tTime: 0:00:00.013135\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1706.3118958333334\tTime: 0:00:00.088899\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1685.8765625\tTime: 0:00:00.012895\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1681.0632708333333\tTime: 0:00:00.092645\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1670.06234375\tTime: 0:00:00.013321\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1658.6626145833334\tTime: 0:00:00.094731\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1645.0743125\tTime: 0:00:00.013253\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1639.6120104166666\tTime: 0:00:00.092865\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1623.9905625\tTime: 0:00:00.013440\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1628.6883020833334\tTime: 0:00:00.092788\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1611.54903125\tTime: 0:00:00.013112\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1612.8843125\tTime: 0:00:00.087668\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1596.5191875\tTime: 0:00:00.013394\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1604.025625\tTime: 0:00:00.090801\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1592.41971875\tTime: 0:00:00.016007\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1596.1148541666666\tTime: 0:00:00.090942\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1582.59678125\tTime: 0:00:00.016169\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1591.0891666666666\tTime: 0:00:00.088979\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1576.96065625\tTime: 0:00:00.013305\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1582.1997604166668\tTime: 0:00:00.090441\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1573.6114375\tTime: 0:00:00.013380\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1573.90453125\tTime: 0:00:00.095171\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1565.83684375\tTime: 0:00:00.013372\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1577.1994270833334\tTime: 0:00:00.087619\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1560.24396875\tTime: 0:00:00.013551\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1567.516125\tTime: 0:00:00.092167\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1558.87390625\tTime: 0:00:00.012976\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1559.3841875\tTime: 0:00:00.093566\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1554.37975\tTime: 0:00:00.013280\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1556.43259375\tTime: 0:00:00.087318\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1553.197125\tTime: 0:00:00.013249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1553.33384375\tTime: 0:00:00.091291\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1551.484875\tTime: 0:00:00.013248\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1551.4522708333334\tTime: 0:00:00.093746\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1549.9939375\tTime: 0:00:00.013252\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1550.6826875\tTime: 0:00:00.090938\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1547.266\tTime: 0:00:00.013137\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1543.362875\tTime: 0:00:00.092285\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1545.8848125\tTime: 0:00:00.013077\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1544.0373020833333\tTime: 0:00:00.091579\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1544.23778125\tTime: 0:00:00.013300\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1539.94121875\tTime: 0:00:00.092324\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1542.63609375\tTime: 0:00:00.013125\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1542.66675\tTime: 0:00:00.090693\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1541.502375\tTime: 0:00:00.013147\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1537.6139270833332\tTime: 0:00:00.092838\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1541.4351875\tTime: 0:00:00.015845\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1538.2329375\tTime: 0:00:00.088507\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1542.56640625\tTime: 0:00:00.016185\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1535.79028125\tTime: 0:00:00.093531\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1539.4095\tTime: 0:00:00.012997\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1534.1483958333333\tTime: 0:00:00.090887\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1536.65090625\tTime: 0:00:00.013230\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1534.2040833333333\tTime: 0:00:00.092008\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1538.6055\tTime: 0:00:00.015906\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1531.8600520833334\tTime: 0:00:00.090957\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1537.34409375\tTime: 0:00:00.013298\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1531.94159375\tTime: 0:00:00.091562\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1535.04953125\tTime: 0:00:00.012929\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1531.4721458333333\tTime: 0:00:00.093300\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1537.88978125\tTime: 0:00:00.013338\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1529.3388125\tTime: 0:00:00.090760\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1532.84334375\tTime: 0:00:00.012901\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1528.0582604166666\tTime: 0:00:00.092155\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1530.80965625\tTime: 0:00:00.013345\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1523.7283541666666\tTime: 0:00:00.104461\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1532.25925\tTime: 0:00:00.013899\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1526.9823958333334\tTime: 0:00:00.091366\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1532.70609375\tTime: 0:00:00.013097\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1521.2703958333334\tTime: 0:00:00.089337\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1531.2234375\tTime: 0:00:00.016336\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1519.8336458333333\tTime: 0:00:00.089845\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1534.18690625\tTime: 0:00:00.013168\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1522.96959375\tTime: 0:00:00.093581\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1529.81546875\tTime: 0:00:00.016301\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1524.2370625\tTime: 0:00:00.097086\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1529.51740625\tTime: 0:00:00.013031\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1522.1855416666667\tTime: 0:00:00.093895\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1531.1049375\tTime: 0:00:00.013448\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1521.8291875\tTime: 0:00:00.090128\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1531.87321875\tTime: 0:00:00.013121\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1521.0128645833333\tTime: 0:00:00.087416\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1530.03128125\tTime: 0:00:00.013370\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1520.5512708333333\tTime: 0:00:00.089885\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1527.85325\tTime: 0:00:00.013087\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1519.7043958333334\tTime: 0:00:00.094968\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1528.91625\tTime: 0:00:00.013248\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1519.6167604166667\tTime: 0:00:00.093329\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1525.4010625\tTime: 0:00:00.013172\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1517.4061145833334\tTime: 0:00:00.094110\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1529.7038125\tTime: 0:00:00.014548\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1514.2117708333333\tTime: 0:00:00.087987\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1528.11246875\tTime: 0:00:00.013269\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1521.0195833333332\tTime: 0:00:00.091225\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1527.46821875\tTime: 0:00:00.013762\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1519.22475\tTime: 0:00:00.090301\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1531.69946875\tTime: 0:00:00.012958\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1516.3187291666666\tTime: 0:00:00.095290\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1527.2319375\tTime: 0:00:00.013221\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m15.517569854560325\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2327.9861957214366\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1780.6559166666666\tTime: 0:00:00.098860\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1677.38553125\tTime: 0:00:00.016135\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1764.9467604166666\tTime: 0:00:00.102023\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1682.4368125\tTime: 0:00:00.015769\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1733.08171875\tTime: 0:00:00.093467\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1691.245875\tTime: 0:00:00.013221\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1702.8993958333333\tTime: 0:00:00.092349\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1688.11571875\tTime: 0:00:00.012716\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1677.8570208333333\tTime: 0:00:00.091275\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1671.683125\tTime: 0:00:00.013102\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1655.4676875\tTime: 0:00:00.087889\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1648.8840625\tTime: 0:00:00.012963\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1637.7654375\tTime: 0:00:00.102183\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1621.22496875\tTime: 0:00:00.013381\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1624.1543854166666\tTime: 0:00:00.093397\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1606.937625\tTime: 0:00:00.015843\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1616.3209583333332\tTime: 0:00:00.090762\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1593.0030625\tTime: 0:00:00.013222\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1602.7804583333334\tTime: 0:00:00.110798\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1586.79278125\tTime: 0:00:00.013101\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1595.749375\tTime: 0:00:00.087264\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1579.286125\tTime: 0:00:00.012976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1587.5662604166666\tTime: 0:00:00.084581\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1572.611625\tTime: 0:00:00.013132\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1584.54578125\tTime: 0:00:00.084501\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1564.8116875\tTime: 0:00:00.012859\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1581.9595104166667\tTime: 0:00:00.090310\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1567.50778125\tTime: 0:00:00.013173\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1576.7127916666666\tTime: 0:00:00.088270\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1561.10725\tTime: 0:00:00.012802\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1566.8663854166666\tTime: 0:00:00.088826\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1558.07003125\tTime: 0:00:00.012966\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1562.2386145833334\tTime: 0:00:00.089841\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1554.07246875\tTime: 0:00:00.012663\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1556.7938645833333\tTime: 0:00:00.089720\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1551.89775\tTime: 0:00:00.013321\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1556.7277083333333\tTime: 0:00:00.090819\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1546.91665625\tTime: 0:00:00.015561\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1556.7557916666667\tTime: 0:00:00.090544\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1544.813\tTime: 0:00:00.013010\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1552.4912083333334\tTime: 0:00:00.089211\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1545.34859375\tTime: 0:00:00.012591\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1548.62990625\tTime: 0:00:00.091164\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1543.09215625\tTime: 0:00:00.013109\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1547.6841770833332\tTime: 0:00:00.090889\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1542.5824375\tTime: 0:00:00.015731\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1544.99484375\tTime: 0:00:00.092410\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1536.06384375\tTime: 0:00:00.013101\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1540.04196875\tTime: 0:00:00.093192\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1543.6741875\tTime: 0:00:00.012958\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1542.8115625\tTime: 0:00:00.090239\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1534.25321875\tTime: 0:00:00.013180\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1539.8748020833334\tTime: 0:00:00.092025\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1536.67675\tTime: 0:00:00.012758\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1535.7926354166666\tTime: 0:00:00.094260\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1537.17396875\tTime: 0:00:00.013243\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1534.9618541666666\tTime: 0:00:00.087924\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1534.34359375\tTime: 0:00:00.012729\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1535.45903125\tTime: 0:00:00.087898\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1531.17275\tTime: 0:00:00.016035\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1531.57196875\tTime: 0:00:00.090064\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1529.5274375\tTime: 0:00:00.012885\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1529.0360625\tTime: 0:00:00.091098\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1527.5234375\tTime: 0:00:00.013179\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1532.5268020833332\tTime: 0:00:00.088381\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1530.2018125\tTime: 0:00:00.012793\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1536.368125\tTime: 0:00:00.089974\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1526.74378125\tTime: 0:00:00.013045\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1530.43928125\tTime: 0:00:00.085609\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1525.5940625\tTime: 0:00:00.012811\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1529.92815625\tTime: 0:00:00.087382\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1524.0864375\tTime: 0:00:00.013144\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1530.7717604166667\tTime: 0:00:00.087076\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1527.697875\tTime: 0:00:00.013027\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1528.3613125\tTime: 0:00:00.089837\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1527.3446875\tTime: 0:00:00.013435\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1523.1548229166667\tTime: 0:00:00.087324\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1525.9593125\tTime: 0:00:00.012786\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1523.79459375\tTime: 0:00:00.091209\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1525.931625\tTime: 0:00:00.013190\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1523.38390625\tTime: 0:00:00.090845\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1525.7870625\tTime: 0:00:00.012714\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m15.477383413307397\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2329.730755624605\u001b[0m\n",
      "Nodes averages betas and thetas inf:  15.49068452383763 2310.6698170946706\n",
      "Executing for eta equals to  0.08\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:59<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 34.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:59<00:00, 33.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 34.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 20)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1798.2721520833334\tTime: 0:00:00.449375\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1702.363534375\tTime: 0:00:00.061614\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1732.3134041666667\tTime: 0:00:00.441534\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1672.002603125\tTime: 0:00:00.062204\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1688.0515385416666\tTime: 0:00:00.446086\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1642.160709375\tTime: 0:00:00.062534\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1661.589390625\tTime: 0:00:00.443977\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1624.494984375\tTime: 0:00:00.062869\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1647.6813739583333\tTime: 0:00:00.440725\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1617.19345\tTime: 0:00:00.061543\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1639.809278125\tTime: 0:00:00.436565\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1612.37425625\tTime: 0:00:00.063054\n",
      "Epoch: [7/100]\tSamples: [26250/375000]\tTrain Loss: 1634.4037989583333\tTime: 0:00:00.443121\n",
      "Epoch: [7/100]\tSamples: [1250/125000]\tValidation Loss: 1609.25288125\tTime: 0:00:00.061495\n",
      "Epoch: [8/100]\tSamples: [30000/375000]\tTrain Loss: 1629.1833208333333\tTime: 0:00:00.439718\n",
      "Epoch: [8/100]\tSamples: [1250/125000]\tValidation Loss: 1607.090365625\tTime: 0:00:00.063308\n",
      "Epoch: [9/100]\tSamples: [33750/375000]\tTrain Loss: 1625.6544510416666\tTime: 0:00:00.440230\n",
      "Epoch: [9/100]\tSamples: [1250/125000]\tValidation Loss: 1603.86294375\tTime: 0:00:00.061971\n",
      "Epoch: [10/100]\tSamples: [37500/375000]\tTrain Loss: 1622.09563125\tTime: 0:00:00.457672\n",
      "Epoch: [10/100]\tSamples: [1250/125000]\tValidation Loss: 1602.40755625\tTime: 0:00:00.063087\n",
      "Epoch: [11/100]\tSamples: [41250/375000]\tTrain Loss: 1620.8322260416667\tTime: 0:00:00.437889\n",
      "Epoch: [11/100]\tSamples: [1250/125000]\tValidation Loss: 1601.19581875\tTime: 0:00:00.061332\n",
      "Epoch: [12/100]\tSamples: [45000/375000]\tTrain Loss: 1618.5905322916667\tTime: 0:00:00.439173\n",
      "Epoch: [12/100]\tSamples: [1250/125000]\tValidation Loss: 1599.653184375\tTime: 0:00:00.062073\n",
      "Epoch: [13/100]\tSamples: [48750/375000]\tTrain Loss: 1615.5486416666668\tTime: 0:00:00.442377\n",
      "Epoch: [13/100]\tSamples: [1250/125000]\tValidation Loss: 1598.651434375\tTime: 0:00:00.061771\n",
      "Epoch: [14/100]\tSamples: [52500/375000]\tTrain Loss: 1614.4543614583333\tTime: 0:00:00.439680\n",
      "Epoch: [14/100]\tSamples: [1250/125000]\tValidation Loss: 1597.45556875\tTime: 0:00:00.062661\n",
      "Epoch: [15/100]\tSamples: [56250/375000]\tTrain Loss: 1613.3628020833332\tTime: 0:00:00.439367\n",
      "Epoch: [15/100]\tSamples: [1250/125000]\tValidation Loss: 1597.606046875\tTime: 0:00:00.061320\n",
      "Epoch: [16/100]\tSamples: [60000/375000]\tTrain Loss: 1612.9786010416667\tTime: 0:00:00.439993\n",
      "Epoch: [16/100]\tSamples: [1250/125000]\tValidation Loss: 1596.2047\tTime: 0:00:00.062347\n",
      "Epoch: [17/100]\tSamples: [63750/375000]\tTrain Loss: 1611.8818875\tTime: 0:00:00.441458\n",
      "Epoch: [17/100]\tSamples: [1250/125000]\tValidation Loss: 1594.661978125\tTime: 0:00:00.062361\n",
      "Epoch: [18/100]\tSamples: [67500/375000]\tTrain Loss: 1610.8088958333333\tTime: 0:00:00.439647\n",
      "Epoch: [18/100]\tSamples: [1250/125000]\tValidation Loss: 1593.266934375\tTime: 0:00:00.062635\n",
      "Epoch: [19/100]\tSamples: [71250/375000]\tTrain Loss: 1608.584940625\tTime: 0:00:00.451873\n",
      "Epoch: [19/100]\tSamples: [1250/125000]\tValidation Loss: 1592.45400625\tTime: 0:00:00.063764\n",
      "Epoch: [20/100]\tSamples: [75000/375000]\tTrain Loss: 1608.134528125\tTime: 0:00:00.437608\n",
      "Epoch: [20/100]\tSamples: [1250/125000]\tValidation Loss: 1590.383475\tTime: 0:00:00.064075\n",
      "Epoch: [21/100]\tSamples: [78750/375000]\tTrain Loss: 1606.6522864583333\tTime: 0:00:00.439680\n",
      "Epoch: [21/100]\tSamples: [1250/125000]\tValidation Loss: 1589.296159375\tTime: 0:00:00.062046\n",
      "Epoch: [22/100]\tSamples: [82500/375000]\tTrain Loss: 1604.3261114583333\tTime: 0:00:00.434425\n",
      "Epoch: [22/100]\tSamples: [1250/125000]\tValidation Loss: 1587.2944625\tTime: 0:00:00.063978\n",
      "Epoch: [23/100]\tSamples: [86250/375000]\tTrain Loss: 1601.3615822916668\tTime: 0:00:00.435559\n",
      "Epoch: [23/100]\tSamples: [1250/125000]\tValidation Loss: 1585.33435\tTime: 0:00:00.063612\n",
      "Epoch: [24/100]\tSamples: [90000/375000]\tTrain Loss: 1601.7911635416667\tTime: 0:00:00.437295\n",
      "Epoch: [24/100]\tSamples: [1250/125000]\tValidation Loss: 1584.3728875\tTime: 0:00:00.064030\n",
      "Epoch: [25/100]\tSamples: [93750/375000]\tTrain Loss: 1602.5117020833334\tTime: 0:00:00.583024\n",
      "Epoch: [25/100]\tSamples: [1250/125000]\tValidation Loss: 1583.82773125\tTime: 0:00:00.063578\n",
      "Epoch: [26/100]\tSamples: [97500/375000]\tTrain Loss: 1600.7856916666667\tTime: 0:00:00.436619\n",
      "Epoch: [26/100]\tSamples: [1250/125000]\tValidation Loss: 1580.8494125\tTime: 0:00:00.063921\n",
      "Epoch: [27/100]\tSamples: [101250/375000]\tTrain Loss: 1599.4024927083333\tTime: 0:00:00.430664\n",
      "Epoch: [27/100]\tSamples: [1250/125000]\tValidation Loss: 1581.405215625\tTime: 0:00:00.063015\n",
      "Epoch: [28/100]\tSamples: [105000/375000]\tTrain Loss: 1598.4173229166668\tTime: 0:00:00.444087\n",
      "Epoch: [28/100]\tSamples: [1250/125000]\tValidation Loss: 1581.18449375\tTime: 0:00:00.063710\n",
      "Epoch: [29/100]\tSamples: [108750/375000]\tTrain Loss: 1598.41395625\tTime: 0:00:00.440798\n",
      "Epoch: [29/100]\tSamples: [1250/125000]\tValidation Loss: 1579.01926875\tTime: 0:00:00.063230\n",
      "Epoch: [30/100]\tSamples: [112500/375000]\tTrain Loss: 1596.396996875\tTime: 0:00:00.444655\n",
      "Epoch: [30/100]\tSamples: [1250/125000]\tValidation Loss: 1578.32903125\tTime: 0:00:00.064471\n",
      "Epoch: [31/100]\tSamples: [116250/375000]\tTrain Loss: 1595.9897041666666\tTime: 0:00:00.439672\n",
      "Epoch: [31/100]\tSamples: [1250/125000]\tValidation Loss: 1577.604140625\tTime: 0:00:00.070094\n",
      "Epoch: [32/100]\tSamples: [120000/375000]\tTrain Loss: 1595.1375208333334\tTime: 0:00:00.444019\n",
      "Epoch: [32/100]\tSamples: [1250/125000]\tValidation Loss: 1575.950059375\tTime: 0:00:00.064981\n",
      "Epoch: [33/100]\tSamples: [123750/375000]\tTrain Loss: 1594.068865625\tTime: 0:00:00.442051\n",
      "Epoch: [33/100]\tSamples: [1250/125000]\tValidation Loss: 1576.27725625\tTime: 0:00:00.063427\n",
      "Epoch: [34/100]\tSamples: [127500/375000]\tTrain Loss: 1593.3866416666667\tTime: 0:00:00.442838\n",
      "Epoch: [34/100]\tSamples: [1250/125000]\tValidation Loss: 1575.7813\tTime: 0:00:00.063859\n",
      "Epoch: [35/100]\tSamples: [131250/375000]\tTrain Loss: 1591.9567677083332\tTime: 0:00:00.444113\n",
      "Epoch: [35/100]\tSamples: [1250/125000]\tValidation Loss: 1576.635153125\tTime: 0:00:00.062699\n",
      "Epoch: [36/100]\tSamples: [135000/375000]\tTrain Loss: 1592.2796916666666\tTime: 0:00:00.441445\n",
      "Epoch: [36/100]\tSamples: [1250/125000]\tValidation Loss: 1576.12709375\tTime: 0:00:00.064555\n",
      "Epoch: [37/100]\tSamples: [138750/375000]\tTrain Loss: 1590.51203125\tTime: 0:00:00.441766\n",
      "Epoch: [37/100]\tSamples: [1250/125000]\tValidation Loss: 1575.143996875\tTime: 0:00:00.062910\n",
      "Epoch: [38/100]\tSamples: [142500/375000]\tTrain Loss: 1591.792509375\tTime: 0:00:00.439829\n",
      "Epoch: [38/100]\tSamples: [1250/125000]\tValidation Loss: 1577.2506625\tTime: 0:00:00.064406\n",
      "Epoch: [39/100]\tSamples: [146250/375000]\tTrain Loss: 1590.985575\tTime: 0:00:00.441036\n",
      "Epoch: [39/100]\tSamples: [1250/125000]\tValidation Loss: 1573.310603125\tTime: 0:00:00.063042\n",
      "Epoch: [40/100]\tSamples: [150000/375000]\tTrain Loss: 1590.8440125\tTime: 0:00:00.442963\n",
      "Epoch: [40/100]\tSamples: [1250/125000]\tValidation Loss: 1570.03055625\tTime: 0:00:00.064710\n",
      "Epoch: [41/100]\tSamples: [153750/375000]\tTrain Loss: 1589.7737083333334\tTime: 0:00:00.441582\n",
      "Epoch: [41/100]\tSamples: [1250/125000]\tValidation Loss: 1571.09539375\tTime: 0:00:00.063938\n",
      "Epoch: [42/100]\tSamples: [157500/375000]\tTrain Loss: 1590.0447291666667\tTime: 0:00:00.438236\n",
      "Epoch: [42/100]\tSamples: [1250/125000]\tValidation Loss: 1572.88240625\tTime: 0:00:00.064995\n",
      "Epoch: [43/100]\tSamples: [161250/375000]\tTrain Loss: 1589.1576760416667\tTime: 0:00:00.439304\n",
      "Epoch: [43/100]\tSamples: [1250/125000]\tValidation Loss: 1570.372240625\tTime: 0:00:00.064012\n",
      "Epoch: [44/100]\tSamples: [165000/375000]\tTrain Loss: 1588.821246875\tTime: 0:00:00.441961\n",
      "Epoch: [44/100]\tSamples: [1250/125000]\tValidation Loss: 1572.539978125\tTime: 0:00:00.064292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45/100]\tSamples: [168750/375000]\tTrain Loss: 1588.4388197916667\tTime: 0:00:00.444121\n",
      "Epoch: [45/100]\tSamples: [1250/125000]\tValidation Loss: 1569.068725\tTime: 0:00:00.071990\n",
      "Epoch: [46/100]\tSamples: [172500/375000]\tTrain Loss: 1588.3953416666666\tTime: 0:00:00.443497\n",
      "Epoch: [46/100]\tSamples: [1250/125000]\tValidation Loss: 1569.36701875\tTime: 0:00:00.064670\n",
      "Epoch: [47/100]\tSamples: [176250/375000]\tTrain Loss: 1587.9082020833334\tTime: 0:00:00.446821\n",
      "Epoch: [47/100]\tSamples: [1250/125000]\tValidation Loss: 1568.64375\tTime: 0:00:00.063392\n",
      "Epoch: [48/100]\tSamples: [180000/375000]\tTrain Loss: 1587.135496875\tTime: 0:00:00.440481\n",
      "Epoch: [48/100]\tSamples: [1250/125000]\tValidation Loss: 1571.3181625\tTime: 0:00:00.064399\n",
      "Epoch: [49/100]\tSamples: [183750/375000]\tTrain Loss: 1587.2908583333333\tTime: 0:00:00.446315\n",
      "Epoch: [49/100]\tSamples: [1250/125000]\tValidation Loss: 1569.3883375\tTime: 0:00:00.063977\n",
      "Epoch: [50/100]\tSamples: [187500/375000]\tTrain Loss: 1587.4054458333333\tTime: 0:00:00.443596\n",
      "Epoch: [50/100]\tSamples: [1250/125000]\tValidation Loss: 1567.4742625\tTime: 0:00:00.064942\n",
      "Epoch: [51/100]\tSamples: [191250/375000]\tTrain Loss: 1587.30460625\tTime: 0:00:00.438456\n",
      "Epoch: [51/100]\tSamples: [1250/125000]\tValidation Loss: 1567.728790625\tTime: 0:00:00.063966\n",
      "Epoch: [52/100]\tSamples: [195000/375000]\tTrain Loss: 1587.406975\tTime: 0:00:00.624100\n",
      "Epoch: [52/100]\tSamples: [1250/125000]\tValidation Loss: 1569.28224375\tTime: 0:00:00.082811\n",
      "Epoch: [53/100]\tSamples: [198750/375000]\tTrain Loss: 1585.763321875\tTime: 0:00:00.480871\n",
      "Epoch: [53/100]\tSamples: [1250/125000]\tValidation Loss: 1566.158409375\tTime: 0:00:00.064089\n",
      "Epoch: [54/100]\tSamples: [202500/375000]\tTrain Loss: 1586.10745\tTime: 0:00:00.447727\n",
      "Epoch: [54/100]\tSamples: [1250/125000]\tValidation Loss: 1568.701034375\tTime: 0:00:00.064772\n",
      "Epoch: [55/100]\tSamples: [206250/375000]\tTrain Loss: 1585.3798104166667\tTime: 0:00:00.441810\n",
      "Epoch: [55/100]\tSamples: [1250/125000]\tValidation Loss: 1568.362928125\tTime: 0:00:00.064729\n",
      "Epoch: [56/100]\tSamples: [210000/375000]\tTrain Loss: 1586.22246875\tTime: 0:00:00.443071\n",
      "Epoch: [56/100]\tSamples: [1250/125000]\tValidation Loss: 1568.48919375\tTime: 0:00:00.064091\n",
      "Epoch: [57/100]\tSamples: [213750/375000]\tTrain Loss: 1584.388125\tTime: 0:00:00.438531\n",
      "Epoch: [57/100]\tSamples: [1250/125000]\tValidation Loss: 1567.38150625\tTime: 0:00:00.063695\n",
      "Epoch: [58/100]\tSamples: [217500/375000]\tTrain Loss: 1585.7360604166668\tTime: 0:00:00.436341\n",
      "Epoch: [58/100]\tSamples: [1250/125000]\tValidation Loss: 1564.8968875\tTime: 0:00:00.065018\n",
      "Epoch: [59/100]\tSamples: [221250/375000]\tTrain Loss: 1584.3553458333333\tTime: 0:00:00.439913\n",
      "Epoch: [59/100]\tSamples: [1250/125000]\tValidation Loss: 1566.343403125\tTime: 0:00:00.064439\n",
      "Epoch: [60/100]\tSamples: [225000/375000]\tTrain Loss: 1585.732084375\tTime: 0:00:00.439259\n",
      "Epoch: [60/100]\tSamples: [1250/125000]\tValidation Loss: 1564.353778125\tTime: 0:00:00.065057\n",
      "Epoch: [61/100]\tSamples: [228750/375000]\tTrain Loss: 1584.6910041666667\tTime: 0:00:00.442249\n",
      "Epoch: [61/100]\tSamples: [1250/125000]\tValidation Loss: 1564.281415625\tTime: 0:00:00.070180\n",
      "Epoch: [62/100]\tSamples: [232500/375000]\tTrain Loss: 1583.0097125\tTime: 0:00:00.440927\n",
      "Epoch: [62/100]\tSamples: [1250/125000]\tValidation Loss: 1565.20758125\tTime: 0:00:00.065102\n",
      "Epoch: [63/100]\tSamples: [236250/375000]\tTrain Loss: 1582.1597229166666\tTime: 0:00:00.445831\n",
      "Epoch: [63/100]\tSamples: [1250/125000]\tValidation Loss: 1563.788340625\tTime: 0:00:00.064318\n",
      "Epoch: [64/100]\tSamples: [240000/375000]\tTrain Loss: 1584.4724354166667\tTime: 0:00:00.448928\n",
      "Epoch: [64/100]\tSamples: [1250/125000]\tValidation Loss: 1566.32869375\tTime: 0:00:00.065047\n",
      "Epoch: [65/100]\tSamples: [243750/375000]\tTrain Loss: 1583.1584729166666\tTime: 0:00:00.443655\n",
      "Epoch: [65/100]\tSamples: [1250/125000]\tValidation Loss: 1562.968175\tTime: 0:00:00.064177\n",
      "Epoch: [66/100]\tSamples: [247500/375000]\tTrain Loss: 1584.0622270833333\tTime: 0:00:00.447727\n",
      "Epoch: [66/100]\tSamples: [1250/125000]\tValidation Loss: 1565.694875\tTime: 0:00:00.065362\n",
      "Epoch: [67/100]\tSamples: [251250/375000]\tTrain Loss: 1583.5063895833334\tTime: 0:00:00.441957\n",
      "Epoch: [67/100]\tSamples: [1250/125000]\tValidation Loss: 1566.26691875\tTime: 0:00:00.063909\n",
      "Epoch: [68/100]\tSamples: [255000/375000]\tTrain Loss: 1582.8181760416667\tTime: 0:00:00.441194\n",
      "Epoch: [68/100]\tSamples: [1250/125000]\tValidation Loss: 1563.958696875\tTime: 0:00:00.083214\n",
      "Epoch: [69/100]\tSamples: [258750/375000]\tTrain Loss: 1583.2101447916666\tTime: 0:00:00.450209\n",
      "Epoch: [69/100]\tSamples: [1250/125000]\tValidation Loss: 1563.906846875\tTime: 0:00:00.064478\n",
      "Epoch: [70/100]\tSamples: [262500/375000]\tTrain Loss: 1583.0533708333332\tTime: 0:00:00.440733\n",
      "Epoch: [70/100]\tSamples: [1250/125000]\tValidation Loss: 1566.3067\tTime: 0:00:00.064580\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m22.65822185012252\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2162.682585997822\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1807.7537916666668\tTime: 0:00:00.092477\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1701.16278125\tTime: 0:00:00.016567\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1799.1421041666667\tTime: 0:00:00.094514\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1701.746125\tTime: 0:00:00.013560\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1786.8261354166666\tTime: 0:00:00.093656\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1704.64521875\tTime: 0:00:00.013623\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1775.3131666666666\tTime: 0:00:00.096595\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1706.9735\tTime: 0:00:00.016367\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1752.77478125\tTime: 0:00:00.096190\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1706.12559375\tTime: 0:00:00.013575\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1731.9992083333334\tTime: 0:00:00.093830\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1698.24703125\tTime: 0:00:00.013346\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1718.8594270833332\tTime: 0:00:00.095001\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1692.3955\tTime: 0:00:00.013410\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1705.336875\tTime: 0:00:00.093049\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1686.1085625\tTime: 0:00:00.016439\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1693.1079791666666\tTime: 0:00:00.096000\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1677.72753125\tTime: 0:00:00.013310\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1682.5058958333334\tTime: 0:00:00.093800\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1670.896\tTime: 0:00:00.016480\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1671.9567916666667\tTime: 0:00:00.093409\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1663.3210625\tTime: 0:00:00.016593\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1663.6387916666667\tTime: 0:00:00.092666\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1657.731125\tTime: 0:00:00.016527\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1657.919625\tTime: 0:00:00.095406\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1652.78421875\tTime: 0:00:00.016628\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1654.0041041666666\tTime: 0:00:00.094684\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1650.155125\tTime: 0:00:00.016547\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1646.64334375\tTime: 0:00:00.095026\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1642.46065625\tTime: 0:00:00.016514\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1641.373875\tTime: 0:00:00.095026\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1637.17603125\tTime: 0:00:00.016432\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1635.2571875\tTime: 0:00:00.093989\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1636.95153125\tTime: 0:00:00.016781\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1631.7018333333333\tTime: 0:00:00.095679\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1633.31671875\tTime: 0:00:00.016482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1628.1848020833334\tTime: 0:00:00.095387\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1628.462625\tTime: 0:00:00.013750\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1624.0421666666666\tTime: 0:00:00.094616\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1625.7174375\tTime: 0:00:00.016309\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1621.1073541666667\tTime: 0:00:00.092531\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1622.709125\tTime: 0:00:00.013832\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1620.2512291666667\tTime: 0:00:00.094630\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1619.71434375\tTime: 0:00:00.013688\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1612.9466041666667\tTime: 0:00:00.093052\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1619.2754375\tTime: 0:00:00.014102\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1610.2793020833333\tTime: 0:00:00.092781\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1617.362\tTime: 0:00:00.013759\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1610.4302604166667\tTime: 0:00:00.094135\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1616.9934375\tTime: 0:00:00.013666\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1606.76453125\tTime: 0:00:00.095756\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1615.09340625\tTime: 0:00:00.013356\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1601.079125\tTime: 0:00:00.092929\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1613.062\tTime: 0:00:00.016794\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1599.4507708333333\tTime: 0:00:00.095875\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1611.39546875\tTime: 0:00:00.016358\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1601.378\tTime: 0:00:00.096152\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1609.2210625\tTime: 0:00:00.013545\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1598.0836041666666\tTime: 0:00:00.093853\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1609.0379375\tTime: 0:00:00.016243\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1596.0538958333334\tTime: 0:00:00.092403\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1605.6356875\tTime: 0:00:00.016816\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1593.879125\tTime: 0:00:00.096080\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1607.824125\tTime: 0:00:00.016265\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1594.3121666666666\tTime: 0:00:00.095218\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1605.64740625\tTime: 0:00:00.016737\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1593.4441666666667\tTime: 0:00:00.094671\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1605.33565625\tTime: 0:00:00.016268\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1591.3203541666667\tTime: 0:00:00.095980\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1606.7865\tTime: 0:00:00.016834\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1590.6783541666666\tTime: 0:00:00.096530\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1602.63128125\tTime: 0:00:00.016162\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1586.4524270833333\tTime: 0:00:00.099934\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1601.671375\tTime: 0:00:00.013590\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1586.3909166666667\tTime: 0:00:00.093927\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1601.1763125\tTime: 0:00:00.013539\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1585.0191875\tTime: 0:00:00.094420\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1600.65884375\tTime: 0:00:00.013659\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1584.8187604166667\tTime: 0:00:00.094842\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1601.5286875\tTime: 0:00:00.016657\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1588.2379895833333\tTime: 0:00:00.097312\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1599.63565625\tTime: 0:00:00.016886\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1584.2624166666667\tTime: 0:00:00.093951\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1603.1391875\tTime: 0:00:00.016166\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1582.76571875\tTime: 0:00:00.095490\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1602.55771875\tTime: 0:00:00.013573\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1580.9516666666666\tTime: 0:00:00.092105\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1599.66621875\tTime: 0:00:00.016468\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1580.76403125\tTime: 0:00:00.095693\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1600.25371875\tTime: 0:00:00.016694\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1578.6263229166666\tTime: 0:00:00.094807\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1598.13525\tTime: 0:00:00.016266\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1585.3429270833333\tTime: 0:00:00.101533\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1599.4035\tTime: 0:00:00.016692\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1578.25234375\tTime: 0:00:00.105318\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1599.28540625\tTime: 0:00:00.016491\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1577.2832291666666\tTime: 0:00:00.107636\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1598.87228125\tTime: 0:00:00.016696\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1580.0535833333333\tTime: 0:00:00.108124\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1596.608625\tTime: 0:00:00.016450\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1580.7262604166667\tTime: 0:00:00.103779\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1595.73615625\tTime: 0:00:00.013717\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1578.0590104166668\tTime: 0:00:00.094261\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1599.448375\tTime: 0:00:00.017432\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1577.017375\tTime: 0:00:00.096321\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1598.87690625\tTime: 0:00:00.016454\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1576.57165625\tTime: 0:00:00.095911\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1596.604875\tTime: 0:00:00.016358\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1575.78175\tTime: 0:00:00.096285\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1598.300125\tTime: 0:00:00.016614\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1576.4704375\tTime: 0:00:00.094689\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1597.5461875\tTime: 0:00:00.013613\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m22.289714486254297\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2476.8240414845054\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1791.843375\tTime: 0:00:00.095389\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1702.52690625\tTime: 0:00:00.013223\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1784.99928125\tTime: 0:00:00.091985\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1703.29275\tTime: 0:00:00.013146\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1771.033125\tTime: 0:00:00.095914\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1705.83546875\tTime: 0:00:00.016478\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1754.51871875\tTime: 0:00:00.094565\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1707.47525\tTime: 0:00:00.013200\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1737.1364479166666\tTime: 0:00:00.095637\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1704.3971875\tTime: 0:00:00.013307\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1717.43765625\tTime: 0:00:00.090696\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1695.14696875\tTime: 0:00:00.016248\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1702.3942604166666\tTime: 0:00:00.090506\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1688.17090625\tTime: 0:00:00.013524\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1688.9189375\tTime: 0:00:00.093207\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1682.3410625\tTime: 0:00:00.016080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1675.23925\tTime: 0:00:00.094288\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1678.1246875\tTime: 0:00:00.016570\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1667.1276875\tTime: 0:00:00.092808\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1667.29578125\tTime: 0:00:00.016156\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1658.9000416666668\tTime: 0:00:00.092823\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1663.7214375\tTime: 0:00:00.013339\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1648.3488958333332\tTime: 0:00:00.105310\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1655.671125\tTime: 0:00:00.016232\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1643.286875\tTime: 0:00:00.105186\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1648.5734375\tTime: 0:00:00.014935\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1634.594\tTime: 0:00:00.092377\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1646.25078125\tTime: 0:00:00.016093\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1630.6874270833334\tTime: 0:00:00.093779\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1645.24915625\tTime: 0:00:00.016152\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1627.4368854166667\tTime: 0:00:00.095113\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1641.83965625\tTime: 0:00:00.012953\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1621.7250520833334\tTime: 0:00:00.094613\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1642.9176875\tTime: 0:00:00.016138\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1616.3289375\tTime: 0:00:00.092595\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1637.7419375\tTime: 0:00:00.016018\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1615.3544375\tTime: 0:00:00.093974\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1634.75403125\tTime: 0:00:00.016331\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1609.6395\tTime: 0:00:00.093446\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1629.74515625\tTime: 0:00:00.016075\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1604.0096979166667\tTime: 0:00:00.094554\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1626.10775\tTime: 0:00:00.013647\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1601.70903125\tTime: 0:00:00.094620\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1628.27590625\tTime: 0:00:00.015966\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1598.5971979166666\tTime: 0:00:00.097014\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1622.0100625\tTime: 0:00:00.016463\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1595.0387916666666\tTime: 0:00:00.093115\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1620.8716875\tTime: 0:00:00.016155\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1592.021\tTime: 0:00:00.093365\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1619.3795\tTime: 0:00:00.016450\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1592.1443854166666\tTime: 0:00:00.095939\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1621.08875\tTime: 0:00:00.016186\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1587.6068020833334\tTime: 0:00:00.099660\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1618.763\tTime: 0:00:00.013373\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1589.39259375\tTime: 0:00:00.095419\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1617.38025\tTime: 0:00:00.013318\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1586.39015625\tTime: 0:00:00.093854\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1616.35475\tTime: 0:00:00.013513\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1581.3744583333332\tTime: 0:00:00.095738\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1614.57234375\tTime: 0:00:00.013393\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1584.4162083333333\tTime: 0:00:00.092991\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1614.4125\tTime: 0:00:00.013278\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1580.0096145833334\tTime: 0:00:00.099201\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1613.64184375\tTime: 0:00:00.013439\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1582.99484375\tTime: 0:00:00.094640\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1611.5125625\tTime: 0:00:00.015920\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1576.76275\tTime: 0:00:00.107418\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1611.54153125\tTime: 0:00:00.013976\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1580.3863541666667\tTime: 0:00:00.094331\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1610.655875\tTime: 0:00:00.013198\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1576.05634375\tTime: 0:00:00.095066\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1613.97540625\tTime: 0:00:00.016712\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1573.9045416666668\tTime: 0:00:00.095467\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1613.74121875\tTime: 0:00:00.016246\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1576.0117708333332\tTime: 0:00:00.095142\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1611.1643125\tTime: 0:00:00.013570\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1572.1945625\tTime: 0:00:00.093429\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1609.79078125\tTime: 0:00:00.013196\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1576.49440625\tTime: 0:00:00.092164\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1608.89978125\tTime: 0:00:00.013770\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1570.46090625\tTime: 0:00:00.092312\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1609.785375\tTime: 0:00:00.013396\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1572.4041354166666\tTime: 0:00:00.094238\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1608.9790625\tTime: 0:00:00.016665\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1569.3115104166666\tTime: 0:00:00.092232\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1612.30675\tTime: 0:00:00.016217\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1572.46996875\tTime: 0:00:00.094859\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1606.71703125\tTime: 0:00:00.016714\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1569.0652916666666\tTime: 0:00:00.106049\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1609.40415625\tTime: 0:00:00.016301\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1566.39821875\tTime: 0:00:00.096068\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1609.9288125\tTime: 0:00:00.016634\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1567.0104479166666\tTime: 0:00:00.094262\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1606.98228125\tTime: 0:00:00.013125\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1569.4655729166666\tTime: 0:00:00.093330\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1610.93409375\tTime: 0:00:00.013900\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1567.9652916666666\tTime: 0:00:00.090830\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1607.125625\tTime: 0:00:00.013625\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m22.239998052602857\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2416.521674755327\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1820.78309375\tTime: 0:00:00.094896\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1677.29996875\tTime: 0:00:00.016783\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1813.7221875\tTime: 0:00:00.090955\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1677.8646875\tTime: 0:00:00.016073\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1803.9184375\tTime: 0:00:00.096798\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1680.7551875\tTime: 0:00:00.016412\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1783.7498958333333\tTime: 0:00:00.092946\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1682.81228125\tTime: 0:00:00.016264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1766.3941354166666\tTime: 0:00:00.097681\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1680.7298125\tTime: 0:00:00.013735\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1748.0831354166667\tTime: 0:00:00.095598\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1673.56284375\tTime: 0:00:00.016258\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1731.2819270833334\tTime: 0:00:00.094699\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1663.75371875\tTime: 0:00:00.013447\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1717.6927395833334\tTime: 0:00:00.092698\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1656.9601875\tTime: 0:00:00.016306\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1705.37015625\tTime: 0:00:00.094140\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1653.404625\tTime: 0:00:00.016657\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1696.3579895833334\tTime: 0:00:00.095110\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1644.38971875\tTime: 0:00:00.016137\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1687.448375\tTime: 0:00:00.094278\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1635.81125\tTime: 0:00:00.016656\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1677.27228125\tTime: 0:00:00.093789\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1633.51978125\tTime: 0:00:00.015972\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1674.3735729166667\tTime: 0:00:00.094880\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1623.84509375\tTime: 0:00:00.016404\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1665.16196875\tTime: 0:00:00.102806\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1624.091125\tTime: 0:00:00.016514\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1655.1606979166668\tTime: 0:00:00.094663\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1615.30821875\tTime: 0:00:00.016073\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1653.3918229166666\tTime: 0:00:00.096306\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1612.141125\tTime: 0:00:00.016441\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1647.9226979166667\tTime: 0:00:00.092809\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1614.42203125\tTime: 0:00:00.016195\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1643.6776875\tTime: 0:00:00.095333\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1609.354\tTime: 0:00:00.013426\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1639.1810729166666\tTime: 0:00:00.092301\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1601.802\tTime: 0:00:00.016168\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1637.6614895833334\tTime: 0:00:00.094768\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1599.09775\tTime: 0:00:00.016316\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1628.8378125\tTime: 0:00:00.094529\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1600.884625\tTime: 0:00:00.014020\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1630.61746875\tTime: 0:00:00.094522\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1599.32403125\tTime: 0:00:00.016752\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1625.6185520833333\tTime: 0:00:00.094404\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1599.15321875\tTime: 0:00:00.013143\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1625.3793645833334\tTime: 0:00:00.093678\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1593.44521875\tTime: 0:00:00.016551\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1623.09203125\tTime: 0:00:00.094298\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1590.7103125\tTime: 0:00:00.016228\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1620.9647708333334\tTime: 0:00:00.095230\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1590.4961875\tTime: 0:00:00.013327\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1620.7554166666666\tTime: 0:00:00.093406\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1590.1775\tTime: 0:00:00.013148\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1616.222375\tTime: 0:00:00.094343\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1587.66565625\tTime: 0:00:00.013312\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1616.2799375\tTime: 0:00:00.093498\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1590.45353125\tTime: 0:00:00.013214\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1614.09909375\tTime: 0:00:00.095937\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1582.81996875\tTime: 0:00:00.017058\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1613.874375\tTime: 0:00:00.094645\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1584.182375\tTime: 0:00:00.016292\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1612.1346458333333\tTime: 0:00:00.095381\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1582.6910625\tTime: 0:00:00.016323\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1609.4684479166667\tTime: 0:00:00.094878\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1583.45115625\tTime: 0:00:00.015920\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1606.5586666666666\tTime: 0:00:00.094362\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1585.927625\tTime: 0:00:00.016501\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1607.48078125\tTime: 0:00:00.095050\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1582.00075\tTime: 0:00:00.016123\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1605.2408854166667\tTime: 0:00:00.096359\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1581.8795\tTime: 0:00:00.016421\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1604.8339583333334\tTime: 0:00:00.093685\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1579.6135625\tTime: 0:00:00.013295\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1602.50746875\tTime: 0:00:00.094478\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1583.8384375\tTime: 0:00:00.013462\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1600.71403125\tTime: 0:00:00.091975\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1580.8769375\tTime: 0:00:00.013325\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1599.8458645833334\tTime: 0:00:00.094797\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1578.04171875\tTime: 0:00:00.013532\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1601.58409375\tTime: 0:00:00.094778\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1580.45634375\tTime: 0:00:00.013067\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1597.6599583333334\tTime: 0:00:00.092653\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1581.2210625\tTime: 0:00:00.016767\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1599.1816666666666\tTime: 0:00:00.093511\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1577.53028125\tTime: 0:00:00.013254\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1598.7909895833334\tTime: 0:00:00.095266\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1577.0311875\tTime: 0:00:00.013590\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1598.1256875\tTime: 0:00:00.093432\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1577.7208125\tTime: 0:00:00.016242\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1596.4190416666668\tTime: 0:00:00.095027\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1577.5175625\tTime: 0:00:00.016162\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1597.9373125\tTime: 0:00:00.095288\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1577.9865\tTime: 0:00:00.016220\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1595.19021875\tTime: 0:00:00.092636\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1576.71896875\tTime: 0:00:00.016520\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1594.4024791666666\tTime: 0:00:00.092112\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1577.965\tTime: 0:00:00.016103\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1594.6156458333332\tTime: 0:00:00.094988\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1578.30928125\tTime: 0:00:00.013952\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1593.83640625\tTime: 0:00:00.090060\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1578.463375\tTime: 0:00:00.013516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1593.87753125\tTime: 0:00:00.093531\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1576.63109375\tTime: 0:00:00.013997\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1590.9365208333334\tTime: 0:00:00.091084\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1576.52028125\tTime: 0:00:00.013541\n",
      "Epoch: [54/100]\tSamples: [40500/75000]\tTrain Loss: 1591.46728125\tTime: 0:00:00.091345\n",
      "Epoch: [54/100]\tSamples: [250/25000]\tValidation Loss: 1576.65925\tTime: 0:00:00.014130\n",
      "Epoch: [55/100]\tSamples: [41250/75000]\tTrain Loss: 1591.95890625\tTime: 0:00:00.091266\n",
      "Epoch: [55/100]\tSamples: [250/25000]\tValidation Loss: 1576.8241875\tTime: 0:00:00.013642\n",
      "Epoch: [56/100]\tSamples: [42000/75000]\tTrain Loss: 1591.3839270833334\tTime: 0:00:00.093859\n",
      "Epoch: [56/100]\tSamples: [250/25000]\tValidation Loss: 1576.36225\tTime: 0:00:00.014114\n",
      "Epoch: [57/100]\tSamples: [42750/75000]\tTrain Loss: 1590.1782291666666\tTime: 0:00:00.091499\n",
      "Epoch: [57/100]\tSamples: [250/25000]\tValidation Loss: 1576.0885625\tTime: 0:00:00.013477\n",
      "Epoch: [58/100]\tSamples: [43500/75000]\tTrain Loss: 1590.1208020833333\tTime: 0:00:00.091512\n",
      "Epoch: [58/100]\tSamples: [250/25000]\tValidation Loss: 1577.75640625\tTime: 0:00:00.013906\n",
      "Epoch: [59/100]\tSamples: [44250/75000]\tTrain Loss: 1591.7689375\tTime: 0:00:00.093877\n",
      "Epoch: [59/100]\tSamples: [250/25000]\tValidation Loss: 1577.547625\tTime: 0:00:00.013657\n",
      "Epoch: [60/100]\tSamples: [45000/75000]\tTrain Loss: 1588.1074791666667\tTime: 0:00:00.096100\n",
      "Epoch: [60/100]\tSamples: [250/25000]\tValidation Loss: 1574.155625\tTime: 0:00:00.014101\n",
      "Epoch: [61/100]\tSamples: [45750/75000]\tTrain Loss: 1591.0348229166666\tTime: 0:00:00.091703\n",
      "Epoch: [61/100]\tSamples: [250/25000]\tValidation Loss: 1576.07659375\tTime: 0:00:00.013277\n",
      "Epoch: [62/100]\tSamples: [46500/75000]\tTrain Loss: 1591.1340520833332\tTime: 0:00:00.094455\n",
      "Epoch: [62/100]\tSamples: [250/25000]\tValidation Loss: 1577.52203125\tTime: 0:00:00.016243\n",
      "Epoch: [63/100]\tSamples: [47250/75000]\tTrain Loss: 1590.26875\tTime: 0:00:00.094086\n",
      "Epoch: [63/100]\tSamples: [250/25000]\tValidation Loss: 1575.66771875\tTime: 0:00:00.012920\n",
      "Epoch: [64/100]\tSamples: [48000/75000]\tTrain Loss: 1587.1645833333334\tTime: 0:00:00.095467\n",
      "Epoch: [64/100]\tSamples: [250/25000]\tValidation Loss: 1575.32778125\tTime: 0:00:00.016594\n",
      "Epoch: [65/100]\tSamples: [48750/75000]\tTrain Loss: 1591.0404791666667\tTime: 0:00:00.095852\n",
      "Epoch: [65/100]\tSamples: [250/25000]\tValidation Loss: 1574.8171875\tTime: 0:00:00.012925\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m22.275188193724794\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2444.297247452294\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1799.8496041666667\tTime: 0:00:00.094695\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1697.6889375\tTime: 0:00:00.013915\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1792.1858020833333\tTime: 0:00:00.092949\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1698.4515625\tTime: 0:00:00.013501\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1779.5841666666668\tTime: 0:00:00.096943\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1700.83059375\tTime: 0:00:00.013601\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1763.667\tTime: 0:00:00.094973\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1703.53203125\tTime: 0:00:00.013590\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1745.71721875\tTime: 0:00:00.097423\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1699.78828125\tTime: 0:00:00.013911\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1727.402625\tTime: 0:00:00.096906\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1693.2035\tTime: 0:00:00.016511\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1712.27740625\tTime: 0:00:00.100146\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1683.98315625\tTime: 0:00:00.016817\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1698.85753125\tTime: 0:00:00.097182\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1678.37709375\tTime: 0:00:00.013732\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1686.6374791666667\tTime: 0:00:00.094227\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1670.67775\tTime: 0:00:00.013693\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1679.16653125\tTime: 0:00:00.096550\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1664.84328125\tTime: 0:00:00.013607\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1664.4223125\tTime: 0:00:00.098698\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1658.382375\tTime: 0:00:00.013754\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1661.9221875\tTime: 0:00:00.096774\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1652.557125\tTime: 0:00:00.013416\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1653.7506770833334\tTime: 0:00:00.094515\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1645.35975\tTime: 0:00:00.013658\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1649.8147708333333\tTime: 0:00:00.095926\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1640.58690625\tTime: 0:00:00.013569\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1639.5803229166668\tTime: 0:00:00.095658\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1636.4989375\tTime: 0:00:00.016956\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1636.1639583333333\tTime: 0:00:00.094154\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1632.95725\tTime: 0:00:00.013648\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1631.33671875\tTime: 0:00:00.095051\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1628.940375\tTime: 0:00:00.016822\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1626.0190520833332\tTime: 0:00:00.094803\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1626.330625\tTime: 0:00:00.016645\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1624.3335625\tTime: 0:00:00.095762\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1622.4704375\tTime: 0:00:00.013944\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1617.5823854166667\tTime: 0:00:00.092399\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1619.277125\tTime: 0:00:00.016701\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1613.3393958333334\tTime: 0:00:00.093181\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1621.28328125\tTime: 0:00:00.016572\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1612.44471875\tTime: 0:00:00.095256\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1617.9026875\tTime: 0:00:00.013431\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1606.52709375\tTime: 0:00:00.096062\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1612.502125\tTime: 0:00:00.013821\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1606.3900208333334\tTime: 0:00:00.095242\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1616.86875\tTime: 0:00:00.015570\n",
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1603.0515416666667\tTime: 0:00:00.096187\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1613.81884375\tTime: 0:00:00.016816\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1599.0833125\tTime: 0:00:00.097526\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1607.76078125\tTime: 0:00:00.016479\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1601.03715625\tTime: 0:00:00.097535\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1611.1745625\tTime: 0:00:00.013637\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1597.93034375\tTime: 0:00:00.095060\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1608.96796875\tTime: 0:00:00.016841\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1593.8112395833334\tTime: 0:00:00.099776\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1605.87565625\tTime: 0:00:00.013918\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1594.79015625\tTime: 0:00:00.091378\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1605.6245625\tTime: 0:00:00.013587\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1590.7924270833332\tTime: 0:00:00.092254\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1603.10740625\tTime: 0:00:00.016604\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1589.8491041666666\tTime: 0:00:00.092808\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1602.94040625\tTime: 0:00:00.016656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1592.7927291666667\tTime: 0:00:00.095168\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1601.95125\tTime: 0:00:00.013571\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1590.5989791666666\tTime: 0:00:00.096865\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1604.111\tTime: 0:00:00.013683\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1587.8552083333334\tTime: 0:00:00.095951\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1599.69896875\tTime: 0:00:00.013668\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1585.35046875\tTime: 0:00:00.093556\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1600.75403125\tTime: 0:00:00.013788\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1584.4065520833333\tTime: 0:00:00.093346\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1598.1785\tTime: 0:00:00.016688\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1582.4436875\tTime: 0:00:00.094054\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1598.63984375\tTime: 0:00:00.013546\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1580.1161458333333\tTime: 0:00:00.097800\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1600.8151875\tTime: 0:00:00.013794\n",
      "Epoch: [40/100]\tSamples: [30000/75000]\tTrain Loss: 1581.9650625\tTime: 0:00:00.095474\n",
      "Epoch: [40/100]\tSamples: [250/25000]\tValidation Loss: 1599.79125\tTime: 0:00:00.013605\n",
      "Epoch: [41/100]\tSamples: [30750/75000]\tTrain Loss: 1581.8734270833334\tTime: 0:00:00.094423\n",
      "Epoch: [41/100]\tSamples: [250/25000]\tValidation Loss: 1597.28459375\tTime: 0:00:00.016790\n",
      "Epoch: [42/100]\tSamples: [31500/75000]\tTrain Loss: 1580.07690625\tTime: 0:00:00.101257\n",
      "Epoch: [42/100]\tSamples: [250/25000]\tValidation Loss: 1600.7801875\tTime: 0:00:00.013772\n",
      "Epoch: [43/100]\tSamples: [32250/75000]\tTrain Loss: 1579.7872916666668\tTime: 0:00:00.094707\n",
      "Epoch: [43/100]\tSamples: [250/25000]\tValidation Loss: 1597.96115625\tTime: 0:00:00.013697\n",
      "Epoch: [44/100]\tSamples: [33000/75000]\tTrain Loss: 1578.2392083333334\tTime: 0:00:00.095525\n",
      "Epoch: [44/100]\tSamples: [250/25000]\tValidation Loss: 1597.933375\tTime: 0:00:00.013631\n",
      "Epoch: [45/100]\tSamples: [33750/75000]\tTrain Loss: 1579.85496875\tTime: 0:00:00.095816\n",
      "Epoch: [45/100]\tSamples: [250/25000]\tValidation Loss: 1595.98721875\tTime: 0:00:00.016835\n",
      "Epoch: [46/100]\tSamples: [34500/75000]\tTrain Loss: 1576.3539270833332\tTime: 0:00:00.094667\n",
      "Epoch: [46/100]\tSamples: [250/25000]\tValidation Loss: 1596.87875\tTime: 0:00:00.013683\n",
      "Epoch: [47/100]\tSamples: [35250/75000]\tTrain Loss: 1577.6512395833333\tTime: 0:00:00.094125\n",
      "Epoch: [47/100]\tSamples: [250/25000]\tValidation Loss: 1597.294375\tTime: 0:00:00.013839\n",
      "Epoch: [48/100]\tSamples: [36000/75000]\tTrain Loss: 1577.05359375\tTime: 0:00:00.093640\n",
      "Epoch: [48/100]\tSamples: [250/25000]\tValidation Loss: 1595.78509375\tTime: 0:00:00.016496\n",
      "Epoch: [49/100]\tSamples: [36750/75000]\tTrain Loss: 1578.0278020833334\tTime: 0:00:00.101845\n",
      "Epoch: [49/100]\tSamples: [250/25000]\tValidation Loss: 1597.588125\tTime: 0:00:00.013738\n",
      "Epoch: [50/100]\tSamples: [37500/75000]\tTrain Loss: 1573.9469270833333\tTime: 0:00:00.092939\n",
      "Epoch: [50/100]\tSamples: [250/25000]\tValidation Loss: 1596.71678125\tTime: 0:00:00.016482\n",
      "Epoch: [51/100]\tSamples: [38250/75000]\tTrain Loss: 1574.9083020833334\tTime: 0:00:00.096029\n",
      "Epoch: [51/100]\tSamples: [250/25000]\tValidation Loss: 1596.303\tTime: 0:00:00.014008\n",
      "Epoch: [52/100]\tSamples: [39000/75000]\tTrain Loss: 1573.8494583333334\tTime: 0:00:00.096033\n",
      "Epoch: [52/100]\tSamples: [250/25000]\tValidation Loss: 1598.5843125\tTime: 0:00:00.013591\n",
      "Epoch: [53/100]\tSamples: [39750/75000]\tTrain Loss: 1574.95334375\tTime: 0:00:00.093593\n",
      "Epoch: [53/100]\tSamples: [250/25000]\tValidation Loss: 1598.07615625\tTime: 0:00:00.013985\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m22.267959481914854\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2441.4863411292968\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1811.8584895833333\tTime: 0:00:00.089929\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1697.91440625\tTime: 0:00:00.016713\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1804.82546875\tTime: 0:00:00.091117\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1698.61846875\tTime: 0:00:00.013392\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1790.0909895833333\tTime: 0:00:00.094708\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1701.570625\tTime: 0:00:00.013962\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1769.8636770833334\tTime: 0:00:00.092474\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1702.56403125\tTime: 0:00:00.013333\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1754.2883229166666\tTime: 0:00:00.090203\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1699.71446875\tTime: 0:00:00.016514\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1735.1235\tTime: 0:00:00.098897\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1692.25396875\tTime: 0:00:00.016319\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1718.7188854166666\tTime: 0:00:00.111630\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1685.13084375\tTime: 0:00:00.016704\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1707.9039270833334\tTime: 0:00:00.104845\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1675.68340625\tTime: 0:00:00.016216\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1698.8339375\tTime: 0:00:00.106021\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1670.621125\tTime: 0:00:00.016848\n",
      "Epoch: [10/100]\tSamples: [7500/75000]\tTrain Loss: 1685.9894166666666\tTime: 0:00:00.104688\n",
      "Epoch: [10/100]\tSamples: [250/25000]\tValidation Loss: 1664.089625\tTime: 0:00:00.016313\n",
      "Epoch: [11/100]\tSamples: [8250/75000]\tTrain Loss: 1676.122125\tTime: 0:00:00.106591\n",
      "Epoch: [11/100]\tSamples: [250/25000]\tValidation Loss: 1657.688\tTime: 0:00:00.016365\n",
      "Epoch: [12/100]\tSamples: [9000/75000]\tTrain Loss: 1671.4388645833333\tTime: 0:00:00.105167\n",
      "Epoch: [12/100]\tSamples: [250/25000]\tValidation Loss: 1650.4556875\tTime: 0:00:00.016454\n",
      "Epoch: [13/100]\tSamples: [9750/75000]\tTrain Loss: 1660.3695833333334\tTime: 0:00:00.105397\n",
      "Epoch: [13/100]\tSamples: [250/25000]\tValidation Loss: 1647.73821875\tTime: 0:00:00.016680\n",
      "Epoch: [14/100]\tSamples: [10500/75000]\tTrain Loss: 1658.8600729166667\tTime: 0:00:00.090705\n",
      "Epoch: [14/100]\tSamples: [250/25000]\tValidation Loss: 1641.41596875\tTime: 0:00:00.013547\n",
      "Epoch: [15/100]\tSamples: [11250/75000]\tTrain Loss: 1651.5756145833334\tTime: 0:00:00.092253\n",
      "Epoch: [15/100]\tSamples: [250/25000]\tValidation Loss: 1637.22521875\tTime: 0:00:00.013965\n",
      "Epoch: [16/100]\tSamples: [12000/75000]\tTrain Loss: 1646.0173645833333\tTime: 0:00:00.089222\n",
      "Epoch: [16/100]\tSamples: [250/25000]\tValidation Loss: 1636.67253125\tTime: 0:00:00.016556\n",
      "Epoch: [17/100]\tSamples: [12750/75000]\tTrain Loss: 1638.33728125\tTime: 0:00:00.092694\n",
      "Epoch: [17/100]\tSamples: [250/25000]\tValidation Loss: 1630.43053125\tTime: 0:00:00.013546\n",
      "Epoch: [18/100]\tSamples: [13500/75000]\tTrain Loss: 1633.92021875\tTime: 0:00:00.091812\n",
      "Epoch: [18/100]\tSamples: [250/25000]\tValidation Loss: 1628.4051875\tTime: 0:00:00.013204\n",
      "Epoch: [19/100]\tSamples: [14250/75000]\tTrain Loss: 1630.63540625\tTime: 0:00:00.089485\n",
      "Epoch: [19/100]\tSamples: [250/25000]\tValidation Loss: 1625.6140625\tTime: 0:00:00.016565\n",
      "Epoch: [20/100]\tSamples: [15000/75000]\tTrain Loss: 1630.5408645833334\tTime: 0:00:00.092192\n",
      "Epoch: [20/100]\tSamples: [250/25000]\tValidation Loss: 1621.0374375\tTime: 0:00:00.013350\n",
      "Epoch: [21/100]\tSamples: [15750/75000]\tTrain Loss: 1628.1422083333334\tTime: 0:00:00.089510\n",
      "Epoch: [21/100]\tSamples: [250/25000]\tValidation Loss: 1619.82965625\tTime: 0:00:00.013768\n",
      "Epoch: [22/100]\tSamples: [16500/75000]\tTrain Loss: 1620.5675520833333\tTime: 0:00:00.092805\n",
      "Epoch: [22/100]\tSamples: [250/25000]\tValidation Loss: 1618.160625\tTime: 0:00:00.013155\n",
      "Epoch: [23/100]\tSamples: [17250/75000]\tTrain Loss: 1621.27903125\tTime: 0:00:00.092124\n",
      "Epoch: [23/100]\tSamples: [250/25000]\tValidation Loss: 1614.3860625\tTime: 0:00:00.016905\n",
      "Epoch: [24/100]\tSamples: [18000/75000]\tTrain Loss: 1617.177125\tTime: 0:00:00.091884\n",
      "Epoch: [24/100]\tSamples: [250/25000]\tValidation Loss: 1616.2411875\tTime: 0:00:00.013367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25/100]\tSamples: [18750/75000]\tTrain Loss: 1611.36790625\tTime: 0:00:00.093396\n",
      "Epoch: [25/100]\tSamples: [250/25000]\tValidation Loss: 1608.1931875\tTime: 0:00:00.013716\n",
      "Epoch: [26/100]\tSamples: [19500/75000]\tTrain Loss: 1608.9914791666667\tTime: 0:00:00.092679\n",
      "Epoch: [26/100]\tSamples: [250/25000]\tValidation Loss: 1611.55825\tTime: 0:00:00.016274\n",
      "Epoch: [27/100]\tSamples: [20250/75000]\tTrain Loss: 1607.0019166666666\tTime: 0:00:00.095186\n",
      "Epoch: [27/100]\tSamples: [250/25000]\tValidation Loss: 1607.56821875\tTime: 0:00:00.013859\n",
      "Epoch: [28/100]\tSamples: [21000/75000]\tTrain Loss: 1603.6108125\tTime: 0:00:00.099537\n",
      "Epoch: [28/100]\tSamples: [250/25000]\tValidation Loss: 1608.524375\tTime: 0:00:00.014472\n",
      "Epoch: [29/100]\tSamples: [21750/75000]\tTrain Loss: 1603.5864895833333\tTime: 0:00:00.091511\n",
      "Epoch: [29/100]\tSamples: [250/25000]\tValidation Loss: 1608.66765625\tTime: 0:00:00.013789\n",
      "Epoch: [30/100]\tSamples: [22500/75000]\tTrain Loss: 1604.8293020833332\tTime: 0:00:00.089442\n",
      "Epoch: [30/100]\tSamples: [250/25000]\tValidation Loss: 1608.1523125\tTime: 0:00:00.013603\n",
      "Epoch: [31/100]\tSamples: [23250/75000]\tTrain Loss: 1600.1330729166666\tTime: 0:00:00.095170\n",
      "Epoch: [31/100]\tSamples: [250/25000]\tValidation Loss: 1603.79909375\tTime: 0:00:00.013981\n",
      "Epoch: [32/100]\tSamples: [24000/75000]\tTrain Loss: 1598.5855416666666\tTime: 0:00:00.090592\n",
      "Epoch: [32/100]\tSamples: [250/25000]\tValidation Loss: 1606.8943125\tTime: 0:00:00.013731\n",
      "Epoch: [33/100]\tSamples: [24750/75000]\tTrain Loss: 1598.3893645833334\tTime: 0:00:00.092040\n",
      "Epoch: [33/100]\tSamples: [250/25000]\tValidation Loss: 1604.54009375\tTime: 0:00:00.013773\n",
      "Epoch: [34/100]\tSamples: [25500/75000]\tTrain Loss: 1597.58396875\tTime: 0:00:00.089431\n",
      "Epoch: [34/100]\tSamples: [250/25000]\tValidation Loss: 1601.875125\tTime: 0:00:00.013597\n",
      "Epoch: [35/100]\tSamples: [26250/75000]\tTrain Loss: 1596.7920208333333\tTime: 0:00:00.092589\n",
      "Epoch: [35/100]\tSamples: [250/25000]\tValidation Loss: 1602.10425\tTime: 0:00:00.013669\n",
      "Epoch: [36/100]\tSamples: [27000/75000]\tTrain Loss: 1598.5583541666667\tTime: 0:00:00.090077\n",
      "Epoch: [36/100]\tSamples: [250/25000]\tValidation Loss: 1604.32184375\tTime: 0:00:00.013530\n",
      "Epoch: [37/100]\tSamples: [27750/75000]\tTrain Loss: 1591.8612708333333\tTime: 0:00:00.091716\n",
      "Epoch: [37/100]\tSamples: [250/25000]\tValidation Loss: 1606.92940625\tTime: 0:00:00.016704\n",
      "Epoch: [38/100]\tSamples: [28500/75000]\tTrain Loss: 1594.22421875\tTime: 0:00:00.090943\n",
      "Epoch: [38/100]\tSamples: [250/25000]\tValidation Loss: 1602.84365625\tTime: 0:00:00.013544\n",
      "Epoch: [39/100]\tSamples: [29250/75000]\tTrain Loss: 1590.4861979166667\tTime: 0:00:00.089594\n",
      "Epoch: [39/100]\tSamples: [250/25000]\tValidation Loss: 1602.1194375\tTime: 0:00:00.013808\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m22.302536297143813\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m2393.714379455328\u001b[0m\n",
      "Nodes averages betas and thetas inf:  22.275079302328127 2434.5687368553504\n",
      "Executing for eta equals to  1\n",
      "Generating document words for node  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 34.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 33.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:58<00:00, 34.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating document words for node  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:59<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the inference corpus  5000\n",
      "Shape of inf_doc_topics (5000, 20)\n",
      "CENTRALIZED\n",
      "Size of centralized corpus  5000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prod_centralized_old\n",
      "Epoch: [1/100]\tSamples: [3750/375000]\tTrain Loss: 1808.0175645833333\tTime: 0:00:00.446435\n",
      "Epoch: [1/100]\tSamples: [1250/125000]\tValidation Loss: 1698.13838125\tTime: 0:00:00.061700\n",
      "Epoch: [2/100]\tSamples: [7500/375000]\tTrain Loss: 1798.1586770833333\tTime: 0:00:00.453661\n",
      "Epoch: [2/100]\tSamples: [1250/125000]\tValidation Loss: 1711.1773625\tTime: 0:00:00.063824\n",
      "Epoch: [3/100]\tSamples: [11250/375000]\tTrain Loss: 1792.4930958333334\tTime: 0:00:00.445132\n",
      "Epoch: [3/100]\tSamples: [1250/125000]\tValidation Loss: 1711.167309375\tTime: 0:00:00.061090\n",
      "Epoch: [4/100]\tSamples: [15000/375000]\tTrain Loss: 1785.2791979166666\tTime: 0:00:00.442391\n",
      "Epoch: [4/100]\tSamples: [1250/125000]\tValidation Loss: 1711.1557375\tTime: 0:00:00.062900\n",
      "Epoch: [5/100]\tSamples: [18750/375000]\tTrain Loss: 1778.0962770833332\tTime: 0:00:00.441048\n",
      "Epoch: [5/100]\tSamples: [1250/125000]\tValidation Loss: 1712.211446875\tTime: 0:00:00.061742\n",
      "Epoch: [6/100]\tSamples: [22500/375000]\tTrain Loss: 1773.23344375\tTime: 0:00:00.435042\n",
      "Epoch: [6/100]\tSamples: [1250/125000]\tValidation Loss: 1713.8087875\tTime: 0:00:00.064384\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m44.292885402499884\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3378.5967105301\u001b[0m\n",
      "NON-COLLABORATIVE of node  0\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1818.5615520833333\tTime: 0:00:00.091296\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1703.7504375\tTime: 0:00:00.013777\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1815.7315208333334\tTime: 0:00:00.091639\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1703.55490625\tTime: 0:00:00.013434\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1815.6684166666666\tTime: 0:00:00.095353\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1703.06875\tTime: 0:00:00.013922\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1812.4704895833333\tTime: 0:00:00.092707\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1702.24171875\tTime: 0:00:00.013649\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1808.6536875\tTime: 0:00:00.092551\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1702.8933125\tTime: 0:00:00.014059\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1802.3629583333334\tTime: 0:00:00.090937\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1705.77059375\tTime: 0:00:00.013923\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1799.78321875\tTime: 0:00:00.090480\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1711.02784375\tTime: 0:00:00.013836\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1798.4281458333332\tTime: 0:00:00.091168\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1715.703125\tTime: 0:00:00.013449\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1793.38434375\tTime: 0:00:00.093535\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1717.712375\tTime: 0:00:00.013594\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m44.29288409243951\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3473.3896909001687\u001b[0m\n",
      "NON-COLLABORATIVE of node  1\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1803.8210520833334\tTime: 0:00:00.091134\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1708.35265625\tTime: 0:00:00.016901\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1803.9119583333334\tTime: 0:00:00.089566\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1708.05284375\tTime: 0:00:00.013295\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1801.7328229166667\tTime: 0:00:00.093974\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1706.0300625\tTime: 0:00:00.013695\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1794.7119270833334\tTime: 0:00:00.089803\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1705.2401875\tTime: 0:00:00.013603\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1790.5851145833333\tTime: 0:00:00.091408\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1706.0275\tTime: 0:00:00.016459\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1789.00771875\tTime: 0:00:00.094649\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1709.20659375\tTime: 0:00:00.016347\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1786.84734375\tTime: 0:00:00.092247\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1714.346625\tTime: 0:00:00.013484\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1781.9026666666666\tTime: 0:00:00.093055\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1717.79675\tTime: 0:00:00.016285\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1783.88296875\tTime: 0:00:00.091191\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1719.20765625\tTime: 0:00:00.016923\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m44.29288419322806\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3483.33524331915\u001b[0m\n",
      "NON-COLLABORATIVE of node  2\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1813.4329583333333\tTime: 0:00:00.090146\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1688.031125\tTime: 0:00:00.013844\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1811.0408541666666\tTime: 0:00:00.087863\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1687.12434375\tTime: 0:00:00.013895\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1807.0903125\tTime: 0:00:00.091248\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1685.30259375\tTime: 0:00:00.013475\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1802.64625\tTime: 0:00:00.103676\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1685.17478125\tTime: 0:00:00.013257\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1799.3229479166666\tTime: 0:00:00.090448\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1686.564125\tTime: 0:00:00.013636\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1795.0471354166666\tTime: 0:00:00.094175\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1688.8245625\tTime: 0:00:00.013308\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1794.3001770833334\tTime: 0:00:00.090871\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1694.4571875\tTime: 0:00:00.016953\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1788.3319166666668\tTime: 0:00:00.092771\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1697.234875\tTime: 0:00:00.013413\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1785.0330833333333\tTime: 0:00:00.091090\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1700.82678125\tTime: 0:00:00.013663\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m44.292884170129994\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3472.7819477194316\u001b[0m\n",
      "NON-COLLABORATIVE of node  3\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1817.6641458333334\tTime: 0:00:00.091729\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1673.453125\tTime: 0:00:00.013660\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1816.89884375\tTime: 0:00:00.088979\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1673.4980625\tTime: 0:00:00.013477\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1813.5486458333332\tTime: 0:00:00.094138\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1672.8859375\tTime: 0:00:00.013972\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1811.452875\tTime: 0:00:00.091287\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1672.54678125\tTime: 0:00:00.016327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1806.4523541666667\tTime: 0:00:00.090851\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1672.88384375\tTime: 0:00:00.016553\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1801.5578854166667\tTime: 0:00:00.093777\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1675.43675\tTime: 0:00:00.013465\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1800.5143541666666\tTime: 0:00:00.092256\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1681.5599375\tTime: 0:00:00.013775\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1796.60896875\tTime: 0:00:00.091299\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1684.70225\tTime: 0:00:00.016322\n",
      "Epoch: [9/100]\tSamples: [6750/75000]\tTrain Loss: 1791.8443958333332\tTime: 0:00:00.094345\n",
      "Epoch: [9/100]\tSamples: [250/25000]\tValidation Loss: 1685.4956875\tTime: 0:00:00.013572\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m44.29288420999656\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3485.2148618807355\u001b[0m\n",
      "NON-COLLABORATIVE of node  4\n",
      "Size of non-collaborative corpus  1000\n",
      "-- -- Creating backup of existing model in /export/usuarios_ml4ds/lbartolome/data/project_folder/TMmodels/Federated_test/prodlda_node_old\n",
      "Epoch: [1/100]\tSamples: [750/75000]\tTrain Loss: 1814.9624791666668\tTime: 0:00:00.091646\n",
      "Epoch: [1/100]\tSamples: [250/25000]\tValidation Loss: 1707.3514375\tTime: 0:00:00.016611\n",
      "Epoch: [2/100]\tSamples: [1500/75000]\tTrain Loss: 1811.1434270833333\tTime: 0:00:00.088951\n",
      "Epoch: [2/100]\tSamples: [250/25000]\tValidation Loss: 1705.984875\tTime: 0:00:00.016180\n",
      "Epoch: [3/100]\tSamples: [2250/75000]\tTrain Loss: 1809.4689791666667\tTime: 0:00:00.094033\n",
      "Epoch: [3/100]\tSamples: [250/25000]\tValidation Loss: 1705.09284375\tTime: 0:00:00.013544\n",
      "Epoch: [4/100]\tSamples: [3000/75000]\tTrain Loss: 1804.2323125\tTime: 0:00:00.090058\n",
      "Epoch: [4/100]\tSamples: [250/25000]\tValidation Loss: 1705.09384375\tTime: 0:00:00.013217\n",
      "Epoch: [5/100]\tSamples: [3750/75000]\tTrain Loss: 1800.98378125\tTime: 0:00:00.090233\n",
      "Epoch: [5/100]\tSamples: [250/25000]\tValidation Loss: 1706.0259375\tTime: 0:00:00.016649\n",
      "Epoch: [6/100]\tSamples: [4500/75000]\tTrain Loss: 1798.6311041666668\tTime: 0:00:00.091357\n",
      "Epoch: [6/100]\tSamples: [250/25000]\tValidation Loss: 1709.0314375\tTime: 0:00:00.012963\n",
      "Epoch: [7/100]\tSamples: [5250/75000]\tTrain Loss: 1796.6091354166667\tTime: 0:00:00.091916\n",
      "Epoch: [7/100]\tSamples: [250/25000]\tValidation Loss: 1713.61584375\tTime: 0:00:00.013458\n",
      "Epoch: [8/100]\tSamples: [6000/75000]\tTrain Loss: 1786.7611354166668\tTime: 0:00:00.090266\n",
      "Epoch: [8/100]\tSamples: [250/25000]\tValidation Loss: 1717.29921875\tTime: 0:00:00.013100\n",
      "Early stopping\n",
      "Tópicos (equivalentes) evaluados correctamente:\n",
      "\u001b[38;5;2m44.29288412022875\u001b[0m\n",
      "Difference in evaluation of doc similarity:\n",
      "\u001b[38;5;2m3485.3504866390817\u001b[0m\n",
      "Nodes averages betas and thetas inf:  44.29288415720457 3480.0144460917136\n"
     ]
    }
   ],
   "source": [
    "frozen_topics_list = [5,10,15,40]\n",
    "eta_list = [1e-2, 0.02, 0.03, 0.04, 0.08, 1]\n",
    "\n",
    "sim_betas_centralized = []\n",
    "sim_thetas_centralized = []\n",
    "sim_betas_non_colab = []\n",
    "sim_thetas_non_colab = []\n",
    "\n",
    "for eta in eta_list:\n",
    "    print(\"Executing for eta equals to \", str(eta))\n",
    "    \n",
    "    tm_settings[\"beta\"] = eta\n",
    "    \n",
    "    # Recalculate centralized settings\n",
    "    prior_frozen = frozen_topics_list[1] * [alpha]\n",
    "    own_topics = int((n_topics-frozen_topics)/n_nodes)\n",
    "    prior_nofrozen = own_topics * [alpha] + (n_topics-frozen_topics-own_topics) * [alpha/10000]\n",
    "\n",
    "    centralized_settings = {\n",
    "        \"n_nodes\": n_nodes,\n",
    "        \"frozen_topics\": frozen_topics,\n",
    "        \"prior_frozen\": prior_frozen,\n",
    "        \"own_topics\": own_topics,\n",
    "        \"prior_nofrozen\": prior_nofrozen\n",
    "    }\n",
    "    \n",
    "    # Generate documents\n",
    "    topic_vectors, doc_topics_all, documents_all = generateSynthetic(False, True, **tm_settings, **centralized_settings)\n",
    "    \n",
    "    # Generate inference corpus and its docs_topics\n",
    "    inf = [doc for docs_node in documents_all for doc in docs_node[n_docs:(n_docs+n_docs_global_inf)]]\n",
    "    print(\"Length of the inference corpus \", str(len(inf)))\n",
    "\n",
    "    for i in range(len(doc_topics_all)):\n",
    "        if i == 0:\n",
    "            inf_doc_topics = doc_topics_all[i][n_docs:(n_docs+n_docs_global_inf)]\n",
    "        else:\n",
    "            inf_doc_topics = np.concatenate((inf_doc_topics,doc_topics_all[i][n_docs:(n_docs+n_docs_global_inf)])) \n",
    "    print(\"Shape of inf_doc_topics\", str(inf_doc_topics.shape))\n",
    "    \n",
    "    ########################\n",
    "    # Centralized training #\n",
    "    ########################\n",
    "    print(\"CENTRALIZED\")\n",
    "    # Define corpus\n",
    "    corpus = [doc for docs_node in documents_all for doc in docs_node[0:n_docs]]\n",
    "    print(\"Size of centralized corpus \", str(len(corpus)))\n",
    "\n",
    "    # Train model \n",
    "    modelname = \"prod_centralized\"\n",
    "    modeldir, avitm, cv, id2token, idx2token = train_avitm(modelname, modelsdir, corpus)\n",
    "    \n",
    "    # Get betas\n",
    "    betas = avitm.get_topic_word_mat()#avitm.get_topic_word_distribution()\n",
    "    betas = softmax(betas, axis=1)\n",
    "    all_words = ['wd'+str(word) for word in np.arange(vocab_size+1) if word > 0]\n",
    "    betas = convert_topic_word_to_init_size(vocab_size=vocab_size,\n",
    "                                            model=avitm,\n",
    "                                            model_type=\"avitm\",\n",
    "                                            ntopics=n_topics,\n",
    "                                            id2token=id2token,\n",
    "                                            all_words=all_words)\n",
    "\n",
    "    # Get thetas\n",
    "    #thetas = np.asarray(avitm.get_doc_topic_distribution(avitm.train_data))[0:n_docs,:]\n",
    "    #thetas_theoretical = doc_topics_all[0][0:n_docs]\n",
    "\n",
    "    # Eval betas and thetas\n",
    "    betas_31 = eval_betas(betas, topic_vectors)\n",
    "    #thetas_31 = eval_thetas(thetas_theoretical, thetas, len(thetas))\n",
    "    sim_betas_centralized.append(betas_31)\n",
    "    \n",
    "    # Inference\n",
    "    # Get inferred thetas\n",
    "    docs_val_conv = [\" \".join(inf[i]) for i in np.arange(len(inf))]\n",
    "    val_bow = cv.transform(docs_val_conv)\n",
    "    val_bow = val_bow.toarray()\n",
    "    val_data = BOWDataset(val_bow, idx2token)\n",
    "\n",
    "    thetas_inf = np.asarray(avitm.get_thetas(val_data))#np.asarray(avitm.get_doc_topic_distribution(val_data))\n",
    "    thetas_theoretical = inf_doc_topics\n",
    "\n",
    "    # Eval thetas\n",
    "    thetas_312 = eval_thetas(thetas_theoretical, thetas_inf, len(thetas_inf))\n",
    "    sim_thetas_centralized.append(thetas_312)\n",
    "    \n",
    "    #############################\n",
    "    # Non-colaborative training #\n",
    "    #############################\n",
    "    betas_nodes = []\n",
    "    thetas_nodes = []\n",
    "    for node in range(n_nodes):\n",
    "        print(\"NON-COLLABORATIVE of node \", str(node))\n",
    "        # Define corpus\n",
    "        corpus = documents_all[node][0:n_docs]\n",
    "        print(\"Size of non-collaborative corpus \", str(len(corpus)))\n",
    "\n",
    "        # Train model \n",
    "        modelname = \"prodlda_node\"\n",
    "        modeldir, avitm, cv, id2token, idx2token = train_avitm(modelname, modelsdir, corpus)\n",
    "\n",
    "        # Get betas\n",
    "        betas = avitm.get_topic_word_mat()#avitm.get_topic_word_distribution()\n",
    "        betas = softmax(betas, axis=1)\n",
    "        all_words = ['wd'+str(word) for word in np.arange(vocab_size+1) if word > 0]\n",
    "        betas = convert_topic_word_to_init_size(vocab_size=vocab_size,\n",
    "                                                model=avitm,\n",
    "                                                model_type=\"avitm\",\n",
    "                                                ntopics=n_topics,\n",
    "                                                id2token=id2token,\n",
    "                                                all_words=all_words)\n",
    "\n",
    "        # Get thetas\n",
    "        #thetas = np.asarray(avitm.get_doc_topic_distribution(avitm.train_data))\n",
    "        #thetas_theoretical = doc_topics_all[0][0:n_docs]\n",
    "\n",
    "\n",
    "        # Eval betas and thetas\n",
    "        betas_32 = eval_betas(betas, topic_vectors)\n",
    "        betas_nodes.append(betas_32)\n",
    "\n",
    "        #thetas_32 = eval_thetas(thetas_theoretical, thetas, len(thetas))\n",
    "\n",
    "        # Inference\n",
    "        # Get inferred thetas\n",
    "        docs_val_conv = [\" \".join(inf[i]) for i in np.arange(len(inf))]\n",
    "        val_bow = cv.transform(docs_val_conv)\n",
    "        val_bow = val_bow.toarray()\n",
    "        val_data = BOWDataset(val_bow, idx2token)\n",
    "\n",
    "        thetas_inf = np.asarray(avitm.get_thetas(val_data))#np.asarray(avitm.get_doc_topic_distribution(val_data))\n",
    "\n",
    "        thetas_theoretical = inf_doc_topics\n",
    "\n",
    "        # Eval thetas\n",
    "        thetas_322 = eval_thetas(thetas_theoretical, thetas_inf, len(thetas_inf))\n",
    "        thetas_nodes.append(thetas_322)\n",
    "    \n",
    "    avg1 = sum(betas_nodes)/n_nodes\n",
    "    avg2 = sum(thetas_nodes)/n_nodes\n",
    "    sim_betas_non_colab.append(avg1)\n",
    "    print(\"Nodes averages betas and thetas inf: \", str(avg1), str(avg2))\n",
    "    sim_thetas_non_colab.append(avg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abdce207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 267,
       "width": 401
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eta_list, sim_thetas_centralized, label=\"Prod-Centr\")\n",
    "plt.plot(eta_list, sim_thetas_non_colab, label=\"Prod-Non-Collaborative\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.xlabel(r'$\\\\eta$', fontsize=16)\n",
    "plt.ylabel('Doc similarity score', fontsize=16)\n",
    "#plt.xticks(eta_list, [1e-2, 0.02, 0.03, 0.04, 0.08, 1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d6c4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.48790820163805, 11.52863365367631, 14.458031268828853, 16.584951307589545, 22.65822185012252, 44.292885402499884]\n",
      "[6.231895270231613, 10.11865646112027, 13.239466144009715, 15.49068452383763, 22.275079302328127, 44.29288415720457]\n"
     ]
    }
   ],
   "source": [
    "print(sim_betas_centralized)\n",
    "print(sim_betas_non_colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e43ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 274,
       "width": 388
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(eta_list, sim_betas_centralized, label=\"Prod-Centr\")\n",
    "plt.plot(eta_list, sim_betas_non_colab, label=\"Prod-Non-Collaborative\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.xlabel('Topics prior', fontsize=16)\n",
    "plt.ylabel('Nr topics correctly evaluated', fontsize=16)\n",
    "#plt.xticks(eta_list, [1e-2, 0.02, 0.03, 0.04, 0.08, 1])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
